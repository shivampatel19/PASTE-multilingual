{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ceda50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python prep_BERTData.py gen mpqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4291c514",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'Aligner'.\n",
      "Counts not matching on line 7 in train.sent..\n",
      "US And UK Criticise Mugabe's Victory\n",
      "['us', 'and', 'uk', 'critic', '##ise', 'mug', '##abe', \"'\", 's', 'victory']\n",
      "['us', 'and', 'uk', 'critic', '##ize', 'mug', '##abe', \"'\", 's', 'victory']\n",
      "\n",
      "\n",
      "Counts not matching on line 13 in train.sent..\n",
      "In this instance , military sources said , the number of prisoners would be much smaller -- perhaps in the dozens -- and the logistics would focus more on security at the 45 - square - mile base and less on the comfort of prisoners who are considered either members of a terrorist network or supporters of terrorists .\n",
      "['in', 'this', 'instance', ',', 'military', 'sources', 'said', ',', 'the', 'number', 'of', 'prisoners', 'would', 'be', 'much', 'smaller', '-', '-', 'perhaps', 'in', 'the', 'dozens', '-', '-', 'and', 'the', 'logistics', 'would', 'focus', 'more', 'on', 'security', 'at', 'the', '45', '-', 'square', '-', 'mile', 'base', 'and', 'less', 'on', 'the', 'comfort', 'of', 'prisoners', 'who', 'are', 'considered', 'either', 'members', 'of', 'a', 'terrorist', 'network', 'or', 'supporters', 'of', 'terrorists', '.']\n",
      "['in', 'this', 'instance', ',', 'military', 'sources', 'said', ',', 'the', 'number', 'of', 'prisoners', 'would', 'be', 'much', 'smaller', '-', 'perhaps', 'in', 'the', 'dozens', '-', 'and', 'the', 'logistics', 'would', 'focus', 'more', 'on', 'security', 'at', 'the', '45', '-', 'square', '-', 'mile', 'base', 'and', 'less', 'on', 'the', 'comfort', 'of', 'prisoners', 'who', 'are', 'considered', 'either', 'members', 'of', 'a', 'terrorist', 'network', 'or', 'supporters', 'of', 'terrorists', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 38 in train.sent..\n",
      "Putin did not receive what he sought in a quick response from Washington , namely , that the State Department would continue to encourage political dialogue between Moscow and the Chechen insurgents .\n",
      "['putin', 'did', 'not', 'receive', 'what', 'he', 'sought', 'in', 'a', 'quick', 'response', 'from', 'washington', ',', 'namely', ',', 'that', 'the', 'state', 'department', 'would', 'continue', 'to', 'encourage', 'political', 'dialogue', 'between', 'moscow', 'and', 'the', 'che', '##chen', 'insurgents', '.']\n",
      "['putin', 'did', 'not', 'receive', 'what', 'he', 'sought', 'in', 'a', 'quick', 'response', 'from', 'washington', ',', 'namely', ',', 'that', 'the', 'state', 'department', 'would', 'continue', 'to', 'encourage', 'political', 'dial', '##og', 'between', 'moscow', 'and', 'the', 'che', '##chen', 'insurgents', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 44 in train.sent..\n",
      "Former president of the United States , Jimmy Carter , has come out in support of Chavez 's promise to set up dialogue tables and is scheduled to visit Venezuela in the near future .\n",
      "['former', 'president', 'of', 'the', 'united', 'states', ',', 'jimmy', 'carter', ',', 'has', 'come', 'out', 'in', 'support', 'of', 'chavez', \"'\", 's', 'promise', 'to', 'set', 'up', 'dialogue', 'tables', 'and', 'is', 'scheduled', 'to', 'visit', 'venezuela', 'in', 'the', 'near', 'future', '.']\n",
      "['former', 'president', 'of', 'the', 'united', 'states', ',', 'jimmy', 'carter', ',', 'has', 'come', 'out', 'in', 'support', 'of', 'chavez', \"'\", 's', 'promise', 'to', 'set', 'up', 'dial', '##og', 'tables', 'and', 'is', 'scheduled', 'to', 'visit', 'venezuela', 'in', 'the', 'near', 'future', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 62 in train.sent..\n",
      "We are going to give a voice to people that you dont want to hear .\n",
      "['we', 'are', 'going', 'to', 'give', 'a', 'voice', 'to', 'people', 'that', 'you', 'don', '##t', 'want', 'to', 'hear', '.']\n",
      "['we', 'are', 'going', 'to', 'give', 'a', 'voice', 'to', 'people', 'that', 'you', 'do', 'not', 'want', 'to', 'hear', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 64 in train.sent..\n",
      "The environmental organisation warned the delegates at the conference that the principles of the WTO would be rendered worthless unless the meeting extracted the commitment from the US on Kyoto Protocol .\n",
      "['the', 'environmental', 'organisation', 'warned', 'the', 'delegates', 'at', 'the', 'conference', 'that', 'the', 'principles', 'of', 'the', 'w', '##to', 'would', 'be', 'rendered', 'worthless', 'unless', 'the', 'meeting', 'extracted', 'the', 'commitment', 'from', 'the', 'us', 'on', 'kyoto', 'protocol', '.']\n",
      "['the', 'environmental', 'organization', 'warned', 'the', 'delegates', 'at', 'the', 'conference', 'that', 'the', 'principles', 'of', 'the', 'w', '##to', 'would', 'be', 'rendered', 'worthless', 'unless', 'the', 'meeting', 'extracted', 'the', 'commitment', 'from', 'the', 'us', 'on', 'kyoto', 'protocol', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 73 in train.sent..\n",
      "Parmentier hoped the Qatari authorities would honour their commitment to allow free access to the people of the country to the ship and vice versa .\n",
      "['par', '##ment', '##ier', 'hoped', 'the', 'qatar', '##i', 'authorities', 'would', 'honour', 'their', 'commitment', 'to', 'allow', 'free', 'access', 'to', 'the', 'people', 'of', 'the', 'country', 'to', 'the', 'ship', 'and', 'vice', 'versa', '.']\n",
      "['par', '##ment', '##ier', 'hoped', 'the', 'qatar', '##i', 'authorities', 'would', 'honor', 'their', 'commitment', 'to', 'allow', 'free', 'access', 'to', 'the', 'people', 'of', 'the', 'country', 'to', 'the', 'ship', 'and', 'vice', 'versa', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 91 in train.sent..\n",
      "Uighurs who want an independent state of East Turkestan and Tibetans associated with the Dalai Lama -- taking advantage of the international crisis .\n",
      "['ui', '##gh', '##urs', 'who', 'want', 'an', 'independent', 'state', 'of', 'east', 'turk', '##est', '##an', 'and', 'tibetan', '##s', 'associated', 'with', 'the', 'dalai', 'lama', '-', '-', 'taking', 'advantage', 'of', 'the', 'international', 'crisis', '.']\n",
      "['ui', '##gh', '##urs', 'who', 'want', 'an', 'independent', 'state', 'of', 'east', 'turk', '##est', '##an', 'and', 'tibetan', '##s', 'associated', 'with', 'the', 'dalai', 'lama', '-', 'taking', 'advantage', 'of', 'the', 'international', 'crisis', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 95 in train.sent..\n",
      "Speaking on behalf of the NGOs , human rights organisation , Hakam president Ramdas Tikamdas said the boycott was to protest the government 's poor response to Suhakam 's numerous recommendations thus far .\n",
      "['speaking', 'on', 'behalf', 'of', 'the', 'ngos', ',', 'human', 'rights', 'organisation', ',', 'ha', '##kam', 'president', 'ram', '##das', 'ti', '##kam', '##das', 'said', 'the', 'boycott', 'was', 'to', 'protest', 'the', 'government', \"'\", 's', 'poor', 'response', 'to', 'su', '##hak', '##am', \"'\", 's', 'numerous', 'recommendations', 'thus', 'far', '.']\n",
      "['speaking', 'on', 'behalf', 'of', 'the', 'ngos', ',', 'human', 'rights', 'organization', ',', 'ha', '##kam', 'president', 'ram', '##das', 'ti', '##kam', '##das', 'said', 'the', 'boycott', 'was', 'to', 'protest', 'the', 'government', \"'\", 's', 'poor', 'response', 'to', 'su', '##hak', '##am', \"'\", 's', 'numerous', 'recommendations', 'thus', 'far', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 97 in train.sent..\n",
      "\" Whereas the Kesas report , submitted after a public inquiry , earned the disdain and wrath of the Prime Minister ( Dr Mahathir Mohamad ) who summarily dismissed it as a product of `western biased ' , \" he said during a press conference at the Selangor Chinese Assembly Hall in Kuala Lumpur .\n",
      "['\"', 'whereas', 'the', 'ke', '##sas', 'report', ',', 'submitted', 'after', 'a', 'public', 'inquiry', ',', 'earned', 'the', 'disdain', 'and', 'wrath', 'of', 'the', 'prime', 'minister', '(', 'dr', 'maha', '##thi', '##r', 'mo', '##ham', '##ad', ')', 'who', 'sum', '##mar', '##ily', 'dismissed', 'it', 'as', 'a', 'product', 'of', '`', 'western', 'biased', \"'\", ',', '\"', 'he', 'said', 'during', 'a', 'press', 'conference', 'at', 'the', 'selangor', 'chinese', 'assembly', 'hall', 'in', 'kuala', 'lumpur', '.']\n",
      "['\"', 'whereas', 'the', 'ke', '##sas', 'report', ',', 'submitted', 'after', 'a', 'public', 'inquiry', ',', 'earned', 'the', 'disdain', 'and', 'wrath', 'of', 'the', 'prime', 'minister', '(', 'dr', 'maha', '##thi', '##r', 'mo', '##ham', '##ad', ')', 'who', 'sum', '##mar', '##ily', 'dismissed', 'it', 'as', 'a', 'product', 'of', \"'\", 'western', 'biased', \"'\", ',', '\"', 'he', 'said', 'during', 'a', 'press', 'conference', 'at', 'the', 'selangor', 'chinese', 'assembly', 'hall', 'in', 'kuala', 'lumpur', '.']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts not matching on line 99 in train.sent..\n",
      "The NGOs stressed the government has also failed to respect or recognise Suhakam 's recommendations and also lamented the decline of human rights in Malaysia .\n",
      "['the', 'ngos', 'stressed', 'the', 'government', 'has', 'also', 'failed', 'to', 'respect', 'or', 'recognise', 'su', '##hak', '##am', \"'\", 's', 'recommendations', 'and', 'also', 'lame', '##nted', 'the', 'decline', 'of', 'human', 'rights', 'in', 'malaysia', '.']\n",
      "['the', 'ngos', 'stressed', 'the', 'government', 'has', 'also', 'failed', 'to', 'respect', 'or', 'recognize', 'su', '##hak', '##am', \"'\", 's', 'recommendations', 'and', 'also', 'lame', '##nted', 'the', 'decline', 'of', 'human', 'rights', 'in', 'malaysia', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 113 in train.sent..\n",
      "And one other form of refreshment that we got , which really embarrassed my mother because she did n't know anything about this until she went with us to the movie one Saturday , there was a bakery next door to the movie theatre .\n",
      "['and', 'one', 'other', 'form', 'of', 'ref', '##resh', '##ment', 'that', 'we', 'got', ',', 'which', 'really', 'embarrassed', 'my', 'mother', 'because', 'she', 'did', 'n', \"'\", 't', 'know', 'anything', 'about', 'this', 'until', 'she', 'went', 'with', 'us', 'to', 'the', 'movie', 'one', 'saturday', ',', 'there', 'was', 'a', 'bakery', 'next', 'door', 'to', 'the', 'movie', 'theatre', '.']\n",
      "['and', 'one', 'other', 'form', 'of', 'ref', '##resh', '##ment', 'that', 'we', 'got', ',', 'which', 'really', 'embarrassed', 'my', 'mother', 'because', 'she', 'did', 'n', \"'\", 't', 'know', 'anything', 'about', 'this', 'until', 'she', 'went', 'with', 'us', 'to', 'the', 'movie', 'one', 'saturday', ',', 'there', 'was', 'a', 'bakery', 'next', 'door', 'to', 'the', 'movie', 'theater', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 139 in train.sent..\n",
      "JAMMU , Apr 2 -- Chief Minister Dr. Farooq Abdullah today accused Pakistan army for breeding terrorism in India to remain in power against the wishes of their people who want peace .\n",
      "['jammu', ',', 'apr', '2', '-', '-', 'chief', 'minister', 'dr', '.', 'far', '##oo', '##q', 'abdullah', 'today', 'accused', 'pakistan', 'army', 'for', 'breeding', 'terrorism', 'in', 'india', 'to', 'remain', 'in', 'power', 'against', 'the', 'wishes', 'of', 'their', 'people', 'who', 'want', 'peace', '.']\n",
      "['jammu', ',', 'apr', '2', '-', 'chief', 'minister', 'dr', '.', 'far', '##oo', '##q', 'abdullah', 'today', 'accused', 'pakistan', 'army', 'for', 'breeding', 'terrorism', 'in', 'india', 'to', 'remain', 'in', 'power', 'against', 'the', 'wishes', 'of', 'their', 'people', 'who', 'want', 'peace', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 140 in train.sent..\n",
      "' For their sustenance and survival , Pak generals have been throttling the voice of Pakistanis who wish to live in friendship and cordiality with their neighbours ' , the Chief Minister said while addressing a function organised by United Public High School at Channi Himat here this afternoon .\n",
      "[\"'\", 'for', 'their', 'su', '##sten', '##ance', 'and', 'survival', ',', 'pak', 'generals', 'have', 'been', 'th', '##rot', '##tling', 'the', 'voice', 'of', 'pakistani', '##s', 'who', 'wish', 'to', 'live', 'in', 'friendship', 'and', 'cord', '##ial', '##ity', 'with', 'their', 'neighbours', \"'\", ',', 'the', 'chief', 'minister', 'said', 'while', 'addressing', 'a', 'function', 'organised', 'by', 'united', 'public', 'high', 'school', 'at', 'chan', '##ni', 'him', '##at', 'here', 'this', 'afternoon', '.']\n",
      "[\"'\", 'for', 'their', 'su', '##sten', '##ance', 'and', 'survival', ',', 'pak', 'generals', 'have', 'been', 'th', '##rot', '##tling', 'the', 'voice', 'of', 'pakistani', '##s', 'who', 'wish', 'to', 'live', 'in', 'friendship', 'and', 'cord', '##ial', '##ity', 'with', 'their', 'neighbors', \"'\", ',', 'the', 'chief', 'minister', 'said', 'while', 'addressing', 'a', 'function', 'organized', 'by', 'united', 'public', 'high', 'school', 'at', 'chan', '##ni', 'him', '##at', 'here', 'this', 'afternoon', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 161 in train.sent..\n",
      "This is why one cannot dismiss the effects of the intensification of the Middle East crisis , Iraq 's initiative in using crude oil as a political weapon against Washington and the debate on an extensive oil embargo against the supporters of Israel on the events of the past few days in Venezuela as well as America 's support for the putschists there .\n",
      "['this', 'is', 'why', 'one', 'cannot', 'dismiss', 'the', 'effects', 'of', 'the', 'int', '##ens', '##ification', 'of', 'the', 'middle', 'east', 'crisis', ',', 'iraq', \"'\", 's', 'initiative', 'in', 'using', 'crude', 'oil', 'as', 'a', 'political', 'weapon', 'against', 'washington', 'and', 'the', 'debate', 'on', 'an', 'extensive', 'oil', 'em', '##bar', '##go', 'against', 'the', 'supporters', 'of', 'israel', 'on', 'the', 'events', 'of', 'the', 'past', 'few', 'days', 'in', 'venezuela', 'as', 'well', 'as', 'america', \"'\", 's', 'support', 'for', 'the', 'puts', '##chi', '##sts', 'there', '.']\n",
      "['this', 'is', 'why', 'one', 'can', 'not', 'dismiss', 'the', 'effects', 'of', 'the', 'int', '##ens', '##ification', 'of', 'the', 'middle', 'east', 'crisis', ',', 'iraq', \"'\", 's', 'initiative', 'in', 'using', 'crude', 'oil', 'as', 'a', 'political', 'weapon', 'against', 'washington', 'and', 'the', 'debate', 'on', 'an', 'extensive', 'oil', 'em', '##bar', '##go', 'against', 'the', 'supporters', 'of', 'israel', 'on', 'the', 'events', 'of', 'the', 'past', 'few', 'days', 'in', 'venezuela', 'as', 'well', 'as', 'america', \"'\", 's', 'support', 'for', 'the', 'puts', '##chi', '##sts', 'there', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 205 in train.sent..\n",
      "Afghanistan is now under US bombardment for refusing to hand over the chief suspect in the Sept. 11 attacks on New York and Washington , Saudi-born dissident Osama bin Laden [ Usama Bin Ladin ] .\n",
      "['afghanistan', 'is', 'now', 'under', 'us', 'bombardment', 'for', 'refusing', 'to', 'hand', 'over', 'the', 'chief', 'suspect', 'in', 'the', 'sept', '.', '11', 'attacks', 'on', 'new', 'york', 'and', 'washington', ',', 'saudi', '-', 'born', 'di', '##ssi', '##dent', 'os', '##ama', 'bin', 'laden', '[', 'usa', '##ma', 'bin', 'lad', '##in', ']', '.']\n",
      "['afghanistan', 'is', 'now', 'under', 'us', 'bombardment', 'for', 'refusing', 'to', 'hand', 'over', 'the', 'chief', 'suspect', 'in', 'the', 'september', '11', 'attacks', 'on', 'new', 'york', 'and', 'washington', ',', 'saudi', '-', 'born', 'di', '##ssi', '##dent', 'os', '##ama', 'bin', 'laden', '[', 'usa', '##ma', 'bin', 'lad', '##in', ']', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 215 in train.sent..\n",
      "If the Supreme Court rules in favour of Mr Tsvangirai , who if convicted on the charges might face life imprisonment , the Attorney General 's Office will have to draw up a new charge .\n",
      "['if', 'the', 'supreme', 'court', 'rules', 'in', 'favour', 'of', 'mr', 'ts', '##van', '##gi', '##rai', ',', 'who', 'if', 'convicted', 'on', 'the', 'charges', 'might', 'face', 'life', 'imprisonment', ',', 'the', 'attorney', 'general', \"'\", 's', 'office', 'will', 'have', 'to', 'draw', 'up', 'a', 'new', 'charge', '.']\n",
      "['if', 'the', 'supreme', 'court', 'rules', 'in', 'favor', 'of', 'mr', 'ts', '##van', '##gi', '##rai', ',', 'who', 'if', 'convicted', 'on', 'the', 'charges', 'might', 'face', 'life', 'imprisonment', ',', 'the', 'attorney', 'general', \"'\", 's', 'office', 'will', 'have', 'to', 'draw', 'up', 'a', 'new', 'charge', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 225 in train.sent..\n",
      "Nairobi , March 13 ( XINHUA ) -- Zimbabwean President Robert Mugabe 's reelection has been praised by the Organization of African Unity ( OAU ) , African countries , but condemned by some western countries .\n",
      "['nairobi', ',', 'march', '13', '(', 'xi', '##nh', '##ua', ')', '-', '-', 'zimbabwe', '##an', 'president', 'robert', 'mug', '##abe', \"'\", 's', 'reelection', 'has', 'been', 'praised', 'by', 'the', 'organization', 'of', 'african', 'unity', '(', 'o', '##au', ')', ',', 'african', 'countries', ',', 'but', 'condemned', 'by', 'some', 'western', 'countries', '.']\n",
      "['nairobi', ',', 'march', '13', '(', 'xi', '##nh', '##ua', ')', '-', 'zimbabwe', '##an', 'president', 'robert', 'mug', '##abe', \"'\", 's', 'reelection', 'has', 'been', 'praised', 'by', 'the', 'organization', 'of', 'african', 'unity', '(', 'o', '##au', ')', ',', 'african', 'countries', ',', 'but', 'condemned', 'by', 'some', 'western', 'countries', '.']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts not matching on line 237 in train.sent..\n",
      "He said those countries and nations which are independant in real sense of the world and do not take dictation from the US or accepts its supremacy are labelled as human rights violators .\n",
      "['he', 'said', 'those', 'countries', 'and', 'nations', 'which', 'are', 'ind', '##ep', '##end', '##ant', 'in', 'real', 'sense', 'of', 'the', 'world', 'and', 'do', 'not', 'take', 'di', '##cta', '##tion', 'from', 'the', 'us', 'or', 'accepts', 'its', 'supremacy', 'are', 'labelled', 'as', 'human', 'rights', 'viola', '##tors', '.']\n",
      "['he', 'said', 'those', 'countries', 'and', 'nations', 'which', 'are', 'ind', '##ep', '##end', '##ant', 'in', 'real', 'sense', 'of', 'the', 'world', 'and', 'do', 'not', 'take', 'di', '##cta', '##tion', 'from', 'the', 'us', 'or', 'accepts', 'its', 'supremacy', 'are', 'labeled', 'as', 'human', 'rights', 'viola', '##tors', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 257 in train.sent..\n",
      "BUENOS AIRES -- Foreign multinational companies trying to avoid billions in losses furiously lobbied Argentine lawmakers and the new government ahead of today 's final vote on emergency legislation to devalue the peso and end the country 's decade- old currency parity with the U.S. dollar .\n",
      "['buenos', 'aires', '-', '-', 'foreign', 'multinational', 'companies', 'trying', 'to', 'avoid', 'billions', 'in', 'losses', 'furiously', 'lobbied', 'argentine', 'law', '##makers', 'and', 'the', 'new', 'government', 'ahead', 'of', 'today', \"'\", 's', 'final', 'vote', 'on', 'emergency', 'legislation', 'to', 'dev', '##al', '##ue', 'the', 'pe', '##so', 'and', 'end', 'the', 'country', \"'\", 's', 'decade', '-', 'old', 'currency', 'par', '##ity', 'with', 'the', 'u', '.', 's', '.', 'dollar', '.']\n",
      "['buenos', 'aires', '-', 'foreign', 'multinational', 'companies', 'trying', 'to', 'avoid', 'billions', 'in', 'losses', 'furiously', 'lobbied', 'argentine', 'law', '##makers', 'and', 'the', 'new', 'government', 'ahead', 'of', 'today', \"'\", 's', 'final', 'vote', 'on', 'emergency', 'legislation', 'to', 'dev', '##al', '##ue', 'the', 'pe', '##so', 'and', 'end', 'the', 'country', \"'\", 's', 'decade', '-', 'old', 'currency', 'par', '##ity', 'with', 'the', 'u', '.', 's', '.', 'dollar', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 260 in train.sent..\n",
      "Amadeo said the president told him , ` `I have never had so many calls in my life from all the groups saying they do n't want us to touch them . ''\n",
      "['ama', '##de', '##o', 'said', 'the', 'president', 'told', 'him', ',', '`', '`', 'i', 'have', 'never', 'had', 'so', 'many', 'calls', 'in', 'my', 'life', 'from', 'all', 'the', 'groups', 'saying', 'they', 'do', 'n', \"'\", 't', 'want', 'us', 'to', 'touch', 'them', '.', \"'\", \"'\"]\n",
      "['ama', '##de', '##o', 'said', 'the', 'president', 'told', 'him', ',', \"'\", \"'\", 'i', 'have', 'never', 'had', 'so', 'many', 'calls', 'in', 'my', 'life', 'from', 'all', 'the', 'groups', 'saying', 'they', 'do', 'n', \"'\", 't', 'want', 'us', 'to', 'touch', 'them', '.', '\"']\n",
      "\n",
      "\n",
      "Counts not matching on line 264 in train.sent..\n",
      "His package of legislation seeks -- at the expense of foreign and domestic companies -- to ease the pain on an increasingly angry middle class , the largest in South America .\n",
      "['his', 'package', 'of', 'legislation', 'seeks', '-', '-', 'at', 'the', 'expense', 'of', 'foreign', 'and', 'domestic', 'companies', '-', '-', 'to', 'ease', 'the', 'pain', 'on', 'an', 'increasingly', 'angry', 'middle', 'class', ',', 'the', 'largest', 'in', 'south', 'america', '.']\n",
      "['his', 'package', 'of', 'legislation', 'seeks', '-', 'at', 'the', 'expense', 'of', 'foreign', 'and', 'domestic', 'companies', '-', 'to', 'ease', 'the', 'pain', 'on', 'an', 'increasingly', 'angry', 'middle', 'class', ',', 'the', 'largest', 'in', 'south', 'america', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 268 in train.sent..\n",
      "Foreign companies that took over former state transportation , phone and energy companies want -- but appear unlikely to get -- some form of indexing so they can raise their prices to compensate for what is expected to be a widening gap between the peso and dollar .\n",
      "['foreign', 'companies', 'that', 'took', 'over', 'former', 'state', 'transportation', ',', 'phone', 'and', 'energy', 'companies', 'want', '-', '-', 'but', 'appear', 'unlikely', 'to', 'get', '-', '-', 'some', 'form', 'of', 'index', '##ing', 'so', 'they', 'can', 'raise', 'their', 'prices', 'to', 'compensate', 'for', 'what', 'is', 'expected', 'to', 'be', 'a', 'widening', 'gap', 'between', 'the', 'pe', '##so', 'and', 'dollar', '.']\n",
      "['foreign', 'companies', 'that', 'took', 'over', 'former', 'state', 'transportation', ',', 'phone', 'and', 'energy', 'companies', 'want', '-', 'but', 'appear', 'unlikely', 'to', 'get', '-', 'some', 'form', 'of', 'index', '##ing', 'so', 'they', 'can', 'raise', 'their', 'prices', 'to', 'compensate', 'for', 'what', 'is', 'expected', 'to', 'be', 'a', 'widening', 'gap', 'between', 'the', 'pe', '##so', 'and', 'dollar', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 269 in train.sent..\n",
      "Moscow , May 8 , IRNA -- Deputy head of the Russian Geopolitical Research Institute Lyonid Ivashev said on Wednesday the United States sees part of an axis of evil any country which does not follow the its policies .\n",
      "['moscow', ',', 'may', '8', ',', 'ir', '##na', '-', '-', 'deputy', 'head', 'of', 'the', 'russian', 'geo', '##pol', '##itical', 'research', 'institute', 'lyon', '##id', 'iv', '##ash', '##ev', 'said', 'on', 'wednesday', 'the', 'united', 'states', 'sees', 'part', 'of', 'an', 'axis', 'of', 'evil', 'any', 'country', 'which', 'does', 'not', 'follow', 'the', 'its', 'policies', '.']\n",
      "['moscow', ',', 'may', '8', ',', 'ir', '##na', '-', 'deputy', 'head', 'of', 'the', 'russian', 'geo', '##pol', '##itical', 'research', 'institute', 'lyon', '##id', 'iv', '##ash', '##ev', 'said', 'on', 'wednesday', 'the', 'united', 'states', 'sees', 'part', 'of', 'an', 'axis', 'of', 'evil', 'any', 'country', 'which', 'does', 'not', 'follow', 'the', 'its', 'policies', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 285 in train.sent..\n",
      "GATUNA , Rwanda , July 6 ( AFP ) - President Paul Kagame of Rwanda and his Ugandan counterpart Yoweri Museveni began talks here Friday in a bid to mend soured relations between their neighbouring countries .\n",
      "['ga', '##tu', '##na', ',', 'rwanda', ',', 'july', '6', '(', 'af', '##p', ')', '-', 'president', 'paul', 'ka', '##game', 'of', 'rwanda', 'and', 'his', 'uganda', '##n', 'counterpart', 'yo', '##wer', '##i', 'muse', '##ven', '##i', 'began', 'talks', 'here', 'friday', 'in', 'a', 'bid', 'to', 'men', '##d', 'sour', '##ed', 'relations', 'between', 'their', 'neighbouring', 'countries', '.']\n",
      "['ga', '##tu', '##na', ',', 'rwanda', ',', 'july', '6', '(', 'af', '##p', ')', '-', 'president', 'paul', 'ka', '##game', 'of', 'rwanda', 'and', 'his', 'uganda', '##n', 'counterpart', 'yo', '##wer', '##i', 'muse', '##ven', '##i', 'began', 'talks', 'here', 'friday', 'in', 'a', 'bid', 'to', 'men', '##d', 'sour', '##ed', 'relations', 'between', 'their', 'neighboring', 'countries', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 286 in train.sent..\n",
      "The formerly close allies fell out in 1999 , the year after each sent troops to back rebel movements in the neighbouring Democratic Republic of Congo , when mounting rivalry lead to violent clashes between their own armies there .\n",
      "['the', 'formerly', 'close', 'allies', 'fell', 'out', 'in', '1999', ',', 'the', 'year', 'after', 'each', 'sent', 'troops', 'to', 'back', 'rebel', 'movements', 'in', 'the', 'neighbouring', 'democratic', 'republic', 'of', 'congo', ',', 'when', 'mounting', 'rivalry', 'lead', 'to', 'violent', 'clashes', 'between', 'their', 'own', 'armies', 'there', '.']\n",
      "['the', 'formerly', 'close', 'allies', 'fell', 'out', 'in', '1999', ',', 'the', 'year', 'after', 'each', 'sent', 'troops', 'to', 'back', 'rebel', 'movements', 'in', 'the', 'neighboring', 'democratic', 'republic', 'of', 'congo', ',', 'when', 'mounting', 'rivalry', 'lead', 'to', 'violent', 'clashes', 'between', 'their', 'own', 'armies', 'there', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 310 in train.sent..\n",
      "But instead , he says with surprise , ` ` They all want to speak with me .\n",
      "['but', 'instead', ',', 'he', 'says', 'with', 'surprise', ',', '`', '`', 'they', 'all', 'want', 'to', 'speak', 'with', 'me', '.']\n",
      "['but', 'instead', ',', 'he', 'says', 'with', 'surprise', ',', \"'\", \"'\", 'they', 'all', 'want', 'to', 'speak', 'with', 'me', '.']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts not matching on line 311 in train.sent..\n",
      "` ` If they do n't trust me with their needs , they do n't get it , '' he says , with a sigh .\n",
      "['`', '`', 'if', 'they', 'do', 'n', \"'\", 't', 'trust', 'me', 'with', 'their', 'needs', ',', 'they', 'do', 'n', \"'\", 't', 'get', 'it', ',', \"'\", \"'\", 'he', 'says', ',', 'with', 'a', 'sigh', '.']\n",
      "[\"'\", \"'\", 'if', 'they', 'do', 'n', \"'\", 't', 'trust', 'me', 'with', 'their', 'needs', ',', 'they', 'do', 'n', \"'\", 't', 'get', 'it', ',', '\"', 'he', 'says', ',', 'with', 'a', 'sigh', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 312 in train.sent..\n",
      "`` I wish I had more time . ''\n",
      "['`', '`', 'i', 'wish', 'i', 'had', 'more', 'time', '.', \"'\", \"'\"]\n",
      "[\"'\", \"'\", 'i', 'wish', 'i', 'had', 'more', 'time', '.', '\"']\n",
      "\n",
      "\n",
      "Counts not matching on line 313 in train.sent..\n",
      "Issues to deal with Iraq , Iran , and North Korea -- which the US President branded as the \" axis of evil \" in his statement to fight against international terrorism -- and activation of the Japanese economy were the major topics of discussion at the Japan - US summit talks held on 18 February between Prime Minister Junichiro Koizumi and US President George W. Bush .\n",
      "['issues', 'to', 'deal', 'with', 'iraq', ',', 'iran', ',', 'and', 'north', 'korea', '-', '-', 'which', 'the', 'us', 'president', 'branded', 'as', 'the', '\"', 'axis', 'of', 'evil', '\"', 'in', 'his', 'statement', 'to', 'fight', 'against', 'international', 'terrorism', '-', '-', 'and', 'activation', 'of', 'the', 'japanese', 'economy', 'were', 'the', 'major', 'topics', 'of', 'discussion', 'at', 'the', 'japan', '-', 'us', 'summit', 'talks', 'held', 'on', '18', 'february', 'between', 'prime', 'minister', 'jun', '##ichi', '##ro', 'ko', '##iz', '##umi', 'and', 'us', 'president', 'george', 'w', '.', 'bush', '.']\n",
      "['issues', 'to', 'deal', 'with', 'iraq', ',', 'iran', ',', 'and', 'north', 'korea', '-', 'which', 'the', 'us', 'president', 'branded', 'as', 'the', '\"', 'axis', 'of', 'evil', '\"', 'in', 'his', 'statement', 'to', 'fight', 'against', 'international', 'terrorism', '-', 'and', 'activation', 'of', 'the', 'japanese', 'economy', 'were', 'the', 'major', 'topics', 'of', 'discussion', 'at', 'the', 'japan', '-', 'us', 'summit', 'talks', 'held', 'on', '18', 'february', 'between', 'prime', 'minister', 'jun', '##ichi', '##ro', 'ko', '##iz', '##umi', 'and', 'us', 'president', 'george', 'w', '.', 'bush', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 321 in train.sent..\n",
      "Bay continues to fill with Muslim militants who had sworn to die rather than be captured , even the little we see of their situation makes it clear they 're in hell .\n",
      "['bay', 'continues', 'to', 'fill', 'with', 'muslim', 'militants', 'who', 'had', 'sworn', 'to', 'die', 'rather', 'than', 'be', 'captured', ',', 'even', 'the', 'little', 'we', 'see', 'of', 'their', 'situation', 'makes', 'it', 'clear', 'they', \"'\", 're', 'in', 'hell', '.']\n",
      "['bay', 'continues', 'to', 'fill', 'with', 'muslim', 'militants', 'who', 'had', 'sworn', 'to', 'die', 'rather', 'than', 'be', 'captured', ',', 'even', 'the', 'little', 'we', 'see', 'of', 'their', 'situation', 'makes', 'it', 'clear', 'they', 'are', 'in', 'hell', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 327 in train.sent..\n",
      "So he is unlikely to have been enamoured of statues .\n",
      "['so', 'he', 'is', 'unlikely', 'to', 'have', 'been', 'en', '##amo', '##ured', 'of', 'statues', '.']\n",
      "['so', 'he', 'is', 'unlikely', 'to', 'have', 'been', 'en', '##amo', '##red', 'of', 'statues', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 343 in train.sent..\n",
      "Space station commander Frank Culbertson had eagerly awaited the arrival of Endeavour , his ride home .\n",
      "['space', 'station', 'commander', 'frank', 'cu', '##lbert', '##son', 'had', 'eagerly', 'awaited', 'the', 'arrival', 'of', 'endeavour', ',', 'his', 'ride', 'home', '.']\n",
      "['space', 'station', 'commander', 'frank', 'cu', '##lbert', '##son', 'had', 'eagerly', 'awaited', 'the', 'arrival', 'of', 'endeavor', ',', 'his', 'ride', 'home', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 344 in train.sent..\n",
      "` ` We 're ready to see you guys , '' Culbertson radioed once Endeavour pulled within 1 1/2 miles .\n",
      "['`', '`', 'we', \"'\", 're', 'ready', 'to', 'see', 'you', 'guys', ',', \"'\", \"'\", 'cu', '##lbert', '##son', 'radio', '##ed', 'once', 'endeavour', 'pulled', 'within', '1', '1', '/', '2', 'miles', '.']\n",
      "[\"'\", \"'\", 'we', 'are', 'ready', 'to', 'see', 'you', 'guys', ',', '\"', 'cu', '##lbert', '##son', 'radio', '##ed', 'once', 'endeavor', 'pulled', 'within', '1', '1', '/', '2', 'miles', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 346 in train.sent..\n",
      "Authorities are only too aware that Kashgar is 4,000 kilometres ( 2,500 miles ) from Beijing but only a tenth of the distance from the Pakistani border , and are desperate to ensure instability or militancy does not leak over the frontiers .\n",
      "['authorities', 'are', 'only', 'too', 'aware', 'that', 'ka', '##sh', '##gar', 'is', '4', ',', '000', 'kilometres', '(', '2', ',', '500', 'miles', ')', 'from', 'beijing', 'but', 'only', 'a', 'tenth', 'of', 'the', 'distance', 'from', 'the', 'pakistani', 'border', ',', 'and', 'are', 'desperate', 'to', 'ensure', 'instability', 'or', 'mil', '##itan', '##cy', 'does', 'not', 'leak', 'over', 'the', 'frontiers', '.']\n",
      "['authorities', 'are', 'only', 'too', 'aware', 'that', 'ka', '##sh', '##gar', 'is', '4', ',', '000', 'kilometers', '(', '2', ',', '500', 'miles', ')', 'from', 'beijing', 'but', 'only', 'a', 'tenth', 'of', 'the', 'distance', 'from', 'the', 'pakistani', 'border', ',', 'and', 'are', 'desperate', 'to', 'ensure', 'instability', 'or', 'mil', '##itan', '##cy', 'does', 'not', 'leak', 'over', 'the', 'frontiers', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 379 in train.sent..\n",
      "In 1992 , Jordan signed the UN Climate Change Convention that compels nations to curb global warming , which is blamed on gases produced by factories and cars that burn fuel .\n",
      "['in', '1992', ',', 'jordan', 'signed', 'the', 'un', 'climate', 'change', 'convention', 'that', 'com', '##pel', '##s', 'nations', 'to', 'curb', 'global', 'warming', ',', 'which', 'is', 'blamed', 'on', 'gases', 'produced', 'by', 'factories', 'and', 'cars', 'that', 'burn', 'fuel', '.']\n",
      "['in', '1992', ',', 'jordan', 'signed', 'the', 'un', 'climate', 'change', 'convention', 'that', 'com', '##pel', '##s', 'nations', 'to', 'curb', 'global', 'warming', ',', 'which', 'is', 'blamed', 'on', 'gas', '##ses', 'produced', 'by', 'factories', 'and', 'cars', 'that', 'burn', 'fuel', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 388 in train.sent..\n",
      "well i have n't really really gotten that far with it um i've always sort of liked General Motors a little bit better than some of the others but uh\n",
      "['well', 'i', 'have', 'n', \"'\", 't', 'really', 'really', 'gotten', 'that', 'far', 'with', 'it', 'um', 'i', \"'\", 've', 'always', 'sort', 'of', 'liked', 'general', 'motors', 'a', 'little', 'bit', 'better', 'than', 'some', 'of', 'the', 'others', 'but', 'uh']\n",
      "['well', 'i', 'have', 'n', \"'\", 't', 'really', 'really', 'gotten', 'that', 'far', 'with', 'it', 'um', 'i', 'have', 'always', 'sort', 'of', 'liked', 'general', 'motors', 'a', 'little', 'bit', 'better', 'than', 'some', 'of', 'the', 'others', 'but', 'uh']\n",
      "\n",
      "\n",
      "Counts not matching on line 389 in train.sent..\n",
      "how come i've been kind of um i guess the commercials are getting to me the Toyota commercials and i know that a lot of people i've i've known that have had Toyotas have been just extremely happy with them that hardly had any problems at all\n",
      "['how', 'come', 'i', \"'\", 've', 'been', 'kind', 'of', 'um', 'i', 'guess', 'the', 'commercials', 'are', 'getting', 'to', 'me', 'the', 'toyota', 'commercials', 'and', 'i', 'know', 'that', 'a', 'lot', 'of', 'people', 'i', \"'\", 've', 'i', \"'\", 've', 'known', 'that', 'have', 'had', 'toyota', '##s', 'have', 'been', 'just', 'extremely', 'happy', 'with', 'them', 'that', 'hardly', 'had', 'any', 'problems', 'at', 'all']\n",
      "['how', 'come', 'i', 'have', 'been', 'kind', 'of', 'um', 'i', 'guess', 'the', 'commercials', 'are', 'getting', 'to', 'me', 'the', 'toyota', 'commercials', 'and', 'i', 'know', 'that', 'a', 'lot', 'of', 'people', 'i', 'have', 'i', 'have', 'known', 'that', 'have', 'had', 'toyota', '##s', 'have', 'been', 'just', 'extremely', 'happy', 'with', 'them', 'that', 'hardly', 'had', 'any', 'problems', 'at', 'all']\n",
      "\n",
      "\n",
      "Counts not matching on line 390 in train.sent..\n",
      "so i do n't know i'm i'm not ready to buy a new car yet but i do n't know if if the next time i'm going to try to to stay with buying something American or if i'm going to go for a little more what i would consider to be a long-term investment\n",
      "['so', 'i', 'do', 'n', \"'\", 't', 'know', 'i', \"'\", 'm', 'i', \"'\", 'm', 'not', 'ready', 'to', 'buy', 'a', 'new', 'car', 'yet', 'but', 'i', 'do', 'n', \"'\", 't', 'know', 'if', 'if', 'the', 'next', 'time', 'i', \"'\", 'm', 'going', 'to', 'try', 'to', 'to', 'stay', 'with', 'buying', 'something', 'american', 'or', 'if', 'i', \"'\", 'm', 'going', 'to', 'go', 'for', 'a', 'little', 'more', 'what', 'i', 'would', 'consider', 'to', 'be', 'a', 'long', '-', 'term', 'investment']\n",
      "['so', 'i', 'do', 'n', \"'\", 't', 'know', 'i', 'am', 'i', 'am', 'not', 'ready', 'to', 'buy', 'a', 'new', 'car', 'yet', 'but', 'i', 'do', 'n', \"'\", 't', 'know', 'if', 'if', 'the', 'next', 'time', 'i', 'am', 'going', 'to', 'try', 'to', 'to', 'stay', 'with', 'buying', 'something', 'american', 'or', 'if', 'i', 'am', 'going', 'to', 'go', 'for', 'a', 'little', 'more', 'what', 'i', 'would', 'consider', 'to', 'be', 'a', 'long', '-', 'term', 'investment']\n",
      "\n",
      "\n",
      "Counts not matching on line 392 in train.sent..\n",
      "Tehran , April 20 , IRNA -- President Mohammad Khatami on Friday evening congratulated the Venezuelan government and nation for the victory and restoration of the legitimate government of President Hugo Chavez after a failed military coup in that country .\n",
      "['tehran', ',', 'april', '20', ',', 'ir', '##na', '-', '-', 'president', 'mohammad', 'k', '##hat', '##ami', 'on', 'friday', 'evening', 'cong', '##rat', '##ulated', 'the', 'venezuelan', 'government', 'and', 'nation', 'for', 'the', 'victory', 'and', 'restoration', 'of', 'the', 'legitimate', 'government', 'of', 'president', 'hugo', 'chavez', 'after', 'a', 'failed', 'military', 'coup', 'in', 'that', 'country', '.']\n",
      "['tehran', ',', 'april', '20', ',', 'ir', '##na', '-', 'president', 'mohammad', 'k', '##hat', '##ami', 'on', 'friday', 'evening', 'cong', '##rat', '##ulated', 'the', 'venezuelan', 'government', 'and', 'nation', 'for', 'the', 'victory', 'and', 'restoration', 'of', 'the', 'legitimate', 'government', 'of', 'president', 'hugo', 'chavez', 'after', 'a', 'failed', 'military', 'coup', 'in', 'that', 'country', '.']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts not matching on line 402 in train.sent..\n",
      "They will then score one point for every subsequent issue or broadcast or Internet posting after the first offense is noted by Chatterbox if they continue not to report said inconvenient fact -- and an additional two points on days when the news organization runs a follow - up without making note of said inconvenient fact .\n",
      "['they', 'will', 'then', 'score', 'one', 'point', 'for', 'every', 'subsequent', 'issue', 'or', 'broadcast', 'or', 'internet', 'posting', 'after', 'the', 'first', 'offense', 'is', 'noted', 'by', 'chatter', '##box', 'if', 'they', 'continue', 'not', 'to', 'report', 'said', 'inc', '##on', '##ven', '##ient', 'fact', '-', '-', 'and', 'an', 'additional', 'two', 'points', 'on', 'days', 'when', 'the', 'news', 'organization', 'runs', 'a', 'follow', '-', 'up', 'without', 'making', 'note', 'of', 'said', 'inc', '##on', '##ven', '##ient', 'fact', '.']\n",
      "['they', 'will', 'then', 'score', 'one', 'point', 'for', 'every', 'subsequent', 'issue', 'or', 'broadcast', 'or', 'internet', 'posting', 'after', 'the', 'first', 'offense', 'is', 'noted', 'by', 'chatter', '##box', 'if', 'they', 'continue', 'not', 'to', 'report', 'said', 'inc', '##on', '##ven', '##ient', 'fact', '-', 'and', 'an', 'additional', 'two', 'points', 'on', 'days', 'when', 'the', 'news', 'organization', 'runs', 'a', 'follow', '-', 'up', 'without', 'making', 'note', 'of', 'said', 'inc', '##on', '##ven', '##ient', 'fact', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 415 in train.sent..\n",
      "Before the Sept. 11 terrorist attacks in the United States , the Bush administration had been severely blamed in the international community for rejecting the Kyoto Protocol .\n",
      "['before', 'the', 'sept', '.', '11', 'terrorist', 'attacks', 'in', 'the', 'united', 'states', ',', 'the', 'bush', 'administration', 'had', 'been', 'severely', 'blamed', 'in', 'the', 'international', 'community', 'for', 'rejecting', 'the', 'kyoto', 'protocol', '.']\n",
      "['before', 'the', 'september', '11', 'terrorist', 'attacks', 'in', 'the', 'united', 'states', ',', 'the', 'bush', 'administration', 'had', 'been', 'severely', 'blamed', 'in', 'the', 'international', 'community', 'for', 'rejecting', 'the', 'kyoto', 'protocol', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 417 in train.sent..\n",
      "WASHINGTON : Unprecedented scepticism and scorn accompanied the release by the United States on Monday of its annual human rights report amid charges of hypocrisy and double standards arising from the ongoing war on terrorism .\n",
      "['washington', ':', 'unprecedented', 'sc', '##ept', '##ici', '##sm', 'and', 'sc', '##orn', 'accompanied', 'the', 'release', 'by', 'the', 'united', 'states', 'on', 'monday', 'of', 'its', 'annual', 'human', 'rights', 'report', 'amid', 'charges', 'of', 'h', '##yp', '##oc', '##ris', '##y', 'and', 'double', 'standards', 'arising', 'from', 'the', 'ongoing', 'war', 'on', 'terrorism', '.']\n",
      "['washington', ':', 'unprecedented', 'skepticism', 'and', 'sc', '##orn', 'accompanied', 'the', 'release', 'by', 'the', 'united', 'states', 'on', 'monday', 'of', 'its', 'annual', 'human', 'rights', 'report', 'amid', 'charges', 'of', 'h', '##yp', '##oc', '##ris', '##y', 'and', 'double', 'standards', 'arising', 'from', 'the', 'ongoing', 'war', 'on', 'terrorism', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 419 in train.sent..\n",
      "Amid widespread domestic criticism over curtailment of civil liberties , US officials laboured to convince a disbelieving press corps that the exercise was evenhanded .\n",
      "['amid', 'widespread', 'domestic', 'criticism', 'over', 'curt', '##ail', '##ment', 'of', 'civil', 'liberties', ',', 'us', 'officials', 'labour', '##ed', 'to', 'convince', 'a', 'di', '##sb', '##eli', '##eving', 'press', 'corps', 'that', 'the', 'exercise', 'was', 'even', '##hand', '##ed', '.']\n",
      "['amid', 'widespread', 'domestic', 'criticism', 'over', 'curt', '##ail', '##ment', 'of', 'civil', 'liberties', ',', 'us', 'officials', 'labor', '##ed', 'to', 'convince', 'a', 'di', '##sb', '##eli', '##eving', 'press', 'corps', 'that', 'the', 'exercise', 'was', 'even', '##hand', '##ed', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 422 in train.sent..\n",
      "Critics in the media sharply questioned such duplicity at Monday 's briefing as Lorne Cramer , US Assistant Secretary for Democracy , Human Rights , and Labour , struggled to defend American policy .\n",
      "['critics', 'in', 'the', 'media', 'sharply', 'questioned', 'such', 'du', '##plicity', 'at', 'monday', \"'\", 's', 'briefing', 'as', 'lo', '##rne', 'cramer', ',', 'us', 'assistant', 'secretary', 'for', 'democracy', ',', 'human', 'rights', ',', 'and', 'labour', ',', 'struggled', 'to', 'defend', 'american', 'policy', '.']\n",
      "['critics', 'in', 'the', 'media', 'sharply', 'questioned', 'such', 'du', '##plicity', 'at', 'monday', \"'\", 's', 'briefing', 'as', 'lo', '##rne', 'cramer', ',', 'us', 'assistant', 'secretary', 'for', 'democracy', ',', 'human', 'rights', ',', 'and', 'labor', ',', 'struggled', 'to', 'defend', 'american', 'policy', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 426 in train.sent..\n",
      "I hope you 're gong to see more of an effect from this administration .\n",
      "['i', 'hope', 'you', \"'\", 're', 'gong', 'to', 'see', 'more', 'of', 'an', 'effect', 'from', 'this', 'administration', '.']\n",
      "['i', 'hope', 'you', 'are', 'gong', 'to', 'see', 'more', 'of', 'an', 'effect', 'from', 'this', 'administration', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 440 in train.sent..\n",
      "But he let slip the opportunities to turn back , because the forces that drive him -- his desire to affect change , his sense of duty to his peers and his ambition -- would not permit him to pass up the biggest chance of his political life .\n",
      "['but', 'he', 'let', 'slip', 'the', 'opportunities', 'to', 'turn', 'back', ',', 'because', 'the', 'forces', 'that', 'drive', 'him', '-', '-', 'his', 'desire', 'to', 'affect', 'change', ',', 'his', 'sense', 'of', 'duty', 'to', 'his', 'peers', 'and', 'his', 'ambition', '-', '-', 'would', 'not', 'permit', 'him', 'to', 'pass', 'up', 'the', 'biggest', 'chance', 'of', 'his', 'political', 'life', '.']\n",
      "['but', 'he', 'let', 'slip', 'the', 'opportunities', 'to', 'turn', 'back', ',', 'because', 'the', 'forces', 'that', 'drive', 'him', '-', 'his', 'desire', 'to', 'affect', 'change', ',', 'his', 'sense', 'of', 'duty', 'to', 'his', 'peers', 'and', 'his', 'ambition', '-', 'would', 'not', 'permit', 'him', 'to', 'pass', 'up', 'the', 'biggest', 'chance', 'of', 'his', 'political', 'life', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 446 in train.sent..\n",
      "Nonetheless , he will be made to realize that he cannot command the CDU , that his power base lies in Munich and not in Berlin , and that the invitation of kingmakers to accept the crown comes at a cost .\n",
      "['nonetheless', ',', 'he', 'will', 'be', 'made', 'to', 'realize', 'that', 'he', 'cannot', 'command', 'the', 'cd', '##u', ',', 'that', 'his', 'power', 'base', 'lies', 'in', 'munich', 'and', 'not', 'in', 'berlin', ',', 'and', 'that', 'the', 'invitation', 'of', 'king', '##makers', 'to', 'accept', 'the', 'crown', 'comes', 'at', 'a', 'cost', '.']\n",
      "['nonetheless', ',', 'he', 'will', 'be', 'made', 'to', 'realize', 'that', 'he', 'can', 'not', 'command', 'the', 'cd', '##u', ',', 'that', 'his', 'power', 'base', 'lies', 'in', 'munich', 'and', 'not', 'in', 'berlin', ',', 'and', 'that', 'the', 'invitation', 'of', 'king', '##makers', 'to', 'accept', 'the', 'crown', 'comes', 'at', 'a', 'cost', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 460 in train.sent..\n",
      "President Chavez himself now boasts of having spent 20 years conspiring -- that is , eroding the armed forces ' loyalty -- to achieve his goal of conquering power .\n",
      "['president', 'chavez', 'himself', 'now', 'boasts', 'of', 'having', 'spent', '20', 'years', 'con', '##sp', '##iring', '-', '-', 'that', 'is', ',', 'er', '##od', '##ing', 'the', 'armed', 'forces', \"'\", 'loyalty', '-', '-', 'to', 'achieve', 'his', 'goal', 'of', 'conquer', '##ing', 'power', '.']\n",
      "['president', 'chavez', 'himself', 'now', 'boasts', 'of', 'having', 'spent', '20', 'years', 'con', '##sp', '##iring', '-', 'that', 'is', ',', 'er', '##od', '##ing', 'the', 'armed', 'forces', \"'\", 'loyalty', '-', 'to', 'achieve', 'his', 'goal', 'of', 'conquer', '##ing', 'power', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 468 in train.sent..\n",
      "The young president 's father Laurent , assassinated in January , had sidelined Masire after accusing him of being biased in favour of the rebels .\n",
      "['the', 'young', 'president', \"'\", 's', 'father', 'laurent', ',', 'assassinated', 'in', 'january', ',', 'had', 'side', '##lined', 'mas', '##ire', 'after', 'accusing', 'him', 'of', 'being', 'biased', 'in', 'favour', 'of', 'the', 'rebels', '.']\n",
      "['the', 'young', 'president', \"'\", 's', 'father', 'laurent', ',', 'assassinated', 'in', 'january', ',', 'had', 'side', '##lined', 'mas', '##ire', 'after', 'accusing', 'him', 'of', 'being', 'biased', 'in', 'favor', 'of', 'the', 'rebels', '.']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts not matching on line 476 in train.sent..\n",
      "Political figures turn on each other from time to time , for good and bad reasons ; we 're used to it .\n",
      "['political', 'figures', 'turn', 'on', 'each', 'other', 'from', 'time', 'to', 'time', ',', 'for', 'good', 'and', 'bad', 'reasons', ';', 'we', \"'\", 're', 'used', 'to', 'it', '.']\n",
      "['political', 'figures', 'turn', 'on', 'each', 'other', 'from', 'time', 'to', 'time', ',', 'for', 'good', 'and', 'bad', 'reasons', ';', 'we', 'are', 'used', 'to', 'it', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 479 in train.sent..\n",
      "Taipei , Jan. 23 ( CNA ) -- Republic of China President Chen Shui-bian expressed the hope Wednesday that the United States will help Taiwan 's bid for observer status in the World Health Organization ( WHO ) , following its assistance to Taiwan 's World Trade Organization ( WTO ) membership bid .\n",
      "['taipei', ',', 'jan', '.', '23', '(', 'cn', '##a', ')', '-', '-', 'republic', 'of', 'china', 'president', 'chen', 'shu', '##i', '-', 'bi', '##an', 'expressed', 'the', 'hope', 'wednesday', 'that', 'the', 'united', 'states', 'will', 'help', 'taiwan', \"'\", 's', 'bid', 'for', 'observer', 'status', 'in', 'the', 'world', 'health', 'organization', '(', 'who', ')', ',', 'following', 'its', 'assistance', 'to', 'taiwan', \"'\", 's', 'world', 'trade', 'organization', '(', 'w', '##to', ')', 'membership', 'bid', '.']\n",
      "['taipei', ',', 'january', '23', '(', 'cn', '##a', ')', '-', 'republic', 'of', 'china', 'president', 'chen', 'shu', '##i', '-', 'bi', '##an', 'expressed', 'the', 'hope', 'wednesday', 'that', 'the', 'united', 'states', 'will', 'help', 'taiwan', \"'\", 's', 'bid', 'for', 'observer', 'status', 'in', 'the', 'world', 'health', 'organization', '(', 'who', ')', ',', 'following', 'its', 'assistance', 'to', 'taiwan', \"'\", 's', 'world', 'trade', 'organization', '(', 'w', '##to', ')', 'membership', 'bid', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 486 in train.sent..\n",
      "Lash also expressed gratitude to Chen for the assistance rendered by Taiwan to the United States in the wake of the Sept. 11 terrorist attacks on the United States and for its participation in the post-war reconstruction of Afghanistan .\n",
      "['lash', 'also', 'expressed', 'gratitude', 'to', 'chen', 'for', 'the', 'assistance', 'rendered', 'by', 'taiwan', 'to', 'the', 'united', 'states', 'in', 'the', 'wake', 'of', 'the', 'sept', '.', '11', 'terrorist', 'attacks', 'on', 'the', 'united', 'states', 'and', 'for', 'its', 'participation', 'in', 'the', 'post', '-', 'war', 'reconstruction', 'of', 'afghanistan', '.']\n",
      "['lash', 'also', 'expressed', 'gratitude', 'to', 'chen', 'for', 'the', 'assistance', 'rendered', 'by', 'taiwan', 'to', 'the', 'united', 'states', 'in', 'the', 'wake', 'of', 'the', 'september', '11', 'terrorist', 'attacks', 'on', 'the', 'united', 'states', 'and', 'for', 'its', 'participation', 'in', 'the', 'post', '-', 'war', 'reconstruction', 'of', 'afghanistan', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 487 in train.sent..\n",
      "TEHRAN -- President Robert Mugabe easily won Zimbabwe 's election on Wednesday despite biased propaganda unleashed against him by some Western countries , accusing him of being unfair towards the opposition .\n",
      "['tehran', '-', '-', 'president', 'robert', 'mug', '##abe', 'easily', 'won', 'zimbabwe', \"'\", 's', 'election', 'on', 'wednesday', 'despite', 'biased', 'propaganda', 'unleashed', 'against', 'him', 'by', 'some', 'western', 'countries', ',', 'accusing', 'him', 'of', 'being', 'unfair', 'towards', 'the', 'opposition', '.']\n",
      "['tehran', '-', 'president', 'robert', 'mug', '##abe', 'easily', 'won', 'zimbabwe', \"'\", 's', 'election', 'on', 'wednesday', 'despite', 'biased', 'propaganda', 'unleashed', 'against', 'him', 'by', 'some', 'western', 'countries', ',', 'accusing', 'him', 'of', 'being', 'unfair', 'towards', 'the', 'opposition', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 497 in train.sent..\n",
      "On Saturday [ 13 April ] -- two days aftr Chavez had been removed from power by a military coup-- thousands of supporters of Venezuelan President Hugo Chavez took to the streets , and after occupying the Presidential palace , they returned him to power .\n",
      "['on', 'saturday', '[', '13', 'april', ']', '-', '-', 'two', 'days', 'aft', '##r', 'chavez', 'had', 'been', 'removed', 'from', 'power', 'by', 'a', 'military', 'coup', '-', '-', 'thousands', 'of', 'supporters', 'of', 'venezuelan', 'president', 'hugo', 'chavez', 'took', 'to', 'the', 'streets', ',', 'and', 'after', 'occupying', 'the', 'presidential', 'palace', ',', 'they', 'returned', 'him', 'to', 'power', '.']\n",
      "['on', 'saturday', '[', '13', 'april', ']', '-', 'two', 'days', 'aft', '##r', 'chavez', 'had', 'been', 'removed', 'from', 'power', 'by', 'a', 'military', 'coup', '-', '-', 'thousands', 'of', 'supporters', 'of', 'venezuelan', 'president', 'hugo', 'chavez', 'took', 'to', 'the', 'streets', ',', 'and', 'after', 'occupying', 'the', 'presidential', 'palace', ',', 'they', 'returned', 'him', 'to', 'power', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 507 in train.sent..\n",
      "\" It is a bad report that can only lead to bad decisions , \" Moyo said , denouncing the report as \" opinionated \" and \" one-sided \" and saying it \" lacks credibility and cannot withstand any objective scrutiny . \"\n",
      "['\"', 'it', 'is', 'a', 'bad', 'report', 'that', 'can', 'only', 'lead', 'to', 'bad', 'decisions', ',', '\"', 'mo', '##yo', 'said', ',', 'den', '##oun', '##cing', 'the', 'report', 'as', '\"', 'opinion', '##ated', '\"', 'and', '\"', 'one', '-', 'sided', '\"', 'and', 'saying', 'it', '\"', 'lacks', 'credibility', 'and', 'cannot', 'withstand', 'any', 'objective', 'scrutiny', '.', '\"']\n",
      "['\"', 'it', 'is', 'a', 'bad', 'report', 'that', 'can', 'only', 'lead', 'to', 'bad', 'decisions', ',', '\"', 'mo', '##yo', 'said', ',', 'den', '##oun', '##cing', 'the', 'report', 'as', '\"', 'opinion', '##ated', '\"', 'and', '\"', 'one', '-', 'sided', '\"', 'and', 'saying', 'it', '\"', 'lacks', 'credibility', 'and', 'can', 'not', 'withstand', 'any', 'objective', 'scrutiny', '.', '\"']\n",
      "\n",
      "\n",
      "Counts not matching on line 546 in train.sent..\n",
      "BEIJING , April 16 ( AFP ) -- China Tuesday welcomed Venezuela 's return to political stability and expressed support for President Hugo Chavez 's promise for a dialogue on national reconciliation following his return to power after a coup .\n",
      "['beijing', ',', 'april', '16', '(', 'af', '##p', ')', '-', '-', 'china', 'tuesday', 'welcomed', 'venezuela', \"'\", 's', 'return', 'to', 'political', 'stability', 'and', 'expressed', 'support', 'for', 'president', 'hugo', 'chavez', \"'\", 's', 'promise', 'for', 'a', 'dialogue', 'on', 'national', 'reconciliation', 'following', 'his', 'return', 'to', 'power', 'after', 'a', 'coup', '.']\n",
      "['beijing', ',', 'april', '16', '(', 'af', '##p', ')', '-', 'china', 'tuesday', 'welcomed', 'venezuela', \"'\", 's', 'return', 'to', 'political', 'stability', 'and', 'expressed', 'support', 'for', 'president', 'hugo', 'chavez', \"'\", 's', 'promise', 'for', 'a', 'dial', '##og', 'on', 'national', 'reconciliation', 'following', 'his', 'return', 'to', 'power', 'after', 'a', 'coup', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 549 in train.sent..\n",
      "Chavez , who returned to power Sunday , promised Monday to invite a broad spectrum of Venezuelan society to participate in a dialogue on the country 's problems .\n",
      "['chavez', ',', 'who', 'returned', 'to', 'power', 'sunday', ',', 'promised', 'monday', 'to', 'invite', 'a', 'broad', 'spectrum', 'of', 'venezuelan', 'society', 'to', 'participate', 'in', 'a', 'dialogue', 'on', 'the', 'country', \"'\", 's', 'problems', '.']\n",
      "['chavez', ',', 'who', 'returned', 'to', 'power', 'sunday', ',', 'promised', 'monday', 'to', 'invite', 'a', 'broad', 'spectrum', 'of', 'venezuelan', 'society', 'to', 'participate', 'in', 'a', 'dial', '##og', 'on', 'the', 'country', \"'\", 's', 'problems', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 570 in train.sent..\n",
      "In contrast with the West , Zimbabwe 's neighbours , including regional superpower South Africa , found little to object to in the election .\n",
      "['in', 'contrast', 'with', 'the', 'west', ',', 'zimbabwe', \"'\", 's', 'neighbours', ',', 'including', 'regional', 'super', '##power', 'south', 'africa', ',', 'found', 'little', 'to', 'object', 'to', 'in', 'the', 'election', '.']\n",
      "['in', 'contrast', 'with', 'the', 'west', ',', 'zimbabwe', \"'\", 's', 'neighbors', ',', 'including', 'regional', 'super', '##power', 'south', 'africa', ',', 'found', 'little', 'to', 'object', 'to', 'in', 'the', 'election', '.']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts not matching on line 590 in train.sent..\n",
      "Without attributing consciousness to an E. coli , or an autonomous agent we may create in the near future , I cannot help but feel that the rudiments of value are present once autonomous agents are around .\n",
      "['without', 'at', '##tri', '##bu', '##ting', 'consciousness', 'to', 'an', 'e', '.', 'coli', ',', 'or', 'an', 'autonomous', 'agent', 'we', 'may', 'create', 'in', 'the', 'near', 'future', ',', 'i', 'cannot', 'help', 'but', 'feel', 'that', 'the', 'ru', '##diment', '##s', 'of', 'value', 'are', 'present', 'once', 'autonomous', 'agents', 'are', 'around', '.']\n",
      "['without', 'at', '##tri', '##bu', '##ting', 'consciousness', 'to', 'an', 'e', '.', 'coli', ',', 'or', 'an', 'autonomous', 'agent', 'we', 'may', 'create', 'in', 'the', 'near', 'future', ',', 'i', 'can', 'not', 'help', 'but', 'feel', 'that', 'the', 'ru', '##diment', '##s', 'of', 'value', 'are', 'present', 'once', 'autonomous', 'agents', 'are', 'around', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 599 in train.sent..\n",
      "HAVANA - ( AP ) -- Thousands of Cubans celebrated Venezuelan President Hugo Chavez 's return to power at a rally Tuesday , likening the failed coup against the Cuban ally to the disastrous U.S. - backed effort to overthrow Fidel Castro 's government 41 years ago .\n",
      "['havana', '-', '(', 'ap', ')', '-', '-', 'thousands', 'of', 'cuban', '##s', 'celebrated', 'venezuelan', 'president', 'hugo', 'chavez', \"'\", 's', 'return', 'to', 'power', 'at', 'a', 'rally', 'tuesday', ',', 'like', '##ning', 'the', 'failed', 'coup', 'against', 'the', 'cuban', 'ally', 'to', 'the', 'disastrous', 'u', '.', 's', '.', '-', 'backed', 'effort', 'to', 'overthrow', 'fide', '##l', 'castro', \"'\", 's', 'government', '41', 'years', 'ago', '.']\n",
      "['havana', '-', '(', 'ap', ')', '-', 'thousands', 'of', 'cuban', '##s', 'celebrated', 'venezuelan', 'president', 'hugo', 'chavez', \"'\", 's', 'return', 'to', 'power', 'at', 'a', 'rally', 'tuesday', ',', 'like', '##ning', 'the', 'failed', 'coup', 'against', 'the', 'cuban', 'ally', 'to', 'the', 'disastrous', 'u', '.', 's', '.', '-', 'backed', 'effort', 'to', 'overthrow', 'fide', '##l', 'castro', \"'\", 's', 'government', '41', 'years', 'ago', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 602 in train.sent..\n",
      "Cuba was swift to denounce the Venezuelan president 's ouster Friday -- reversed two days later when Chavez was reinstated by loyalist military officers after demonstrations calling for his return .\n",
      "['cuba', 'was', 'swift', 'to', 'den', '##oun', '##ce', 'the', 'venezuelan', 'president', \"'\", 's', 'ou', '##ster', 'friday', '-', '-', 'reversed', 'two', 'days', 'later', 'when', 'chavez', 'was', 'reinstated', 'by', 'loyalist', 'military', 'officers', 'after', 'demonstrations', 'calling', 'for', 'his', 'return', '.']\n",
      "['cuba', 'was', 'swift', 'to', 'den', '##oun', '##ce', 'the', 'venezuelan', 'president', \"'\", 's', 'ou', '##ster', 'friday', '-', 'reversed', 'two', 'days', 'later', 'when', 'chavez', 'was', 'reinstated', 'by', 'loyalist', 'military', 'officers', 'after', 'demonstrations', 'calling', 'for', 'his', 'return', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 612 in train.sent..\n",
      "Tang called on Washington to uphold the so-called \" one China policy \" -- the centrepiece of Beijing 's dealings with Taiwan which categorises the island is an inalienable part of mainland territory -- but failed to specifically condemn Washington 's arms sales to Taipei .\n",
      "['tang', 'called', 'on', 'washington', 'to', 'uphold', 'the', 'so', '-', 'called', '\"', 'one', 'china', 'policy', '\"', '-', '-', 'the', 'centre', '##piece', 'of', 'beijing', \"'\", 's', 'dealings', 'with', 'taiwan', 'which', 'cat', '##ego', '##rise', '##s', 'the', 'island', 'is', 'an', 'ina', '##lie', '##nable', 'part', 'of', 'mainland', 'territory', '-', '-', 'but', 'failed', 'to', 'specifically', 'condemn', 'washington', \"'\", 's', 'arms', 'sales', 'to', 'taipei', '.']\n",
      "['tang', 'called', 'on', 'washington', 'to', 'uphold', 'the', 'so', '-', 'called', '\"', 'one', 'china', 'policy', '\"', '-', 'the', 'center', '##piece', 'of', 'beijing', \"'\", 's', 'dealings', 'with', 'taiwan', 'which', 'cat', '##ego', '##rize', '##s', 'the', 'island', 'is', 'an', 'ina', '##lie', '##nable', 'part', 'of', 'mainland', 'territory', '-', 'but', 'failed', 'to', 'specifically', 'condemn', 'washington', \"'\", 's', 'arms', 'sales', 'to', 'taipei', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 614 in train.sent..\n",
      "The tone of Tang 's press conference was markedly different to that of last year 's equivalent event , during which he roundly criticised United States arms sales to Taiwan .\n",
      "['the', 'tone', 'of', 'tang', \"'\", 's', 'press', 'conference', 'was', 'markedly', 'different', 'to', 'that', 'of', 'last', 'year', \"'\", 's', 'equivalent', 'event', ',', 'during', 'which', 'he', 'round', '##ly', 'criticised', 'united', 'states', 'arms', 'sales', 'to', 'taiwan', '.']\n",
      "['the', 'tone', 'of', 'tang', \"'\", 's', 'press', 'conference', 'was', 'markedly', 'different', 'to', 'that', 'of', 'last', 'year', \"'\", 's', 'equivalent', 'event', ',', 'during', 'which', 'he', 'round', '##ly', 'criticized', 'united', 'states', 'arms', 'sales', 'to', 'taiwan', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 622 in train.sent..\n",
      "SHANGHAI , Oct 16 ( AFP ) - Malaysian Foreign Minister Syed Hamid Albar warned Tuesday that prolonged military attacks on Afghanistan could destabilise the Islamic world and reiterated calls for the US to end the campaign quickly .\n",
      "['shanghai', ',', 'oct', '16', '(', 'af', '##p', ')', '-', 'malaysian', 'foreign', 'minister', 'syed', 'hamid', 'alba', '##r', 'warned', 'tuesday', 'that', 'prolonged', 'military', 'attacks', 'on', 'afghanistan', 'could', 'des', '##ta', '##bilis', '##e', 'the', 'islamic', 'world', 'and', 'reiterated', 'calls', 'for', 'the', 'us', 'to', 'end', 'the', 'campaign', 'quickly', '.']\n",
      "['shanghai', ',', 'oct', '16', '(', 'af', '##p', ')', '-', 'malaysian', 'foreign', 'minister', 'syed', 'hamid', 'alba', '##r', 'warned', 'tuesday', 'that', 'prolonged', 'military', 'attacks', 'on', 'afghanistan', 'could', 'des', '##ta', '##bil', '##ize', 'the', 'islamic', 'world', 'and', 'reiterated', 'calls', 'for', 'the', 'us', 'to', 'end', 'the', 'campaign', 'quickly', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 636 in train.sent..\n",
      "Russia favours creation of \" international instruments \" to regulate emissions\n",
      "['russia', 'favour', '##s', 'creation', 'of', '\"', 'international', 'instruments', '\"', 'to', 'regulate', 'emissions']\n",
      "['russia', 'favors', 'creation', 'of', '\"', 'international', 'instruments', '\"', 'to', 'regulate', 'emissions']\n",
      "\n",
      "\n",
      "Counts not matching on line 653 in train.sent..\n",
      "\" We think this plan cannot be an ' alternative ' to Kyoto Protocol because it would allow the current greenhouse gas emissions of the United States to increase by around 30 % compared to 1990 level in 2010 , \" the letter said .\n",
      "['\"', 'we', 'think', 'this', 'plan', 'cannot', 'be', 'an', \"'\", 'alternative', \"'\", 'to', 'kyoto', 'protocol', 'because', 'it', 'would', 'allow', 'the', 'current', 'greenhouse', 'gas', 'emissions', 'of', 'the', 'united', 'states', 'to', 'increase', 'by', 'around', '30', '%', 'compared', 'to', '1990', 'level', 'in', '2010', ',', '\"', 'the', 'letter', 'said', '.']\n",
      "['\"', 'we', 'think', 'this', 'plan', 'can', 'not', 'be', 'an', \"'\", 'alternative', \"'\", 'to', 'kyoto', 'protocol', 'because', 'it', 'would', 'allow', 'the', 'current', 'greenhouse', 'gas', 'emissions', 'of', 'the', 'united', 'states', 'to', 'increase', 'by', 'around', '30', '%', 'compared', 'to', '1990', 'level', 'in', '2010', ',', '\"', 'the', 'letter', 'said', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 656 in train.sent..\n",
      "Meanwhile , Peace Boat also handed a separate letter addressed to the president to the guard , calling on the U.S. to take leadership in helping developing countries through \" peaceful dialogue and fair economic support . \"\n",
      "['meanwhile', ',', 'peace', 'boat', 'also', 'handed', 'a', 'separate', 'letter', 'addressed', 'to', 'the', 'president', 'to', 'the', 'guard', ',', 'calling', 'on', 'the', 'u', '.', 's', '.', 'to', 'take', 'leadership', 'in', 'helping', 'developing', 'countries', 'through', '\"', 'peaceful', 'dialogue', 'and', 'fair', 'economic', 'support', '.', '\"']\n",
      "['meanwhile', ',', 'peace', 'boat', 'also', 'handed', 'a', 'separate', 'letter', 'addressed', 'to', 'the', 'president', 'to', 'the', 'guard', ',', 'calling', 'on', 'the', 'u', '.', 's', '.', 'to', 'take', 'leadership', 'in', 'helping', 'developing', 'countries', 'through', '\"', 'peaceful', 'dial', '##og', 'and', 'fair', 'economic', 'support', '.', '\"']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts not matching on line 663 in train.sent..\n",
      "Another officer relays something we 'll hear repeated often : that because of international political pressure , the prisoners are getting coddled .\n",
      "['another', 'officer', 'relay', '##s', 'something', 'we', \"'\", 'll', 'hear', 'repeated', 'often', ':', 'that', 'because', 'of', 'international', 'political', 'pressure', ',', 'the', 'prisoners', 'are', 'getting', 'cod', '##dled', '.']\n",
      "['another', 'officer', 'relay', '##s', 'something', 'we', 'will', 'hear', 'repeated', 'often', ':', 'that', 'because', 'of', 'international', 'political', 'pressure', ',', 'the', 'prisoners', 'are', 'getting', 'cod', '##dled', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 667 in train.sent..\n",
      "Besides that , ever since the detainees started arriving on January 11 , Gitmo and the joint forces being run under Southern Command have experienced the PR equivalent of what my ever-subtle colleagues -- borrowing from Special Forces terminology for disastrous missions -- call a \" goat f-- . \"\n",
      "['besides', 'that', ',', 'ever', 'since', 'the', 'detainees', 'started', 'arriving', 'on', 'january', '11', ',', 'gi', '##tm', '##o', 'and', 'the', 'joint', 'forces', 'being', 'run', 'under', 'southern', 'command', 'have', 'experienced', 'the', 'pr', 'equivalent', 'of', 'what', 'my', 'ever', '-', 'subtle', 'colleagues', '-', '-', 'borrowing', 'from', 'special', 'forces', 'terminology', 'for', 'disastrous', 'missions', '-', '-', 'call', 'a', '\"', 'goat', 'f', '-', '-', '.', '\"']\n",
      "['besides', 'that', ',', 'ever', 'since', 'the', 'detainees', 'started', 'arriving', 'on', 'january', '11', ',', 'gi', '##tm', '##o', 'and', 'the', 'joint', 'forces', 'being', 'run', 'under', 'southern', 'command', 'have', 'experienced', 'the', 'pr', 'equivalent', 'of', 'what', 'my', 'ever', '-', 'subtle', 'colleagues', '-', 'borrowing', 'from', 'special', 'forces', 'terminology', 'for', 'disastrous', 'missions', '-', 'call', 'a', '\"', 'goat', 'f', '-', '-', '.', '\"']\n",
      "\n",
      "\n",
      "Counts not matching on line 672 in train.sent..\n",
      "Sillier still were protestations from such humanitarians as Saddam Hussein and the government of Malaysia ( Prime Minister Mahathir Mohamad has made some of the loudest noise , though Amnesty International dings him for arresting the speechwriter of a political rival , who was then blindfolded , stripped naked , punched , verbally abused , and forced to simulate homosexual acts -- none of which is alleged at Camp X -Ray ) .\n",
      "['si', '##llie', '##r', 'still', 'were', 'protest', '##ations', 'from', 'such', 'humanitarian', '##s', 'as', 'saddam', 'hussein', 'and', 'the', 'government', 'of', 'malaysia', '(', 'prime', 'minister', 'maha', '##thi', '##r', 'mo', '##ham', '##ad', 'has', 'made', 'some', 'of', 'the', 'loud', '##est', 'noise', ',', 'though', 'amnesty', 'international', 'ding', '##s', 'him', 'for', 'arresting', 'the', 'speech', '##writer', 'of', 'a', 'political', 'rival', ',', 'who', 'was', 'then', 'blind', '##fold', '##ed', ',', 'stripped', 'naked', ',', 'punched', ',', 'verbal', '##ly', 'abused', ',', 'and', 'forced', 'to', 'simulate', 'homosexual', 'acts', '-', '-', 'none', 'of', 'which', 'is', 'alleged', 'at', 'camp', 'x', '-', 'ray', ')', '.']\n",
      "['si', '##llie', '##r', 'still', 'were', 'protest', '##ations', 'from', 'such', 'humanitarian', '##s', 'as', 'saddam', 'hussein', 'and', 'the', 'government', 'of', 'malaysia', '(', 'prime', 'minister', 'maha', '##thi', '##r', 'mo', '##ham', '##ad', 'has', 'made', 'some', 'of', 'the', 'loud', '##est', 'noise', ',', 'though', 'amnesty', 'international', 'ding', '##s', 'him', 'for', 'arresting', 'the', 'speech', '##writer', 'of', 'a', 'political', 'rival', ',', 'who', 'was', 'then', 'blind', '##fold', '##ed', ',', 'stripped', 'naked', ',', 'punched', ',', 'verbal', '##ly', 'abused', ',', 'and', 'forced', 'to', 'simulate', 'homosexual', 'acts', '-', 'none', 'of', 'which', 'is', 'alleged', 'at', 'camp', 'x', '-', 'ray', ')', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 677 in train.sent..\n",
      "Restricted to an area about 150 yards away from the open-air cellblocks , we observe the camp from a slight elevation that CNN 's John Zarrella calls \" Heartbreak Ridge , \" so named \" because if you 're a journalist , it breaks your heart that you ca n't get closer . \"\n",
      "['restricted', 'to', 'an', 'area', 'about', '150', 'yards', 'away', 'from', 'the', 'open', '-', 'air', 'cell', '##block', '##s', ',', 'we', 'observe', 'the', 'camp', 'from', 'a', 'slight', 'elevation', 'that', 'cnn', \"'\", 's', 'john', 'za', '##rrell', '##a', 'calls', '\"', 'heartbreak', 'ridge', ',', '\"', 'so', 'named', '\"', 'because', 'if', 'you', \"'\", 're', 'a', 'journalist', ',', 'it', 'breaks', 'your', 'heart', 'that', 'you', 'ca', 'n', \"'\", 't', 'get', 'closer', '.', '\"']\n",
      "['restricted', 'to', 'an', 'area', 'about', '150', 'yards', 'away', 'from', 'the', 'open', '-', 'air', 'cell', '##block', '##s', ',', 'we', 'observe', 'the', 'camp', 'from', 'a', 'slight', 'elevation', 'that', 'cnn', \"'\", 's', 'john', 'za', '##rrell', '##a', 'calls', '\"', 'heartbreak', 'ridge', ',', '\"', 'so', 'named', '\"', 'because', 'if', 'you', 'are', 'a', 'journalist', ',', 'it', 'breaks', 'your', 'heart', 'that', 'you', 'ca', 'n', \"'\", 't', 'get', 'closer', '.', '\"']\n",
      "\n",
      "\n",
      "Counts not matching on line 686 in train.sent..\n",
      "We see them offering them cookies , hugging them like they 're best buddies .\n",
      "['we', 'see', 'them', 'offering', 'them', 'cookies', ',', 'hugging', 'them', 'like', 'they', \"'\", 're', 'best', 'buddies', '.']\n",
      "['we', 'see', 'them', 'offering', 'them', 'cookies', ',', 'hugging', 'them', 'like', 'they', 'are', 'best', 'buddies', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 691 in train.sent..\n",
      "With all the global bellyaching about the detainees ' right to humane treatment , it 's hard to imagine them getting better treatment than they 're already receiving .\n",
      "['with', 'all', 'the', 'global', 'belly', '##achi', '##ng', 'about', 'the', 'detainees', \"'\", 'right', 'to', 'humane', 'treatment', ',', 'it', \"'\", 's', 'hard', 'to', 'imagine', 'them', 'getting', 'better', 'treatment', 'than', 'they', \"'\", 're', 'already', 'receiving', '.']\n",
      "['with', 'all', 'the', 'global', 'belly', '##achi', '##ng', 'about', 'the', 'detainees', \"'\", 'right', 'to', 'humane', 'treatment', ',', 'it', \"'\", 's', 'hard', 'to', 'imagine', 'them', 'getting', 'better', 'treatment', 'than', 'they', 'are', 'already', 'receiving', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 692 in train.sent..\n",
      "Still , the overseers of the prison are concerned that detainees are n't getting enough pita bread with their meals , and they 're planning to make the food spicier , just the way the prisoners like it back home .\n",
      "['still', ',', 'the', 'oversee', '##rs', 'of', 'the', 'prison', 'are', 'concerned', 'that', 'detainees', 'are', 'n', \"'\", 't', 'getting', 'enough', 'pit', '##a', 'bread', 'with', 'their', 'meals', ',', 'and', 'they', \"'\", 're', 'planning', 'to', 'make', 'the', 'food', 'sp', '##ici', '##er', ',', 'just', 'the', 'way', 'the', 'prisoners', 'like', 'it', 'back', 'home', '.']\n",
      "['still', ',', 'the', 'oversee', '##rs', 'of', 'the', 'prison', 'are', 'concerned', 'that', 'detainees', 'are', 'n', \"'\", 't', 'getting', 'enough', 'pit', '##a', 'bread', 'with', 'their', 'meals', ',', 'and', 'they', 'are', 'planning', 'to', 'make', 'the', 'food', 'sp', '##ici', '##er', ',', 'just', 'the', 'way', 'the', 'prisoners', 'like', 'it', 'back', 'home', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 700 in train.sent..\n",
      "I hope you 'll consider continuing your support of Jameson 's special campers by renewing your last gift of $ xxx .\n",
      "['i', 'hope', 'you', \"'\", 'll', 'consider', 'continuing', 'your', 'support', 'of', 'jameson', \"'\", 's', 'special', 'camp', '##ers', 'by', 'renew', '##ing', 'your', 'last', 'gift', 'of', '$', 'xx', '##x', '.']\n",
      "['i', 'hope', 'you', 'will', 'consider', 'continuing', 'your', 'support', 'of', 'jameson', \"'\", 's', 'special', 'camp', '##ers', 'by', 'renew', '##ing', 'your', 'last', 'gift', 'of', '$', 'xx', '##x', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 706 in train.sent..\n",
      "Khatami and Chavez agreed that ' Dialogue Among Civilizations ' could serve to mitigate clashes of civilizations and would also ensure a durable peace .\n",
      "['k', '##hat', '##ami', 'and', 'chavez', 'agreed', 'that', \"'\", 'dialogue', 'among', 'civilizations', \"'\", 'could', 'serve', 'to', 'mit', '##igate', 'clashes', 'of', 'civilizations', 'and', 'would', 'also', 'ensure', 'a', 'durable', 'peace', '.']\n",
      "['k', '##hat', '##ami', 'and', 'chavez', 'agreed', 'that', \"'\", 'dial', '##og', 'among', 'civilizations', \"'\", 'could', 'serve', 'to', 'mit', '##igate', 'clashes', 'of', 'civilizations', 'and', 'would', 'also', 'ensure', 'a', 'durable', 'peace', '.']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts not matching on line 713 in train.sent..\n",
      "Washington , February 11 ( XINHUA ) -- US Senate Majority leader Tom Daschle criticized on Monday President George W. Bush for his remarks that described Iran , Iraq and the Democratic People 's Republic of Korea ( DPRK ) as \" axis of evil \" .\n",
      "['washington', ',', 'february', '11', '(', 'xi', '##nh', '##ua', ')', '-', '-', 'us', 'senate', 'majority', 'leader', 'tom', 'das', '##ch', '##le', 'criticized', 'on', 'monday', 'president', 'george', 'w', '.', 'bush', 'for', 'his', 'remarks', 'that', 'described', 'iran', ',', 'iraq', 'and', 'the', 'democratic', 'people', \"'\", 's', 'republic', 'of', 'korea', '(', 'd', '##pr', '##k', ')', 'as', '\"', 'axis', 'of', 'evil', '\"', '.']\n",
      "['washington', ',', 'february', '11', '(', 'xi', '##nh', '##ua', ')', '-', 'us', 'senate', 'majority', 'leader', 'tom', 'das', '##ch', '##le', 'criticized', 'on', 'monday', 'president', 'george', 'w', '.', 'bush', 'for', 'his', 'remarks', 'that', 'described', 'iran', ',', 'iraq', 'and', 'the', 'democratic', 'people', \"'\", 's', 'republic', 'of', 'korea', '(', 'd', '##pr', '##k', ')', 'as', '\"', 'axis', 'of', 'evil', '\"', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 718 in train.sent..\n",
      "Beijing , March 31 ( XINHUA ) -- Chinese Foreign Minister Tang Jiaxuan Sunday urged immediate withdrawal of Israeli troops from Palestinian leader Yasser Arafat 's residence and called for Arafat 's personal safety to be ensured .\n",
      "['beijing', ',', 'march', '31', '(', 'xi', '##nh', '##ua', ')', '-', '-', 'chinese', 'foreign', 'minister', 'tang', 'jia', '##x', '##uan', 'sunday', 'urged', 'immediate', 'withdrawal', 'of', 'israeli', 'troops', 'from', 'palestinian', 'leader', 'ya', '##sser', 'ara', '##fat', \"'\", 's', 'residence', 'and', 'called', 'for', 'ara', '##fat', \"'\", 's', 'personal', 'safety', 'to', 'be', 'ensured', '.']\n",
      "['beijing', ',', 'march', '31', '(', 'xi', '##nh', '##ua', ')', '-', 'chinese', 'foreign', 'minister', 'tang', 'jia', '##x', '##uan', 'sunday', 'urged', 'immediate', 'withdrawal', 'of', 'israeli', 'troops', 'from', 'palestinian', 'leader', 'ya', '##sser', 'ara', '##fat', \"'\", 's', 'residence', 'and', 'called', 'for', 'ara', '##fat', \"'\", 's', 'personal', 'safety', 'to', 'be', 'ensured', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 739 in train.sent..\n",
      "Another analyst , John C. Maxwell Jr. of Wheat , First Securities in Richmond , Va. , recently went to a \" sell \" recommendation on Kellogg stock , which closed Friday at $ 71.75 , down 75 cents , in New York Stock Exchange composite trading .\n",
      "['another', 'analyst', ',', 'john', 'c', '.', 'maxwell', 'jr', '.', 'of', 'wheat', ',', 'first', 'securities', 'in', 'richmond', ',', 'va', '.', ',', 'recently', 'went', 'to', 'a', '\"', 'sell', '\"', 'recommendation', 'on', 'kellogg', 'stock', ',', 'which', 'closed', 'friday', 'at', '$', '71', '.', '75', ',', 'down', '75', 'cents', ',', 'in', 'new', 'york', 'stock', 'exchange', 'composite', 'trading', '.']\n",
      "['another', 'analyst', ',', 'john', 'c', '.', 'maxwell', 'jr', '.', 'of', 'wheat', ',', 'first', 'securities', 'in', 'richmond', ',', 'virginia', ',', 'recently', 'went', 'to', 'a', '\"', 'sell', '\"', 'recommendation', 'on', 'kellogg', 'stock', ',', 'which', 'closed', 'friday', 'at', '$', '71', '.', '75', ',', 'down', '75', 'cents', ',', 'in', 'new', 'york', 'stock', 'exchange', 'composite', 'trading', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 740 in train.sent..\n",
      "People are reading the boxes and deciding they want something that 's `healthy ' for you -- oats , bran . \"\n",
      "['people', 'are', 'reading', 'the', 'boxes', 'and', 'deciding', 'they', 'want', 'something', 'that', \"'\", 's', '`', 'healthy', \"'\", 'for', 'you', '-', '-', 'o', '##ats', ',', 'bran', '.', '\"']\n",
      "['people', 'are', 'reading', 'the', 'boxes', 'and', 'deciding', 'they', 'want', 'something', 'that', \"'\", 's', \"'\", 'healthy', \"'\", 'for', 'you', '-', 'o', '##ats', ',', 'bran', '.', '\"']\n",
      "\n",
      "\n",
      "Counts not matching on line 743 in train.sent..\n",
      "WASHINGTON , Jan. 22 - Frustrated by an international outcry over the American treatment of prisoners in Cuba , Secretary of Defense Donald H. Rumsfeld defended the United States ' conduct at length today and dismissed the criticism as breathless armchair hyperbole .\n",
      "['washington', ',', 'jan', '.', '22', '-', 'frustrated', 'by', 'an', 'international', 'out', '##cr', '##y', 'over', 'the', 'american', 'treatment', 'of', 'prisoners', 'in', 'cuba', ',', 'secretary', 'of', 'defense', 'donald', 'h', '.', 'rum', '##sf', '##eld', 'defended', 'the', 'united', 'states', \"'\", 'conduct', 'at', 'length', 'today', 'and', 'dismissed', 'the', 'criticism', 'as', 'breathless', 'armchair', 'hyper', '##bol', '##e', '.']\n",
      "['washington', ',', 'january', '22', '-', 'frustrated', 'by', 'an', 'international', 'out', '##cr', '##y', 'over', 'the', 'american', 'treatment', 'of', 'prisoners', 'in', 'cuba', ',', 'secretary', 'of', 'defense', 'donald', 'h', '.', 'rum', '##sf', '##eld', 'defended', 'the', 'united', 'states', \"'\", 'conduct', 'at', 'length', 'today', 'and', 'dismissed', 'the', 'criticism', 'as', 'breathless', 'armchair', 'hyper', '##bol', '##e', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 767 in train.sent..\n",
      "Tehran , Dec 9 , IRNA -- Tehran - based Islamic Human Rights Commission ( IHRC ) on Sunday expressed concern about return of the period in which force and weapon had the last say in international relations .\n",
      "['tehran', ',', 'dec', '9', ',', 'ir', '##na', '-', '-', 'tehran', '-', 'based', 'islamic', 'human', 'rights', 'commission', '(', 'i', '##hr', '##c', ')', 'on', 'sunday', 'expressed', 'concern', 'about', 'return', 'of', 'the', 'period', 'in', 'which', 'force', 'and', 'weapon', 'had', 'the', 'last', 'say', 'in', 'international', 'relations', '.']\n",
      "['tehran', ',', 'dec', '9', ',', 'ir', '##na', '-', 'tehran', '-', 'based', 'islamic', 'human', 'rights', 'commission', '(', 'i', '##hr', '##c', ')', 'on', 'sunday', 'expressed', 'concern', 'about', 'return', 'of', 'the', 'period', 'in', 'which', 'force', 'and', 'weapon', 'had', 'the', 'last', 'say', 'in', 'international', 'relations', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 835 in train.sent..\n",
      "He said that banks , real estate , construction projects , stock markets , investing in losing companies and gambling are among the favourite targets for money launderers .\n",
      "['he', 'said', 'that', 'banks', ',', 'real', 'estate', ',', 'construction', 'projects', ',', 'stock', 'markets', ',', 'investing', 'in', 'losing', 'companies', 'and', 'gambling', 'are', 'among', 'the', 'favourite', 'targets', 'for', 'money', 'lau', '##nder', '##ers', '.']\n",
      "['he', 'said', 'that', 'banks', ',', 'real', 'estate', ',', 'construction', 'projects', ',', 'stock', 'markets', ',', 'investing', 'in', 'losing', 'companies', 'and', 'gambling', 'are', 'among', 'the', 'favorite', 'targets', 'for', 'money', 'lau', '##nder', '##ers', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 836 in train.sent..\n",
      "We 're asking for a contribution in the amount of because you ca n't got a better bang for your buck than to support an organization that impacts so many lives in so many ways .\n",
      "['we', \"'\", 're', 'asking', 'for', 'a', 'contribution', 'in', 'the', 'amount', 'of', 'because', 'you', 'ca', 'n', \"'\", 't', 'got', 'a', 'better', 'bang', 'for', 'your', 'buck', 'than', 'to', 'support', 'an', 'organization', 'that', 'impacts', 'so', 'many', 'lives', 'in', 'so', 'many', 'ways', '.']\n",
      "['we', 'are', 'asking', 'for', 'a', 'contribution', 'in', 'the', 'amount', 'of', 'because', 'you', 'ca', 'n', \"'\", 't', 'got', 'a', 'better', 'bang', 'for', 'your', 'buck', 'than', 'to', 'support', 'an', 'organization', 'that', 'impacts', 'so', 'many', 'lives', 'in', 'so', 'many', 'ways', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 843 in train.sent..\n",
      "Mostly , I liked to spend time reading encyclopedias --\n",
      "['mostly', ',', 'i', 'liked', 'to', 'spend', 'time', 'reading', 'encyclopedia', '##s', '-', '-']\n",
      "['mostly', ',', 'i', 'liked', 'to', 'spend', 'time', 'reading', 'encyclopedia', '##s', '-']\n",
      "\n",
      "\n",
      "Counts not matching on line 855 in train.sent..\n",
      "LUSAKA -- Zambian President Levy Mwanawasa yesterday hailed the re-election of his Zimbabwean counterpart Robert Mugabe and called on defeated opponent Morgan Tsvangirai to accept the controversial result .\n",
      "['lu', '##saka', '-', '-', 'zambia', '##n', 'president', 'levy', 'mw', '##ana', '##was', '##a', 'yesterday', 'hailed', 'the', 're', '-', 'election', 'of', 'his', 'zimbabwe', '##an', 'counterpart', 'robert', 'mug', '##abe', 'and', 'called', 'on', 'defeated', 'opponent', 'morgan', 'ts', '##van', '##gi', '##rai', 'to', 'accept', 'the', 'controversial', 'result', '.']\n",
      "['lu', '##saka', '-', 'zambia', '##n', 'president', 'levy', 'mw', '##ana', '##was', '##a', 'yesterday', 'hailed', 'the', 're', '-', 'election', 'of', 'his', 'zimbabwe', '##an', 'counterpart', 'robert', 'mug', '##abe', 'and', 'called', 'on', 'defeated', 'opponent', 'morgan', 'ts', '##van', '##gi', '##rai', 'to', 'accept', 'the', 'controversial', 'result', '.']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts not matching on line 857 in train.sent..\n",
      "\" As chairman of the Organisation of African Unity and president of a friendly neighbour , I congratulate President Mugabe on his re-election , \" Mwanawasa said .\n",
      "['\"', 'as', 'chairman', 'of', 'the', 'organisation', 'of', 'african', 'unity', 'and', 'president', 'of', 'a', 'friendly', 'neighbour', ',', 'i', 'cong', '##rat', '##ulate', 'president', 'mug', '##abe', 'on', 'his', 're', '-', 'election', ',', '\"', 'mw', '##ana', '##was', '##a', 'said', '.']\n",
      "['\"', 'as', 'chairman', 'of', 'the', 'organization', 'of', 'african', 'unity', 'and', 'president', 'of', 'a', 'friendly', 'neighbor', ',', 'i', 'cong', '##rat', '##ulate', 'president', 'mug', '##abe', 'on', 'his', 're', '-', 'election', ',', '\"', 'mw', '##ana', '##was', '##a', 'said', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 861 in train.sent..\n",
      "The ASEM EnMM concluded in Beijing on 17 January with the adoption of a Statement of the Presidium calling for an early implementation of the Kyoto Protocol as well as cooperation and dialogue between ASEM members .\n",
      "['the', 'as', '##em', 'en', '##mm', 'concluded', 'in', 'beijing', 'on', '17', 'january', 'with', 'the', 'adoption', 'of', 'a', 'statement', 'of', 'the', 'pre', '##si', '##dium', 'calling', 'for', 'an', 'early', 'implementation', 'of', 'the', 'kyoto', 'protocol', 'as', 'well', 'as', 'cooperation', 'and', 'dialogue', 'between', 'as', '##em', 'members', '.']\n",
      "['the', 'as', '##em', 'en', '##mm', 'concluded', 'in', 'beijing', 'on', '17', 'january', 'with', 'the', 'adoption', 'of', 'a', 'statement', 'of', 'the', 'pre', '##si', '##dium', 'calling', 'for', 'an', 'early', 'implementation', 'of', 'the', 'kyoto', 'protocol', 'as', 'well', 'as', 'cooperation', 'and', 'dial', '##og', 'between', 'as', '##em', 'members', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 876 in train.sent..\n",
      "Anti-smuggling teams in Izmir stopped two buses in Bornova town and captured 108 persons including 28 Turks who wanted to go to Germany , in the buses .\n",
      "['anti', '-', 'smuggling', 'teams', 'in', 'i', '##z', '##mir', 'stopped', 'two', 'buses', 'in', 'born', '##ova', 'town', 'and', 'captured', '108', 'persons', 'including', '28', 'turks', 'who', 'wanted', 'to', 'go', 'to', 'germany', ',', 'in', 'the', 'buses', '.']\n",
      "['anti', '-', 'smuggling', 'teams', 'in', 'i', '##z', '##mir', 'stopped', 'two', 'bus', '##ses', 'in', 'born', '##ova', 'town', 'and', 'captured', '108', 'persons', 'including', '28', 'turks', 'who', 'wanted', 'to', 'go', 'to', 'germany', ',', 'in', 'the', 'bus', '##ses', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 882 in train.sent..\n",
      "Ramsamy also read a joint statement made on Thursday at the close of a meeting of SADC foreign and finance ministers in Blantyre , Malawi , labelling the terror attacks ghastly and barbaric .\n",
      "['rams', '##amy', 'also', 'read', 'a', 'joint', 'statement', 'made', 'on', 'thursday', 'at', 'the', 'close', 'of', 'a', 'meeting', 'of', 'sad', '##c', 'foreign', 'and', 'finance', 'ministers', 'in', 'b', '##lan', '##ty', '##re', ',', 'malawi', ',', 'label', '##ling', 'the', 'terror', 'attacks', 'g', '##has', '##tly', 'and', 'bar', '##bari', '##c', '.']\n",
      "['rams', '##amy', 'also', 'read', 'a', 'joint', 'statement', 'made', 'on', 'thursday', 'at', 'the', 'close', 'of', 'a', 'meeting', 'of', 'sad', '##c', 'foreign', 'and', 'finance', 'ministers', 'in', 'b', '##lan', '##ty', '##re', ',', 'malawi', ',', 'labeling', 'the', 'terror', 'attacks', 'g', '##has', '##tly', 'and', 'bar', '##bari', '##c', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 933 in train.sent..\n",
      "Under this situation , the nation cannot possibly avoid pressures to match the cuts of advanced nations .\n",
      "['under', 'this', 'situation', ',', 'the', 'nation', 'cannot', 'possibly', 'avoid', 'pressures', 'to', 'match', 'the', 'cuts', 'of', 'advanced', 'nations', '.']\n",
      "['under', 'this', 'situation', ',', 'the', 'nation', 'can', 'not', 'possibly', 'avoid', 'pressures', 'to', 'match', 'the', 'cuts', 'of', 'advanced', 'nations', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 934 in train.sent..\n",
      "In particular , Japan and European countries are likely to persuade developing countries including South Korea to take part in the reduction of greenhouse gases earlier than planned in an attempt to secure the United States ' ratification of the protocol .\n",
      "['in', 'particular', ',', 'japan', 'and', 'european', 'countries', 'are', 'likely', 'to', 'persuade', 'developing', 'countries', 'including', 'south', 'korea', 'to', 'take', 'part', 'in', 'the', 'reduction', 'of', 'greenhouse', 'gases', 'earlier', 'than', 'planned', 'in', 'an', 'attempt', 'to', 'secure', 'the', 'united', 'states', \"'\", 'ratification', 'of', 'the', 'protocol', '.']\n",
      "['in', 'particular', ',', 'japan', 'and', 'european', 'countries', 'are', 'likely', 'to', 'persuade', 'developing', 'countries', 'including', 'south', 'korea', 'to', 'take', 'part', 'in', 'the', 'reduction', 'of', 'greenhouse', 'gas', '##ses', 'earlier', 'than', 'planned', 'in', 'an', 'attempt', 'to', 'secure', 'the', 'united', 'states', \"'\", 'ratification', 'of', 'the', 'protocol', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 948 in train.sent..\n",
      "A number of embassies here , including the American , French , German and Japanese , have issued advisories to their nationals warning them of risks when travelling in some parts of the country .\n",
      "['a', 'number', 'of', 'em', '##bas', '##sies', 'here', ',', 'including', 'the', 'american', ',', 'french', ',', 'german', 'and', 'japanese', ',', 'have', 'issued', 'advisor', '##ies', 'to', 'their', 'nationals', 'warning', 'them', 'of', 'risks', 'when', 'travelling', 'in', 'some', 'parts', 'of', 'the', 'country', '.']\n",
      "['a', 'number', 'of', 'em', '##bas', '##sies', 'here', ',', 'including', 'the', 'american', ',', 'french', ',', 'german', 'and', 'japanese', ',', 'have', 'issued', 'advisor', '##ies', 'to', 'their', 'nationals', 'warning', 'them', 'of', 'risks', 'when', 'traveling', 'in', 'some', 'parts', 'of', 'the', 'country', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 952 in train.sent..\n",
      "They think she is travelling too much , while internal problems sap the country 's energy , and that she has misplaced strategic priorities in her overseas visits .\n",
      "['they', 'think', 'she', 'is', 'travelling', 'too', 'much', ',', 'while', 'internal', 'problems', 'sap', 'the', 'country', \"'\", 's', 'energy', ',', 'and', 'that', 'she', 'has', 'mis', '##placed', 'strategic', 'priorities', 'in', 'her', 'overseas', 'visits', '.']\n",
      "['they', 'think', 'she', 'is', 'traveling', 'too', 'much', ',', 'while', 'internal', 'problems', 'sap', 'the', 'country', \"'\", 's', 'energy', ',', 'and', 'that', 'she', 'has', 'mis', '##placed', 'strategic', 'priorities', 'in', 'her', 'overseas', 'visits', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 956 in train.sent..\n",
      "Jameson points the way for children who need that extra hand and I hope you 'll continue your support this year .\n",
      "['jameson', 'points', 'the', 'way', 'for', 'children', 'who', 'need', 'that', 'extra', 'hand', 'and', 'i', 'hope', 'you', \"'\", 'll', 'continue', 'your', 'support', 'this', 'year', '.']\n",
      "['jameson', 'points', 'the', 'way', 'for', 'children', 'who', 'need', 'that', 'extra', 'hand', 'and', 'i', 'hope', 'you', 'will', 'continue', 'your', 'support', 'this', 'year', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 960 in train.sent..\n",
      "I hope you 'll continue -- and if possible increase - your support for these great kids .\n",
      "['i', 'hope', 'you', \"'\", 'll', 'continue', '-', '-', 'and', 'if', 'possible', 'increase', '-', 'your', 'support', 'for', 'these', 'great', 'kids', '.']\n",
      "['i', 'hope', 'you', 'will', 'continue', '-', 'and', 'if', 'possible', 'increase', '-', 'your', 'support', 'for', 'these', 'great', 'kids', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 963 in train.sent..\n",
      "It -- and the opposition Democrats , still smarting at his election victory -- will dig for dirt as long it takes .\n",
      "['it', '-', '-', 'and', 'the', 'opposition', 'democrats', ',', 'still', 'smart', '##ing', 'at', 'his', 'election', 'victory', '-', '-', 'will', 'dig', 'for', 'dirt', 'as', 'long', 'it', 'takes', '.']\n",
      "['it', '-', 'and', 'the', 'opposition', 'democrats', ',', 'still', 'smart', '##ing', 'at', 'his', 'election', 'victory', '-', 'will', 'dig', 'for', 'dirt', 'as', 'long', 'it', 'takes', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 975 in train.sent..\n",
      "Chief - of- Staff of the Turkish Armed Forces Huseyin Kivrikoglu arrived in Uzbekistan on Saturday [ 16 March ] at the invitation of Uzbek Defence Minister Kadyr Gulyamov , sources in the Turkish Embassy in Tashkent told Interfax .\n",
      "['chief', '-', 'of', '-', 'staff', 'of', 'the', 'turkish', 'armed', 'forces', 'hu', '##sey', '##in', 'ki', '##vr', '##iko', '##gl', '##u', 'arrived', 'in', 'uzbekistan', 'on', 'saturday', '[', '16', 'march', ']', 'at', 'the', 'invitation', 'of', 'u', '##zbek', 'defence', 'minister', 'ka', '##dy', '##r', 'gu', '##ly', '##amo', '##v', ',', 'sources', 'in', 'the', 'turkish', 'embassy', 'in', 'ta', '##sh', '##ken', '##t', 'told', 'inter', '##fa', '##x', '.']\n",
      "['chief', '-', 'of', '-', 'staff', 'of', 'the', 'turkish', 'armed', 'forces', 'hu', '##sey', '##in', 'ki', '##vr', '##iko', '##gl', '##u', 'arrived', 'in', 'uzbekistan', 'on', 'saturday', '[', '16', 'march', ']', 'at', 'the', 'invitation', 'of', 'u', '##zbek', 'defense', 'minister', 'ka', '##dy', '##r', 'gu', '##ly', '##amo', '##v', ',', 'sources', 'in', 'the', 'turkish', 'embassy', 'in', 'ta', '##sh', '##ken', '##t', 'told', 'inter', '##fa', '##x', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 976 in train.sent..\n",
      "The programme calls for the overhaul of nuclear power stations with a view to extending their safe and efficient operation , extending the service life of power units , resumption of the construction of power units and compiling a list of promising sites for future nuclear power stations .\n",
      "['the', 'programme', 'calls', 'for', 'the', 'overhaul', 'of', 'nuclear', 'power', 'stations', 'with', 'a', 'view', 'to', 'extending', 'their', 'safe', 'and', 'efficient', 'operation', ',', 'extending', 'the', 'service', 'life', 'of', 'power', 'units', ',', 'res', '##ump', '##tion', 'of', 'the', 'construction', 'of', 'power', 'units', 'and', 'compiling', 'a', 'list', 'of', 'promising', 'sites', 'for', 'future', 'nuclear', 'power', 'stations', '.']\n",
      "['the', 'program', 'calls', 'for', 'the', 'overhaul', 'of', 'nuclear', 'power', 'stations', 'with', 'a', 'view', 'to', 'extending', 'their', 'safe', 'and', 'efficient', 'operation', ',', 'extending', 'the', 'service', 'life', 'of', 'power', 'units', ',', 'res', '##ump', '##tion', 'of', 'the', 'construction', 'of', 'power', 'units', 'and', 'compiling', 'a', 'list', 'of', 'promising', 'sites', 'for', 'future', 'nuclear', 'power', 'stations', '.']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts not matching on line 981 in train.sent..\n",
      "Six months have passed since Sept. 11 and the focus of US anger has turned to countries that have been labeled \" rogue nations \" and members of an \" axis of evil . \"\n",
      "['six', 'months', 'have', 'passed', 'since', 'sept', '.', '11', 'and', 'the', 'focus', 'of', 'us', 'anger', 'has', 'turned', 'to', 'countries', 'that', 'have', 'been', 'labeled', '\"', 'rogue', 'nations', '\"', 'and', 'members', 'of', 'an', '\"', 'axis', 'of', 'evil', '.', '\"']\n",
      "['six', 'months', 'have', 'passed', 'since', 'september', '11', 'and', 'the', 'focus', 'of', 'us', 'anger', 'has', 'turned', 'to', 'countries', 'that', 'have', 'been', 'labeled', '\"', 'rogue', 'nations', '\"', 'and', 'members', 'of', 'an', '\"', 'axis', 'of', 'evil', '.', '\"']\n",
      "\n",
      "\n",
      "Counts not matching on line 982 in train.sent..\n",
      "\" If you 're not with us , you 're against us . \"\n",
      "['\"', 'if', 'you', \"'\", 're', 'not', 'with', 'us', ',', 'you', \"'\", 're', 'against', 'us', '.', '\"']\n",
      "['\"', 'if', 'you', 'are', 'not', 'with', 'us', ',', 'you', 'are', 'against', 'us', '.', '\"']\n",
      "\n",
      "\n",
      "Counts not matching on line 1008 in train.sent..\n",
      "The pundits in Ottawa , it seems , have saved all of their praise for John Manley , the new Deputy Prime Minister and a hometown favourite .\n",
      "['the', 'pun', '##dit', '##s', 'in', 'ottawa', ',', 'it', 'seems', ',', 'have', 'saved', 'all', 'of', 'their', 'praise', 'for', 'john', 'man', '##ley', ',', 'the', 'new', 'deputy', 'prime', 'minister', 'and', 'a', 'hometown', 'favourite', '.']\n",
      "['the', 'pun', '##dit', '##s', 'in', 'ottawa', ',', 'it', 'seems', ',', 'have', 'saved', 'all', 'of', 'their', 'praise', 'for', 'john', 'man', '##ley', ',', 'the', 'new', 'deputy', 'prime', 'minister', 'and', 'a', 'hometown', 'favorite', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 1009 in train.sent..\n",
      "\" [ Mr. Manley ] has proven to be a sensible manager who Canadians can trust , \" says a Sun editorial , observing that he emerged from the Sept. 11 crisis as a \" sensible , serious voice in Cabinet . \"\n",
      "['\"', '[', 'mr', '.', 'man', '##ley', ']', 'has', 'proven', 'to', 'be', 'a', 'sensible', 'manager', 'who', 'canadians', 'can', 'trust', ',', '\"', 'says', 'a', 'sun', 'editorial', ',', 'observing', 'that', 'he', 'emerged', 'from', 'the', 'sept', '.', '11', 'crisis', 'as', 'a', '\"', 'sensible', ',', 'serious', 'voice', 'in', 'cabinet', '.', '\"']\n",
      "['\"', '[', 'mr', '.', 'man', '##ley', ']', 'has', 'proven', 'to', 'be', 'a', 'sensible', 'manager', 'who', 'canadians', 'can', 'trust', ',', '\"', 'says', 'a', 'sun', 'editorial', ',', 'observing', 'that', 'he', 'emerged', 'from', 'the', 'september', '11', 'crisis', 'as', 'a', '\"', 'sensible', ',', 'serious', 'voice', 'in', 'cabinet', '.', '\"']\n",
      "\n",
      "\n",
      "Counts not matching on line 1011 in train.sent..\n",
      "ISLAMABAD - Pakistan Tuesday slated US State Department 's country report on human rights situation in Pakistan and labelled it \" factually inaccurate and unwarranted . \"\n",
      "['islamabad', '-', 'pakistan', 'tuesday', 'slated', 'us', 'state', 'department', \"'\", 's', 'country', 'report', 'on', 'human', 'rights', 'situation', 'in', 'pakistan', 'and', 'labelled', 'it', '\"', 'factual', '##ly', 'inaccurate', 'and', 'un', '##war', '##rant', '##ed', '.', '\"']\n",
      "['islamabad', '-', 'pakistan', 'tuesday', 'slated', 'us', 'state', 'department', \"'\", 's', 'country', 'report', 'on', 'human', 'rights', 'situation', 'in', 'pakistan', 'and', 'labeled', 'it', '\"', 'factual', '##ly', 'inaccurate', 'and', 'un', '##war', '##rant', '##ed', '.', '\"']\n",
      "\n",
      "\n",
      "Counts not matching on line 1026 in train.sent..\n",
      "All said they were protesting an election they said had been tainted by months of political violence and intimidation , last-minute changes to electoral laws , and the disenfranchisement of tens of thousands of voters in Harare -- an opposition stronghold -- who failed to vote because the government reduced the number of polling stations .\n",
      "['all', 'said', 'they', 'were', 'protesting', 'an', 'election', 'they', 'said', 'had', 'been', 'tainted', 'by', 'months', 'of', 'political', 'violence', 'and', 'intimidation', ',', 'last', '-', 'minute', 'changes', 'to', 'electoral', 'laws', ',', 'and', 'the', 'di', '##sen', '##fra', '##nch', '##ise', '##ment', 'of', 'tens', 'of', 'thousands', 'of', 'voters', 'in', 'hara', '##re', '-', '-', 'an', 'opposition', 'stronghold', '-', '-', 'who', 'failed', 'to', 'vote', 'because', 'the', 'government', 'reduced', 'the', 'number', 'of', 'polling', 'stations', '.']\n",
      "['all', 'said', 'they', 'were', 'protesting', 'an', 'election', 'they', 'said', 'had', 'been', 'tainted', 'by', 'months', 'of', 'political', 'violence', 'and', 'intimidation', ',', 'last', '-', 'minute', 'changes', 'to', 'electoral', 'laws', ',', 'and', 'the', 'di', '##sen', '##fra', '##nch', '##ise', '##ment', 'of', 'tens', 'of', 'thousands', 'of', 'voters', 'in', 'hara', '##re', '-', 'an', 'opposition', 'stronghold', '-', 'who', 'failed', 'to', 'vote', 'because', 'the', 'government', 'reduced', 'the', 'number', 'of', 'polling', 'stations', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 1055 in train.sent..\n",
      "Currently , many engineering students in universities prefer to specialise in the electrical or computer disciplines because the demand for them is higher .\n",
      "['currently', ',', 'many', 'engineering', 'students', 'in', 'universities', 'prefer', 'to', 'special', '##ise', 'in', 'the', 'electrical', 'or', 'computer', 'disciplines', 'because', 'the', 'demand', 'for', 'them', 'is', 'higher', '.']\n",
      "['currently', ',', 'many', 'engineering', 'students', 'in', 'universities', 'prefer', 'to', 'special', '##ize', 'in', 'the', 'electrical', 'or', 'computer', 'disciplines', 'because', 'the', 'demand', 'for', 'them', 'is', 'higher', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 1074 in train.sent..\n",
      "The influential International Crisis Group ( ICG ) warned that the `risk of major violence erupting is exceedingly high ' if the election was seen to be rigged .\n",
      "['the', 'influential', 'international', 'crisis', 'group', '(', 'ic', '##g', ')', 'warned', 'that', 'the', '`', 'risk', 'of', 'major', 'violence', 'er', '##upt', '##ing', 'is', 'exceeding', '##ly', 'high', \"'\", 'if', 'the', 'election', 'was', 'seen', 'to', 'be', 'rigged', '.']\n",
      "['the', 'influential', 'international', 'crisis', 'group', '(', 'ic', '##g', ')', 'warned', 'that', 'the', \"'\", 'risk', 'of', 'major', 'violence', 'er', '##upt', '##ing', 'is', 'exceeding', '##ly', 'high', \"'\", 'if', 'the', 'election', 'was', 'seen', 'to', 'be', 'rigged', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 1080 in train.sent..\n",
      "Beijing , April 29 ( XINHUA ) -- Lebanese Prime Minister Rafik Hariri invited Chinese entrepreneurs to invest in his country at a luncheon was held here Monday in his honor .\n",
      "['beijing', ',', 'april', '29', '(', 'xi', '##nh', '##ua', ')', '-', '-', 'lebanese', 'prime', 'minister', 'raf', '##ik', 'hari', '##ri', 'invited', 'chinese', 'entrepreneurs', 'to', 'invest', 'in', 'his', 'country', 'at', 'a', 'lunch', '##eon', 'was', 'held', 'here', 'monday', 'in', 'his', 'honor', '.']\n",
      "['beijing', ',', 'april', '29', '(', 'xi', '##nh', '##ua', ')', '-', 'lebanese', 'prime', 'minister', 'raf', '##ik', 'hari', '##ri', 'invited', 'chinese', 'entrepreneurs', 'to', 'invest', 'in', 'his', 'country', 'at', 'a', 'lunch', '##eon', 'was', 'held', 'here', 'monday', 'in', 'his', 'honor', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 1086 in train.sent..\n",
      "Thanking you in advance for your support , we remain , Sincerely , John T. Neighbours Philip B. Roby President Treasurer John F. Brandon Executive Director\n",
      "['thanking', 'you', 'in', 'advance', 'for', 'your', 'support', ',', 'we', 'remain', ',', 'sincerely', ',', 'john', 't', '.', 'neighbours', 'philip', 'b', '.', 'rob', '##y', 'president', 'treasurer', 'john', 'f', '.', 'brandon', 'executive', 'director']\n",
      "['thanking', 'you', 'in', 'advance', 'for', 'your', 'support', ',', 'we', 'remain', ',', 'sincerely', ',', 'john', 't', '.', 'neighbors', 'philip', 'b', '.', 'rob', '##y', 'president', 'treasurer', 'john', 'f', '.', 'brandon', 'executive', 'director']\n",
      "\n",
      "\n",
      "Counts not matching on line 1087 in train.sent..\n",
      "In the Bible , Genesis 14:18 -- 20 records that Abraham visited the city of ` `Salem ' ' in approximately 1800 b.c. and was blessed by the city ' s ruler , Melchzedik , who offered him bread and wine .\n",
      "['in', 'the', 'bible', ',', 'genesis', '14', ':', '18', '-', '-', '20', 'records', 'that', 'abraham', 'visited', 'the', 'city', 'of', '`', '`', 'salem', \"'\", \"'\", 'in', 'approximately', '1800', 'b', '.', 'c', '.', 'and', 'was', 'blessed', 'by', 'the', 'city', \"'\", 's', 'ruler', ',', 'mel', '##ch', '##zed', '##ik', ',', 'who', 'offered', 'him', 'bread', 'and', 'wine', '.']\n",
      "['in', 'the', 'bible', ',', 'genesis', '14', ':', '18', '-', '20', 'records', 'that', 'abraham', 'visited', 'the', 'city', 'of', \"'\", \"'\", 'salem', \"'\", \"'\", 'in', 'approximately', '1800', 'b', '.', 'c', '.', 'and', 'was', 'blessed', 'by', 'the', 'city', \"'\", 's', 'ruler', ',', 'mel', '##ch', '##zed', '##ik', ',', 'who', 'offered', 'him', 'bread', 'and', 'wine', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 1089 in train.sent..\n",
      "The site of the Temple eventually became identified as Mt. Moriah , on which it stood , where Abraham was called to sacrifice his son Isaac .\n",
      "['the', 'site', 'of', 'the', 'temple', 'eventually', 'became', 'identified', 'as', 'mt', '.', 'mori', '##ah', ',', 'on', 'which', 'it', 'stood', ',', 'where', 'abraham', 'was', 'called', 'to', 'sacrifice', 'his', 'son', 'isaac', '.']\n",
      "['the', 'site', 'of', 'the', 'temple', 'eventually', 'became', 'identified', 'as', 'mount', 'mori', '##ah', ',', 'on', 'which', 'it', 'stood', ',', 'where', 'abraham', 'was', 'called', 'to', 'sacrifice', 'his', 'son', 'isaac', '.']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts not matching on line 1092 in train.sent..\n",
      "A massive fortress was built overlooking the Temple Mount , which Herod named ` `Antonia ' ' in honor of his Roman friend and benefactor , Mark Antony .\n",
      "['a', 'massive', 'fortress', 'was', 'built', 'overlooking', 'the', 'temple', 'mount', ',', 'which', 'hero', '##d', 'named', '`', '`', 'antonia', \"'\", \"'\", 'in', 'honor', 'of', 'his', 'roman', 'friend', 'and', 'benefactor', ',', 'mark', 'antony', '.']\n",
      "['a', 'massive', 'fortress', 'was', 'built', 'overlooking', 'the', 'temple', 'mount', ',', 'which', 'hero', '##d', 'named', \"'\", \"'\", 'antonia', \"'\", \"'\", 'in', 'honor', 'of', 'his', 'roman', 'friend', 'and', 'benefactor', ',', 'mark', 'antony', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 1099 in train.sent..\n",
      "Weizmann was an important figure in the negotiations with the British government that led to the Balfour Declaration of 1917 , supporting the idea of a Jewish ``national home ' ' in Palestine that also respected the rights of existing non -Jewish people already living there .\n",
      "['wei', '##zman', '##n', 'was', 'an', 'important', 'figure', 'in', 'the', 'negotiations', 'with', 'the', 'british', 'government', 'that', 'led', 'to', 'the', 'balfour', 'declaration', 'of', '1917', ',', 'supporting', 'the', 'idea', 'of', 'a', 'jewish', '`', '`', 'national', 'home', \"'\", \"'\", 'in', 'palestine', 'that', 'also', 'respected', 'the', 'rights', 'of', 'existing', 'non', '-', 'jewish', 'people', 'already', 'living', 'there', '.']\n",
      "['wei', '##zman', '##n', 'was', 'an', 'important', 'figure', 'in', 'the', 'negotiations', 'with', 'the', 'british', 'government', 'that', 'led', 'to', 'the', 'balfour', 'declaration', 'of', '1917', ',', 'supporting', 'the', 'idea', 'of', 'a', 'jewish', \"'\", \"'\", 'national', 'home', \"'\", \"'\", 'in', 'palestine', 'that', 'also', 'respected', 'the', 'rights', 'of', 'existing', 'non', '-', 'jewish', 'people', 'already', 'living', 'there', '.']\n",
      "\n",
      "\n",
      "[7, 13, 38, 44, 62, 64, 73, 91, 95, 97, 99, 113, 139, 140, 161, 205, 215, 225, 237, 257, 260, 264, 268, 269, 285, 286, 310, 311, 312, 313, 321, 327, 343, 344, 346, 379, 388, 389, 390, 392, 402, 415, 417, 419, 422, 426, 440, 446, 460, 468, 476, 479, 486, 487, 497, 507, 546, 549, 570, 590, 599, 602, 612, 614, 622, 636, 653, 656, 663, 667, 672, 677, 686, 691, 692, 700, 706, 713, 718, 739, 740, 743, 767, 835, 836, 843, 855, 857, 861, 876, 882, 933, 934, 948, 952, 956, 960, 963, 975, 976, 981, 982, 1008, 1009, 1011, 1026, 1055, 1074, 1080, 1086, 1087, 1089, 1092, 1099]\n",
      "Deleted\n",
      "996\n",
      "\n",
      "\n",
      "Deleted\n",
      "996\n",
      "\n",
      "\n",
      "Deleted\n",
      "996\n",
      "\n",
      "\n",
      "Counts not matching on line 9 in dev.sent..\n",
      "The two groups have criticised the election process with the Sadc Parliamentary Forum saying it did not meet the regional grouping 's standards on elections .\n",
      "['the', 'two', 'groups', 'have', 'criticised', 'the', 'election', 'process', 'with', 'the', 'sad', '##c', 'parliamentary', 'forum', 'saying', 'it', 'did', 'not', 'meet', 'the', 'regional', 'grouping', \"'\", 's', 'standards', 'on', 'elections', '.']\n",
      "['the', 'two', 'groups', 'have', 'criticized', 'the', 'election', 'process', 'with', 'the', 'sad', '##c', 'parliamentary', 'forum', 'saying', 'it', 'did', 'not', 'meet', 'the', 'regional', 'grouping', \"'\", 's', 'standards', 'on', 'elections', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 26 in dev.sent..\n",
      "In relation to the first ambiguity , Powell 's words definitely cannot be taken seriously , considering that precisely Washington is the one that has been practicing a one-sided approach to the events in the Middle East for 18 months now and it was the chief opponent of the positioning of peace troops between the two warring sides .\n",
      "['in', 'relation', 'to', 'the', 'first', 'ambiguity', ',', 'powell', \"'\", 's', 'words', 'definitely', 'cannot', 'be', 'taken', 'seriously', ',', 'considering', 'that', 'precisely', 'washington', 'is', 'the', 'one', 'that', 'has', 'been', 'practicing', 'a', 'one', '-', 'sided', 'approach', 'to', 'the', 'events', 'in', 'the', 'middle', 'east', 'for', '18', 'months', 'now', 'and', 'it', 'was', 'the', 'chief', 'opponent', 'of', 'the', 'positioning', 'of', 'peace', 'troops', 'between', 'the', 'two', 'warring', 'sides', '.']\n",
      "['in', 'relation', 'to', 'the', 'first', 'ambiguity', ',', 'powell', \"'\", 's', 'words', 'definitely', 'can', 'not', 'be', 'taken', 'seriously', ',', 'considering', 'that', 'precisely', 'washington', 'is', 'the', 'one', 'that', 'has', 'been', 'practicing', 'a', 'one', '-', 'sided', 'approach', 'to', 'the', 'events', 'in', 'the', 'middle', 'east', 'for', '18', 'months', 'now', 'and', 'it', 'was', 'the', 'chief', 'opponent', 'of', 'the', 'positioning', 'of', 'peace', 'troops', 'between', 'the', 'two', 'warring', 'sides', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 51 in dev.sent..\n",
      "Clinton said he did not support independence for Taiwan , the policy of \" two Chinas \" or \" one China , one Taiwan \" and agreed that Taiwan should not be a member of any organisation to which statehood is a requirement .\n",
      "['clinton', 'said', 'he', 'did', 'not', 'support', 'independence', 'for', 'taiwan', ',', 'the', 'policy', 'of', '\"', 'two', 'china', '##s', '\"', 'or', '\"', 'one', 'china', ',', 'one', 'taiwan', '\"', 'and', 'agreed', 'that', 'taiwan', 'should', 'not', 'be', 'a', 'member', 'of', 'any', 'organisation', 'to', 'which', 'statehood', 'is', 'a', 'requirement', '.']\n",
      "['clinton', 'said', 'he', 'did', 'not', 'support', 'independence', 'for', 'taiwan', ',', 'the', 'policy', 'of', '\"', 'two', 'china', '##s', '\"', 'or', '\"', 'one', 'china', ',', 'one', 'taiwan', '\"', 'and', 'agreed', 'that', 'taiwan', 'should', 'not', 'be', 'a', 'member', 'of', 'any', 'organization', 'to', 'which', 'statehood', 'is', 'a', 'requirement', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 53 in dev.sent..\n",
      "If the rate of increase in greenhouse gases had been maintained at the peak reached in 1980 , the climate by 2050 would have reached temperatures not currently anticipated until 2100 , when CO 2 concentrations in the atmosphere are expected to have doubled , the researchers calculate .\n",
      "['if', 'the', 'rate', 'of', 'increase', 'in', 'greenhouse', 'gases', 'had', 'been', 'maintained', 'at', 'the', 'peak', 'reached', 'in', '1980', ',', 'the', 'climate', 'by', '205', '##0', 'would', 'have', 'reached', 'temperatures', 'not', 'currently', 'anticipated', 'until', '210', '##0', ',', 'when', 'co', '2', 'concentrations', 'in', 'the', 'atmosphere', 'are', 'expected', 'to', 'have', 'doubled', ',', 'the', 'researchers', 'calculate', '.']\n",
      "['if', 'the', 'rate', 'of', 'increase', 'in', 'greenhouse', 'gas', '##ses', 'had', 'been', 'maintained', 'at', 'the', 'peak', 'reached', 'in', '1980', ',', 'the', 'climate', 'by', '205', '##0', 'would', 'have', 'reached', 'temperatures', 'not', 'currently', 'anticipated', 'until', '210', '##0', ',', 'when', 'co', '2', 'concentrations', 'in', 'the', 'atmosphere', 'are', 'expected', 'to', 'have', 'doubled', ',', 'the', 'researchers', 'calculate', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 71 in dev.sent..\n",
      "` ` I expect the Turkish world to resist to that as much as Turkey does and to act consciously to defend the law and justice , `` he said .\n",
      "['`', '`', 'i', 'expect', 'the', 'turkish', 'world', 'to', 'resist', 'to', 'that', 'as', 'much', 'as', 'turkey', 'does', 'and', 'to', 'act', 'consciously', 'to', 'defend', 'the', 'law', 'and', 'justice', ',', '`', '`', 'he', 'said', '.']\n",
      "[\"'\", \"'\", 'i', 'expect', 'the', 'turkish', 'world', 'to', 'resist', 'to', 'that', 'as', 'much', 'as', 'turkey', 'does', 'and', 'to', 'act', 'consciously', 'to', 'defend', 'the', 'law', 'and', 'justice', ',', \"'\", \"'\", 'he', 'said', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 72 in dev.sent..\n",
      "I wish the representatives of the Turkish world to bring this message to their friends .``\n",
      "['i', 'wish', 'the', 'representatives', 'of', 'the', 'turkish', 'world', 'to', 'bring', 'this', 'message', 'to', 'their', 'friends', '.', '`', '`']\n",
      "['i', 'wish', 'the', 'representatives', 'of', 'the', 'turkish', 'world', 'to', 'bring', 'this', 'message', 'to', 'their', 'friends', '.', \"'\", \"'\"]\n",
      "\n",
      "\n",
      "Counts not matching on line 74 in dev.sent..\n",
      "` ` We wish them to give up their wish and policy to throw us from the island .\n",
      "['`', '`', 'we', 'wish', 'them', 'to', 'give', 'up', 'their', 'wish', 'and', 'policy', 'to', 'throw', 'us', 'from', 'the', 'island', '.']\n",
      "[\"'\", \"'\", 'we', 'wish', 'them', 'to', 'give', 'up', 'their', 'wish', 'and', 'policy', 'to', 'throw', 'us', 'from', 'the', 'island', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 75 in dev.sent..\n",
      "Also asking for help from the Turkish press , Denktas said that ` `I ask for help from the press as I will negotiate for peace and compromise to solve Cyprus question .\n",
      "['also', 'asking', 'for', 'help', 'from', 'the', 'turkish', 'press', ',', 'den', '##kt', '##as', 'said', 'that', '`', '`', 'i', 'ask', 'for', 'help', 'from', 'the', 'press', 'as', 'i', 'will', 'negotiate', 'for', 'peace', 'and', 'compromise', 'to', 'solve', 'cyprus', 'question', '.']\n",
      "['also', 'asking', 'for', 'help', 'from', 'the', 'turkish', 'press', ',', 'den', '##kt', '##as', 'said', 'that', \"'\", \"'\", 'i', 'ask', 'for', 'help', 'from', 'the', 'press', 'as', 'i', 'will', 'negotiate', 'for', 'peace', 'and', 'compromise', 'to', 'solve', 'cyprus', 'question', '.']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts not matching on line 76 in dev.sent..\n",
      "I would like these representatives to explain the fact to the EU , which forgot the 1960 Constitution that the Turkish Cypriots are not minority and the Greek Cypriot side which wants to join the EU unilaterally and as if it was the legitimate government of Cyprus is not expected in the EU .``\n",
      "['i', 'would', 'like', 'these', 'representatives', 'to', 'explain', 'the', 'fact', 'to', 'the', 'eu', ',', 'which', 'forgot', 'the', '1960', 'constitution', 'that', 'the', 'turkish', 'cypriot', '##s', 'are', 'not', 'minority', 'and', 'the', 'greek', 'cypriot', 'side', 'which', 'wants', 'to', 'join', 'the', 'eu', 'un', '##ila', '##tera', '##lly', 'and', 'as', 'if', 'it', 'was', 'the', 'legitimate', 'government', 'of', 'cyprus', 'is', 'not', 'expected', 'in', 'the', 'eu', '.', '`', '`']\n",
      "['i', 'would', 'like', 'these', 'representatives', 'to', 'explain', 'the', 'fact', 'to', 'the', 'eu', ',', 'which', 'forgot', 'the', '1960', 'constitution', 'that', 'the', 'turkish', 'cypriot', '##s', 'are', 'not', 'minority', 'and', 'the', 'greek', 'cypriot', 'side', 'which', 'wants', 'to', 'join', 'the', 'eu', 'un', '##ila', '##tera', '##lly', 'and', 'as', 'if', 'it', 'was', 'the', 'legitimate', 'government', 'of', 'cyprus', 'is', 'not', 'expected', 'in', 'the', 'eu', '.', \"'\", \"'\"]\n",
      "\n",
      "\n",
      "Counts not matching on line 81 in dev.sent..\n",
      "The team from the organisation 's Council of Ministers , on the other hand , considered the vote a \" true reflection \" of the people 's will .\n",
      "['the', 'team', 'from', 'the', 'organisation', \"'\", 's', 'council', 'of', 'ministers', ',', 'on', 'the', 'other', 'hand', ',', 'considered', 'the', 'vote', 'a', '\"', 'true', 'reflection', '\"', 'of', 'the', 'people', \"'\", 's', 'will', '.']\n",
      "['the', 'team', 'from', 'the', 'organization', \"'\", 's', 'council', 'of', 'ministers', ',', 'on', 'the', 'other', 'hand', ',', 'considered', 'the', 'vote', 'a', '\"', 'true', 'reflection', '\"', 'of', 'the', 'people', \"'\", 's', 'will', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 82 in dev.sent..\n",
      "The Organisation of African Unity ( OAU ) also backed Zimbabwean President Robert Mugabe 's re-election , with its observer team describing the poll as \" transparent , credible , free and fair \" .\n",
      "['the', 'organisation', 'of', 'african', 'unity', '(', 'o', '##au', ')', 'also', 'backed', 'zimbabwe', '##an', 'president', 'robert', 'mug', '##abe', \"'\", 's', 're', '-', 'election', ',', 'with', 'its', 'observer', 'team', 'describing', 'the', 'poll', 'as', '\"', 'transparent', ',', 'credible', ',', 'free', 'and', 'fair', '\"', '.']\n",
      "['the', 'organization', 'of', 'african', 'unity', '(', 'o', '##au', ')', 'also', 'backed', 'zimbabwe', '##an', 'president', 'robert', 'mug', '##abe', \"'\", 's', 're', '-', 'election', ',', 'with', 'its', 'observer', 'team', 'describing', 'the', 'poll', 'as', '\"', 'transparent', ',', 'credible', ',', 'free', 'and', 'fair', '\"', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 84 in dev.sent..\n",
      "The team acknowledged that the election campaign had been characterised by \" polarisation , tension and incidents of violence and intimidation . \"\n",
      "['the', 'team', 'acknowledged', 'that', 'the', 'election', 'campaign', 'had', 'been', 'characterised', 'by', '\"', 'polar', '##isation', ',', 'tension', 'and', 'incidents', 'of', 'violence', 'and', 'intimidation', '.', '\"']\n",
      "['the', 'team', 'acknowledged', 'that', 'the', 'election', 'campaign', 'had', 'been', 'characterized', 'by', '\"', 'polar', '##ization', ',', 'tension', 'and', 'incidents', 'of', 'violence', 'and', 'intimidation', '.', '\"']\n",
      "\n",
      "\n",
      "Counts not matching on line 93 in dev.sent..\n",
      "The hand symbolised reconciliation ; and Blair accepted it .\n",
      "['the', 'hand', 'symbol', '##ised', 'reconciliation', ';', 'and', 'blair', 'accepted', 'it', '.']\n",
      "['the', 'hand', 'symbol', '##ized', 'reconciliation', ';', 'and', 'blair', 'accepted', 'it', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 95 in dev.sent..\n",
      "The Commonwealth leaders , many of them in the first place unable to understand the dispute between Zimbabwe and its former coloniser , Britain , breathed a collective sigh of relief at what they hoped was the beginning of the healing process .\n",
      "['the', 'commonwealth', 'leaders', ',', 'many', 'of', 'them', 'in', 'the', 'first', 'place', 'unable', 'to', 'understand', 'the', 'dispute', 'between', 'zimbabwe', 'and', 'its', 'former', 'colon', '##iser', ',', 'britain', ',', 'breathed', 'a', 'collective', 'sigh', 'of', 'relief', 'at', 'what', 'they', 'hoped', 'was', 'the', 'beginning', 'of', 'the', 'healing', 'process', '.']\n",
      "['the', 'commonwealth', 'leaders', ',', 'many', 'of', 'them', 'in', 'the', 'first', 'place', 'unable', 'to', 'understand', 'the', 'dispute', 'between', 'zimbabwe', 'and', 'its', 'former', 'colon', '##izer', ',', 'britain', ',', 'breathed', 'a', 'collective', 'sigh', 'of', 'relief', 'at', 'what', 'they', 'hoped', 'was', 'the', 'beginning', 'of', 'the', 'healing', 'process', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 104 in dev.sent..\n",
      "For some time , European politicians have threatened to suspend economic ties with Israel -- a move , which in light of close and extensive trade relations between EU member states and Israel , could cause serious damage .\n",
      "['for', 'some', 'time', ',', 'european', 'politicians', 'have', 'threatened', 'to', 'suspend', 'economic', 'ties', 'with', 'israel', '-', '-', 'a', 'move', ',', 'which', 'in', 'light', 'of', 'close', 'and', 'extensive', 'trade', 'relations', 'between', 'eu', 'member', 'states', 'and', 'israel', ',', 'could', 'cause', 'serious', 'damage', '.']\n",
      "['for', 'some', 'time', ',', 'european', 'politicians', 'have', 'threatened', 'to', 'suspend', 'economic', 'ties', 'with', 'israel', '-', 'a', 'move', ',', 'which', 'in', 'light', 'of', 'close', 'and', 'extensive', 'trade', 'relations', 'between', 'eu', 'member', 'states', 'and', 'israel', ',', 'could', 'cause', 'serious', 'damage', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 108 in dev.sent..\n",
      "Countries like France and Belgium are easily capable of voting for sanctions against Israel , but other states -- including Germany and Britain -- have exhibited a more balanced position regarding the Israeli- Palestinian conflict .\n",
      "['countries', 'like', 'france', 'and', 'belgium', 'are', 'easily', 'capable', 'of', 'voting', 'for', 'sanctions', 'against', 'israel', ',', 'but', 'other', 'states', '-', '-', 'including', 'germany', 'and', 'britain', '-', '-', 'have', 'exhibited', 'a', 'more', 'balanced', 'position', 'regarding', 'the', 'israeli', '-', 'palestinian', 'conflict', '.']\n",
      "['countries', 'like', 'france', 'and', 'belgium', 'are', 'easily', 'capable', 'of', 'voting', 'for', 'sanctions', 'against', 'israel', ',', 'but', 'other', 'states', '-', 'including', 'germany', 'and', 'britain', '-', 'have', 'exhibited', 'a', 'more', 'balanced', 'position', 'regarding', 'the', 'israeli', '-', 'palestinian', 'conflict', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 111 in dev.sent..\n",
      "If the Europeans wish to influence Israel in the political arena -- in a direction that many in Israel would support wholeheartedly -- they will not be able to promote their positions in such a manner .\n",
      "['if', 'the', 'europeans', 'wish', 'to', 'influence', 'israel', 'in', 'the', 'political', 'arena', '-', '-', 'in', 'a', 'direction', 'that', 'many', 'in', 'israel', 'would', 'support', 'whole', '##hearted', '##ly', '-', '-', 'they', 'will', 'not', 'be', 'able', 'to', 'promote', 'their', 'positions', 'in', 'such', 'a', 'manner', '.']\n",
      "['if', 'the', 'europeans', 'wish', 'to', 'influence', 'israel', 'in', 'the', 'political', 'arena', '-', 'in', 'a', 'direction', 'that', 'many', 'in', 'israel', 'would', 'support', 'whole', '##hearted', '##ly', '-', 'they', 'will', 'not', 'be', 'able', 'to', 'promote', 'their', 'positions', 'in', 'such', 'a', 'manner', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 113 in dev.sent..\n",
      "TOKYO , Feb 18 ( AFP ) -- US President George W. Bush said Monday that all options were on the table to deal with Iraq , Iran and North Korea , even as Germany warned against any \" adventure \" in Iraq .\n",
      "['tokyo', ',', 'feb', '18', '(', 'af', '##p', ')', '-', '-', 'us', 'president', 'george', 'w', '.', 'bush', 'said', 'monday', 'that', 'all', 'options', 'were', 'on', 'the', 'table', 'to', 'deal', 'with', 'iraq', ',', 'iran', 'and', 'north', 'korea', ',', 'even', 'as', 'germany', 'warned', 'against', 'any', '\"', 'adventure', '\"', 'in', 'iraq', '.']\n",
      "['tokyo', ',', 'feb', '18', '(', 'af', '##p', ')', '-', 'us', 'president', 'george', 'w', '.', 'bush', 'said', 'monday', 'that', 'all', 'options', 'were', 'on', 'the', 'table', 'to', 'deal', 'with', 'iraq', ',', 'iran', 'and', 'north', 'korea', ',', 'even', 'as', 'germany', 'warned', 'against', 'any', '\"', 'adventure', '\"', 'in', 'iraq', '.']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts not matching on line 118 in dev.sent..\n",
      "\" People who love freedom understand that we cannot allow nations that are n't transparent , nations with a terrible history , nations that are so dictatorial they 're willing to starve their people , we ca n't allow them to mate up with terrorist organizations , \" Bush said .\n",
      "['\"', 'people', 'who', 'love', 'freedom', 'understand', 'that', 'we', 'cannot', 'allow', 'nations', 'that', 'are', 'n', \"'\", 't', 'transparent', ',', 'nations', 'with', 'a', 'terrible', 'history', ',', 'nations', 'that', 'are', 'so', 'dictator', '##ial', 'they', \"'\", 're', 'willing', 'to', 'star', '##ve', 'their', 'people', ',', 'we', 'ca', 'n', \"'\", 't', 'allow', 'them', 'to', 'mate', 'up', 'with', 'terrorist', 'organizations', ',', '\"', 'bush', 'said', '.']\n",
      "['\"', 'people', 'who', 'love', 'freedom', 'understand', 'that', 'we', 'can', 'not', 'allow', 'nations', 'that', 'are', 'n', \"'\", 't', 'transparent', ',', 'nations', 'with', 'a', 'terrible', 'history', ',', 'nations', 'that', 'are', 'so', 'dictator', '##ial', 'they', 'are', 'willing', 'to', 'star', '##ve', 'their', 'people', ',', 'we', 'ca', 'n', \"'\", 't', 'allow', 'them', 'to', 'mate', 'up', 'with', 'terrorist', 'organizations', ',', '\"', 'bush', 'said', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 124 in dev.sent..\n",
      "US diplomats say Bush will seek to support Kim's Nobel Prize winning policy by offering new talks with the North , while remaining firm about North Korea 's missile sales and its feared chemical and biological weapons programmes .\n",
      "['us', 'diplomats', 'say', 'bush', 'will', 'seek', 'to', 'support', 'kim', \"'\", 's', 'nobel', 'prize', 'winning', 'policy', 'by', 'offering', 'new', 'talks', 'with', 'the', 'north', ',', 'while', 'remaining', 'firm', 'about', 'north', 'korea', \"'\", 's', 'missile', 'sales', 'and', 'its', 'feared', 'chemical', 'and', 'biological', 'weapons', 'programmes', '.']\n",
      "['us', 'diplomats', 'say', 'bush', 'will', 'seek', 'to', 'support', 'kim', \"'\", 's', 'nobel', 'prize', 'winning', 'policy', 'by', 'offering', 'new', 'talks', 'with', 'the', 'north', ',', 'while', 'remaining', 'firm', 'about', 'north', 'korea', \"'\", 's', 'missile', 'sales', 'and', 'its', 'feared', 'chemical', 'and', 'biological', 'weapons', 'programs', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 128 in dev.sent..\n",
      "In Berlin , Germany 's chief government spokesman Uwe-Karsten Heye told journalists , \" The federal government cannot imagine that the United States government has an interest in engaging in an adventure \" in Iraq .\n",
      "['in', 'berlin', ',', 'germany', \"'\", 's', 'chief', 'government', 'spokesman', 'u', '##we', '-', 'ka', '##rsten', 'hey', '##e', 'told', 'journalists', ',', '\"', 'the', 'federal', 'government', 'cannot', 'imagine', 'that', 'the', 'united', 'states', 'government', 'has', 'an', 'interest', 'in', 'engaging', 'in', 'an', 'adventure', '\"', 'in', 'iraq', '.']\n",
      "['in', 'berlin', ',', 'germany', \"'\", 's', 'chief', 'government', 'spokesman', 'u', '##we', '-', 'ka', '##rsten', 'hey', '##e', 'told', 'journalists', ',', '\"', 'the', 'federal', 'government', 'can', 'not', 'imagine', 'that', 'the', 'united', 'states', 'government', 'has', 'an', 'interest', 'in', 'engaging', 'in', 'an', 'adventure', '\"', 'in', 'iraq', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 130 in dev.sent..\n",
      "Fischer last week sharply criticised Bush 's \" axis of evil \" remarks , telling a newspaper that such a concept \" gets us nowhere . \"\n",
      "['fischer', 'last', 'week', 'sharply', 'criticised', 'bush', \"'\", 's', '\"', 'axis', 'of', 'evil', '\"', 'remarks', ',', 'telling', 'a', 'newspaper', 'that', 'such', 'a', 'concept', '\"', 'gets', 'us', 'nowhere', '.', '\"']\n",
      "['fischer', 'last', 'week', 'sharply', 'criticized', 'bush', \"'\", 's', '\"', 'axis', 'of', 'evil', '\"', 'remarks', ',', 'telling', 'a', 'newspaper', 'that', 'such', 'a', 'concept', '\"', 'gets', 'us', 'nowhere', '.', '\"']\n",
      "\n",
      "\n",
      "Counts not matching on line 133 in dev.sent..\n",
      "\" We also hope that Iraq gives a favourable response and allows UN weapon inspectors \" to return to the country , he added .\n",
      "['\"', 'we', 'also', 'hope', 'that', 'iraq', 'gives', 'a', 'favourable', 'response', 'and', 'allows', 'un', 'weapon', 'inspectors', '\"', 'to', 'return', 'to', 'the', 'country', ',', 'he', 'added', '.']\n",
      "['\"', 'we', 'also', 'hope', 'that', 'iraq', 'gives', 'a', 'favorable', 'response', 'and', 'allows', 'un', 'weapon', 'inspectors', '\"', 'to', 'return', 'to', 'the', 'country', ',', 'he', 'added', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 158 in dev.sent..\n",
      "I do n't , just so I can work in the school I 'll be happy .\n",
      "['i', 'do', 'n', \"'\", 't', ',', 'just', 'so', 'i', 'can', 'work', 'in', 'the', 'school', 'i', \"'\", 'll', 'be', 'happy', '.']\n",
      "['i', 'do', 'n', \"'\", 't', ',', 'just', 'so', 'i', 'can', 'work', 'in', 'the', 'school', 'i', 'will', 'be', 'happy', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 212 in dev.sent..\n",
      "\" So although our international staff went back to Kabul and hope to go back to the other places ... one cannot say it is safe in the country and secure enough .\n",
      "['\"', 'so', 'although', 'our', 'international', 'staff', 'went', 'back', 'to', 'kabul', 'and', 'hope', 'to', 'go', 'back', 'to', 'the', 'other', 'places', '.', '.', '.', 'one', 'cannot', 'say', 'it', 'is', 'safe', 'in', 'the', 'country', 'and', 'secure', 'enough', '.']\n",
      "['\"', 'so', 'although', 'our', 'international', 'staff', 'went', 'back', 'to', 'kabul', 'and', 'hope', 'to', 'go', 'back', 'to', 'the', 'other', 'places', '.', '.', '.', 'one', 'can', 'not', 'say', 'it', 'is', 'safe', 'in', 'the', 'country', 'and', 'secure', 'enough', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 237 in dev.sent..\n",
      "HARARE -- Opposition leader Morgan Tsvangirai has accused Zimbabwean President Robert Mugabe of deliberately withholding food from some areas of the drought - ravaged country as punishment for not voting the correct way in March 's election .\n",
      "['hara', '##re', '-', '-', 'opposition', 'leader', 'morgan', 'ts', '##van', '##gi', '##rai', 'has', 'accused', 'zimbabwe', '##an', 'president', 'robert', 'mug', '##abe', 'of', 'deliberately', 'with', '##holding', 'food', 'from', 'some', 'areas', 'of', 'the', 'drought', '-', 'ravaged', 'country', 'as', 'punishment', 'for', 'not', 'voting', 'the', 'correct', 'way', 'in', 'march', \"'\", 's', 'election', '.']\n",
      "['hara', '##re', '-', 'opposition', 'leader', 'morgan', 'ts', '##van', '##gi', '##rai', 'has', 'accused', 'zimbabwe', '##an', 'president', 'robert', 'mug', '##abe', 'of', 'deliberately', 'with', '##holding', 'food', 'from', 'some', 'areas', 'of', 'the', 'drought', '-', 'ravaged', 'country', 'as', 'punishment', 'for', 'not', 'voting', 'the', 'correct', 'way', 'in', 'march', \"'\", 's', 'election', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 263 in dev.sent..\n",
      "Tehran , April 16 , IRNA -- United Nations Secretary - General Kofi Annan telephoned Hugo Chavez , President of Venezuela on April 15 to express satisfaction that the process of restoring constitutional order in Venezuela was underway .\n",
      "['tehran', ',', 'april', '16', ',', 'ir', '##na', '-', '-', 'united', 'nations', 'secretary', '-', 'general', 'ko', '##fi', 'anna', '##n', 'telephone', '##d', 'hugo', 'chavez', ',', 'president', 'of', 'venezuela', 'on', 'april', '15', 'to', 'express', 'satisfaction', 'that', 'the', 'process', 'of', 'restoring', 'constitutional', 'order', 'in', 'venezuela', 'was', 'underway', '.']\n",
      "['tehran', ',', 'april', '16', ',', 'ir', '##na', '-', 'united', 'nations', 'secretary', '-', 'general', 'ko', '##fi', 'anna', '##n', 'telephone', '##d', 'hugo', 'chavez', ',', 'president', 'of', 'venezuela', 'on', 'april', '15', 'to', 'express', 'satisfaction', 'that', 'the', 'process', 'of', 'restoring', 'constitutional', 'order', 'in', 'venezuela', 'was', 'underway', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 265 in dev.sent..\n",
      "The Secretary - General welcomed the return of calm to the country , and noted his readiness to assist in the effort to strengthen the democratic dialogue , the rule of law and human rights in Venezuela .\n",
      "['the', 'secretary', '-', 'general', 'welcomed', 'the', 'return', 'of', 'calm', 'to', 'the', 'country', ',', 'and', 'noted', 'his', 'readiness', 'to', 'assist', 'in', 'the', 'effort', 'to', 'strengthen', 'the', 'democratic', 'dialogue', ',', 'the', 'rule', 'of', 'law', 'and', 'human', 'rights', 'in', 'venezuela', '.']\n",
      "['the', 'secretary', '-', 'general', 'welcomed', 'the', 'return', 'of', 'calm', 'to', 'the', 'country', ',', 'and', 'noted', 'his', 'readiness', 'to', 'assist', 'in', 'the', 'effort', 'to', 'strengthen', 'the', 'democratic', 'dial', '##og', ',', 'the', 'rule', 'of', 'law', 'and', 'human', 'rights', 'in', 'venezuela', '.']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts not matching on line 269 in dev.sent..\n",
      "Town are wonderful examples of this -- creating labyrinths of narrow alleys and cul-de-sacs that were designed to confuse and to demoralize invaders .\n",
      "['town', 'are', 'wonderful', 'examples', 'of', 'this', '-', '-', 'creating', 'labyrinth', '##s', 'of', 'narrow', 'alley', '##s', 'and', 'cu', '##l', '-', 'de', '-', 'sac', '##s', 'that', 'were', 'designed', 'to', 'confuse', 'and', 'to', 'demo', '##ral', '##ize', 'invaders', '.']\n",
      "['town', 'are', 'wonderful', 'examples', 'of', 'this', '-', 'creating', 'labyrinth', '##s', 'of', 'narrow', 'alley', '##s', 'and', 'cu', '##l', '-', 'de', '-', 'sac', '##s', 'that', 'were', 'designed', 'to', 'confuse', 'and', 'to', 'demo', '##ral', '##ize', 'invaders', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 277 in dev.sent..\n",
      "Australia 's plans to construct a space port on Christmas Island , located just a stone 's throw , a mere 500 kilometres south of Jakarta , has concerned some in the Indonesian Government .\n",
      "['australia', \"'\", 's', 'plans', 'to', 'construct', 'a', 'space', 'port', 'on', 'christmas', 'island', ',', 'located', 'just', 'a', 'stone', \"'\", 's', 'throw', ',', 'a', 'mere', '500', 'kilometres', 'south', 'of', 'jakarta', ',', 'has', 'concerned', 'some', 'in', 'the', 'indonesian', 'government', '.']\n",
      "['australia', \"'\", 's', 'plans', 'to', 'construct', 'a', 'space', 'port', 'on', 'christmas', 'island', ',', 'located', 'just', 'a', 'stone', \"'\", 's', 'throw', ',', 'a', 'mere', '500', 'kilometers', 'south', 'of', 'jakarta', ',', 'has', 'concerned', 'some', 'in', 'the', 'indonesian', 'government', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 281 in dev.sent..\n",
      "\" If Australia then denies the claim , we need only demand that Australia produce proof that the space debris did not originate from its space centre activities .\n",
      "['\"', 'if', 'australia', 'then', 'denies', 'the', 'claim', ',', 'we', 'need', 'only', 'demand', 'that', 'australia', 'produce', 'proof', 'that', 'the', 'space', 'debris', 'did', 'not', 'originate', 'from', 'its', 'space', 'centre', 'activities', '.']\n",
      "['\"', 'if', 'australia', 'then', 'denies', 'the', 'claim', ',', 'we', 'need', 'only', 'demand', 'that', 'australia', 'produce', 'proof', 'that', 'the', 'space', 'debris', 'did', 'not', 'originate', 'from', 'its', 'space', 'center', 'activities', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 284 in dev.sent..\n",
      "\" Australia is not allowed to prevent other states who want to cooperate on its space centre .\n",
      "['\"', 'australia', 'is', 'not', 'allowed', 'to', 'prevent', 'other', 'states', 'who', 'want', 'to', 'cooperate', 'on', 'its', 'space', 'centre', '.']\n",
      "['\"', 'australia', 'is', 'not', 'allowed', 'to', 'prevent', 'other', 'states', 'who', 'want', 'to', 'cooperate', 'on', 'its', 'space', 'center', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 290 in dev.sent..\n",
      "I was pleased to note that your Oct. 23 Centennial Journal item recognized the money - fund concept as one of the significant events of the past century .\n",
      "['i', 'was', 'pleased', 'to', 'note', 'that', 'your', 'oct', '.', '23', 'centennial', 'journal', 'item', 'recognized', 'the', 'money', '-', 'fund', 'concept', 'as', 'one', 'of', 'the', 'significant', 'events', 'of', 'the', 'past', 'century', '.']\n",
      "['i', 'was', 'pleased', 'to', 'note', 'that', 'your', 'october', '23', 'centennial', 'journal', 'item', 'recognized', 'the', 'money', '-', 'fund', 'concept', 'as', 'one', 'of', 'the', 'significant', 'events', 'of', 'the', 'past', 'century', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 293 in dev.sent..\n",
      "Bam on Sunday said she believed Zimbabwe 's election was not free and fair , adding they were not in line with international standards as well as those of her organisation .\n",
      "['bam', 'on', 'sunday', 'said', 'she', 'believed', 'zimbabwe', \"'\", 's', 'election', 'was', 'not', 'free', 'and', 'fair', ',', 'adding', 'they', 'were', 'not', 'in', 'line', 'with', 'international', 'standards', 'as', 'well', 'as', 'those', 'of', 'her', 'organisation', '.']\n",
      "['bam', 'on', 'sunday', 'said', 'she', 'believed', 'zimbabwe', \"'\", 's', 'election', 'was', 'not', 'free', 'and', 'fair', ',', 'adding', 'they', 'were', 'not', 'in', 'line', 'with', 'international', 'standards', 'as', 'well', 'as', 'those', 'of', 'her', 'organization', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 294 in dev.sent..\n",
      "Malinga , who represented South African churches on 50 - member mission , told journalists during breakfast at the Diakonia Council of Churches in Durban , that she was uncomfortable with the manner in which the team had been treated -- even before they left South Africa .\n",
      "['mali', '##nga', ',', 'who', 'represented', 'south', 'african', 'churches', 'on', '50', '-', 'member', 'mission', ',', 'told', 'journalists', 'during', 'breakfast', 'at', 'the', 'dia', '##kon', '##ia', 'council', 'of', 'churches', 'in', 'durban', ',', 'that', 'she', 'was', 'uncomfortable', 'with', 'the', 'manner', 'in', 'which', 'the', 'team', 'had', 'been', 'treated', '-', '-', 'even', 'before', 'they', 'left', 'south', 'africa', '.']\n",
      "['mali', '##nga', ',', 'who', 'represented', 'south', 'african', 'churches', 'on', '50', '-', 'member', 'mission', ',', 'told', 'journalists', 'during', 'breakfast', 'at', 'the', 'dia', '##kon', '##ia', 'council', 'of', 'churches', 'in', 'durban', ',', 'that', 'she', 'was', 'uncomfortable', 'with', 'the', 'manner', 'in', 'which', 'the', 'team', 'had', 'been', 'treated', '-', 'even', 'before', 'they', 'left', 'south', 'africa', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 303 in dev.sent..\n",
      "Harare , March 17 ( XINHUA ) -- Despite Western pressure on him over his re-election victory , Zimbabwean President Robert Mugabe was sworn in on Sunday as the country 's head of state to serve another six -year term .\n",
      "['hara', '##re', ',', 'march', '17', '(', 'xi', '##nh', '##ua', ')', '-', '-', 'despite', 'western', 'pressure', 'on', 'him', 'over', 'his', 're', '-', 'election', 'victory', ',', 'zimbabwe', '##an', 'president', 'robert', 'mug', '##abe', 'was', 'sworn', 'in', 'on', 'sunday', 'as', 'the', 'country', \"'\", 's', 'head', 'of', 'state', 'to', 'serve', 'another', 'six', '-', 'year', 'term', '.']\n",
      "['hara', '##re', ',', 'march', '17', '(', 'xi', '##nh', '##ua', ')', '-', 'despite', 'western', 'pressure', 'on', 'him', 'over', 'his', 're', '-', 'election', 'victory', ',', 'zimbabwe', '##an', 'president', 'robert', 'mug', '##abe', 'was', 'sworn', 'in', 'on', 'sunday', 'as', 'the', 'country', \"'\", 's', 'head', 'of', 'state', 'to', 'serve', 'another', 'six', '-', 'year', 'term', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 326 in dev.sent..\n",
      "but there are some others out there that i do n't believe deserve the money they 're getting\n",
      "['but', 'there', 'are', 'some', 'others', 'out', 'there', 'that', 'i', 'do', 'n', \"'\", 't', 'believe', 'deserve', 'the', 'money', 'they', \"'\", 're', 'getting']\n",
      "['but', 'there', 'are', 'some', 'others', 'out', 'there', 'that', 'i', 'do', 'n', \"'\", 't', 'believe', 'deserve', 'the', 'money', 'they', 'are', 'getting']\n",
      "\n",
      "\n",
      "Counts not matching on line 327 in dev.sent..\n",
      "every once in a while i i like to go on the nights when there 's not anybody out there not very many people out there it 's a lot more fun when you 're not fighting a crowd\n",
      "['every', 'once', 'in', 'a', 'while', 'i', 'i', 'like', 'to', 'go', 'on', 'the', 'nights', 'when', 'there', \"'\", 's', 'not', 'anybody', 'out', 'there', 'not', 'very', 'many', 'people', 'out', 'there', 'it', \"'\", 's', 'a', 'lot', 'more', 'fun', 'when', 'you', \"'\", 're', 'not', 'fighting', 'a', 'crowd']\n",
      "['every', 'once', 'in', 'a', 'while', 'i', 'i', 'like', 'to', 'go', 'on', 'the', 'nights', 'when', 'there', \"'\", 's', 'not', 'anybody', 'out', 'there', 'not', 'very', 'many', 'people', 'out', 'there', 'it', \"'\", 's', 'a', 'lot', 'more', 'fun', 'when', 'you', 'are', 'not', 'fighting', 'a', 'crowd']\n",
      "\n",
      "\n",
      "Counts not matching on line 331 in dev.sent..\n",
      "they 'll try something and then they throw it out and get something else you know and you get tired of that\n",
      "['they', \"'\", 'll', 'try', 'something', 'and', 'then', 'they', 'throw', 'it', 'out', 'and', 'get', 'something', 'else', 'you', 'know', 'and', 'you', 'get', 'tired', 'of', 'that']\n",
      "['they', 'will', 'try', 'something', 'and', 'then', 'they', 'throw', 'it', 'out', 'and', 'get', 'something', 'else', 'you', 'know', 'and', 'you', 'get', 'tired', 'of', 'that']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts not matching on line 332 in dev.sent..\n",
      "hope they 're telling you\n",
      "['hope', 'they', \"'\", 're', 'telling', 'you']\n",
      "['hope', 'they', 'are', 'telling', 'you']\n",
      "\n",
      "\n",
      "Counts not matching on line 333 in dev.sent..\n",
      "yes when i first started teaching i remember i went up to my job and i said okay i want to see a curriculum guide you know so i'll know what i'm suppose to teach and they go we do n't have one of we do n't even know where one is\n",
      "['yes', 'when', 'i', 'first', 'started', 'teaching', 'i', 'remember', 'i', 'went', 'up', 'to', 'my', 'job', 'and', 'i', 'said', 'okay', 'i', 'want', 'to', 'see', 'a', 'curriculum', 'guide', 'you', 'know', 'so', 'i', \"'\", 'll', 'know', 'what', 'i', \"'\", 'm', 'suppose', 'to', 'teach', 'and', 'they', 'go', 'we', 'do', 'n', \"'\", 't', 'have', 'one', 'of', 'we', 'do', 'n', \"'\", 't', 'even', 'know', 'where', 'one', 'is']\n",
      "['yes', 'when', 'i', 'first', 'started', 'teaching', 'i', 'remember', 'i', 'went', 'up', 'to', 'my', 'job', 'and', 'i', 'said', 'okay', 'i', 'want', 'to', 'see', 'a', 'curriculum', 'guide', 'you', 'know', 'so', 'i', 'will', 'know', 'what', 'i', 'am', 'suppose', 'to', 'teach', 'and', 'they', 'go', 'we', 'do', 'n', \"'\", 't', 'have', 'one', 'of', 'we', 'do', 'n', \"'\", 't', 'even', 'know', 'where', 'one', 'is']\n",
      "\n",
      "\n",
      "Counts not matching on line 341 in dev.sent..\n",
      "it was okay it was kind of slow and i felt like it kind of got chopped off at the end you know it just it and i do n't know it one of those movies it 's not going to be around long it 'll be a dollar movie in no time\n",
      "['it', 'was', 'okay', 'it', 'was', 'kind', 'of', 'slow', 'and', 'i', 'felt', 'like', 'it', 'kind', 'of', 'got', 'chopped', 'off', 'at', 'the', 'end', 'you', 'know', 'it', 'just', 'it', 'and', 'i', 'do', 'n', \"'\", 't', 'know', 'it', 'one', 'of', 'those', 'movies', 'it', \"'\", 's', 'not', 'going', 'to', 'be', 'around', 'long', 'it', \"'\", 'll', 'be', 'a', 'dollar', 'movie', 'in', 'no', 'time']\n",
      "['it', 'was', 'okay', 'it', 'was', 'kind', 'of', 'slow', 'and', 'i', 'felt', 'like', 'it', 'kind', 'of', 'got', 'chopped', 'off', 'at', 'the', 'end', 'you', 'know', 'it', 'just', 'it', 'and', 'i', 'do', 'n', \"'\", 't', 'know', 'it', 'one', 'of', 'those', 'movies', 'it', \"'\", 's', 'not', 'going', 'to', 'be', 'around', 'long', 'it', 'will', 'be', 'a', 'dollar', 'movie', 'in', 'no', 'time']\n",
      "\n",
      "\n",
      "Counts not matching on line 343 in dev.sent..\n",
      "TAIPEI , Sept 26 ( AFP ) -- Taiwan President Chen Shui-bian on Wednesday reiterated Taipei 's full support for the United States as Washington prepared to launch reprisals against Afghanistan .\n",
      "['taipei', ',', 'sept', '26', '(', 'af', '##p', ')', '-', '-', 'taiwan', 'president', 'chen', 'shu', '##i', '-', 'bi', '##an', 'on', 'wednesday', 'reiterated', 'taipei', \"'\", 's', 'full', 'support', 'for', 'the', 'united', 'states', 'as', 'washington', 'prepared', 'to', 'launch', 'rep', '##ris', '##als', 'against', 'afghanistan', '.']\n",
      "['taipei', ',', 'sept', '26', '(', 'af', '##p', ')', '-', 'taiwan', 'president', 'chen', 'shu', '##i', '-', 'bi', '##an', 'on', 'wednesday', 'reiterated', 'taipei', \"'\", 's', 'full', 'support', 'for', 'the', 'united', 'states', 'as', 'washington', 'prepared', 'to', 'launch', 'rep', '##ris', '##als', 'against', 'afghanistan', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 349 in dev.sent..\n",
      "He added : \" We are prepared to initiate a dialogue , and we want to work with our friends and allies in the world on ways of dealing with such regimes . \"\n",
      "['he', 'added', ':', '\"', 'we', 'are', 'prepared', 'to', 'initiate', 'a', 'dialogue', ',', 'and', 'we', 'want', 'to', 'work', 'with', 'our', 'friends', 'and', 'allies', 'in', 'the', 'world', 'on', 'ways', 'of', 'dealing', 'with', 'such', 'regimes', '.', '\"']\n",
      "['he', 'added', ':', '\"', 'we', 'are', 'prepared', 'to', 'initiate', 'a', 'dial', '##og', ',', 'and', 'we', 'want', 'to', 'work', 'with', 'our', 'friends', 'and', 'allies', 'in', 'the', 'world', 'on', 'ways', 'of', 'dealing', 'with', 'such', 'regimes', '.', '\"']\n",
      "\n",
      "\n",
      "Counts not matching on line 351 in dev.sent..\n",
      "At any rate , Secretary Powell 's remark about the US administration 's readiness to enter dialogue with these \" evil \" states and with Washington 's friends on ways of dealing with them involves some contradictions .\n",
      "['at', 'any', 'rate', ',', 'secretary', 'powell', \"'\", 's', 'remark', 'about', 'the', 'us', 'administration', \"'\", 's', 'readiness', 'to', 'enter', 'dialogue', 'with', 'these', '\"', 'evil', '\"', 'states', 'and', 'with', 'washington', \"'\", 's', 'friends', 'on', 'ways', 'of', 'dealing', 'with', 'them', 'involves', 'some', 'contradiction', '##s', '.']\n",
      "['at', 'any', 'rate', ',', 'secretary', 'powell', \"'\", 's', 'remark', 'about', 'the', 'us', 'administration', \"'\", 's', 'readiness', 'to', 'enter', 'dial', '##og', 'with', 'these', '\"', 'evil', '\"', 'states', 'and', 'with', 'washington', \"'\", 's', 'friends', 'on', 'ways', 'of', 'dealing', 'with', 'them', 'involves', 'some', 'contradiction', '##s', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 354 in dev.sent..\n",
      "The United States is currently run by a typical Texan mentality , which is closer to that of cowboys than to a civilized mentality that believes in dialogue and coexistence among peoples .\n",
      "['the', 'united', 'states', 'is', 'currently', 'run', 'by', 'a', 'typical', 'tex', '##an', 'mental', '##ity', ',', 'which', 'is', 'closer', 'to', 'that', 'of', 'cowboys', 'than', 'to', 'a', 'civilized', 'mental', '##ity', 'that', 'believes', 'in', 'dialogue', 'and', 'coe', '##xi', '##sten', '##ce', 'among', 'peoples', '.']\n",
      "['the', 'united', 'states', 'is', 'currently', 'run', 'by', 'a', 'typical', 'tex', '##an', 'mental', '##ity', ',', 'which', 'is', 'closer', 'to', 'that', 'of', 'cowboys', 'than', 'to', 'a', 'civilized', 'mental', '##ity', 'that', 'believes', 'in', 'dial', '##og', 'and', 'coe', '##xi', '##sten', '##ce', 'among', 'peoples', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 357 in dev.sent..\n",
      "uh - huh uh- huh yeah sometimes i i get them on my uh answering machine at home so and i hate that when i've got a whole bunch of messages and i go through them and most of them are n't from anybody at all\n",
      "['uh', '-', 'huh', 'uh', '-', 'huh', 'yeah', 'sometimes', 'i', 'i', 'get', 'them', 'on', 'my', 'uh', 'answering', 'machine', 'at', 'home', 'so', 'and', 'i', 'hate', 'that', 'when', 'i', \"'\", 've', 'got', 'a', 'whole', 'bunch', 'of', 'messages', 'and', 'i', 'go', 'through', 'them', 'and', 'most', 'of', 'them', 'are', 'n', \"'\", 't', 'from', 'anybody', 'at', 'all']\n",
      "['uh', '-', 'huh', 'uh', '-', 'huh', 'yeah', 'sometimes', 'i', 'i', 'get', 'them', 'on', 'my', 'uh', 'answering', 'machine', 'at', 'home', 'so', 'and', 'i', 'hate', 'that', 'when', 'i', 'have', 'got', 'a', 'whole', 'bunch', 'of', 'messages', 'and', 'i', 'go', 'through', 'them', 'and', 'most', 'of', 'them', 'are', 'n', \"'\", 't', 'from', 'anybody', 'at', 'all']\n",
      "\n",
      "\n",
      "Counts not matching on line 360 in dev.sent..\n",
      "um - hum um - hum yeah that 's true living in an apartment complex though you know you ca n't um you ca n't really stop those people from coming around even though they put up signs out front that says no solicitations uh but they still come up to the front door and uh you know walk around so usually what i do is i'll call the apartment manager and tell him hey there 's people coming around you know and they 're trying to sell something or or they 're from a religious organization and i really hate that i really really do i had somebody come to the door about two weeks ago and um gosh it was about nine o'clock at night too it was n't even what i would consider you know a family hour it 's time to you know start going to bed and uh and it was somebody from um oh what was it the uh Jesus Christ of Latter Day Saints and uh i've read a lot about uh that particular sect and i do n't particularly care for it so i especially do n't like for them to come up to my door and try and talk to me\n",
      "['um', '-', 'hum', 'um', '-', 'hum', 'yeah', 'that', \"'\", 's', 'true', 'living', 'in', 'an', 'apartment', 'complex', 'though', 'you', 'know', 'you', 'ca', 'n', \"'\", 't', 'um', 'you', 'ca', 'n', \"'\", 't', 'really', 'stop', 'those', 'people', 'from', 'coming', 'around', 'even', 'though', 'they', 'put', 'up', 'signs', 'out', 'front', 'that', 'says', 'no', 'sol', '##ici', '##tation', '##s', 'uh', 'but', 'they', 'still', 'come', 'up', 'to', 'the', 'front', 'door', 'and', 'uh', 'you', 'know', 'walk', 'around', 'so', 'usually', 'what', 'i', 'do', 'is', 'i', \"'\", 'll', 'call', 'the', 'apartment', 'manager', 'and', 'tell', 'him', 'hey', 'there', \"'\", 's', 'people', 'coming', 'around', 'you', 'know', 'and', 'they', \"'\", 're', 'trying', 'to', 'sell', 'something', 'or', 'or', 'they', \"'\", 're', 'from', 'a', 'religious', 'organization', 'and', 'i', 'really', 'hate', 'that', 'i', 'really', 'really', 'do', 'i', 'had', 'somebody', 'come', 'to', 'the', 'door', 'about', 'two', 'weeks', 'ago', 'and', 'um', 'go', '##sh', 'it', 'was', 'about', 'nine', 'o', \"'\", 'clock', 'at', 'night', 'too', 'it', 'was', 'n', \"'\", 't', 'even', 'what', 'i', 'would', 'consider', 'you', 'know', 'a', 'family', 'hour', 'it', \"'\", 's', 'time', 'to', 'you', 'know', 'start', 'going', 'to', 'bed', 'and', 'uh', 'and', 'it', 'was', 'somebody', 'from', 'um', 'oh', 'what', 'was', 'it', 'the', 'uh', 'jesus', 'christ', 'of', 'latter', 'day', 'saints', 'and', 'uh', 'i', \"'\", 've', 'read', 'a', 'lot', 'about', 'uh', 'that', 'particular', 'sect', 'and', 'i', 'do', 'n', \"'\", 't', 'particularly', 'care', 'for', 'it', 'so', 'i', 'especially', 'do', 'n', \"'\", 't', 'like', 'for', 'them', 'to', 'come', 'up', 'to', 'my', 'door', 'and', 'try', 'and', 'talk', 'to', 'me']\n",
      "['um', '-', 'hum', 'um', '-', 'hum', 'yeah', 'that', \"'\", 's', 'true', 'living', 'in', 'an', 'apartment', 'complex', 'though', 'you', 'know', 'you', 'ca', 'n', \"'\", 't', 'um', 'you', 'ca', 'n', \"'\", 't', 'really', 'stop', 'those', 'people', 'from', 'coming', 'around', 'even', 'though', 'they', 'put', 'up', 'signs', 'out', 'front', 'that', 'says', 'no', 'sol', '##ici', '##tation', '##s', 'uh', 'but', 'they', 'still', 'come', 'up', 'to', 'the', 'front', 'door', 'and', 'uh', 'you', 'know', 'walk', 'around', 'so', 'usually', 'what', 'i', 'do', 'is', 'i', 'will', 'call', 'the', 'apartment', 'manager', 'and', 'tell', 'him', 'hey', 'there', \"'\", 's', 'people', 'coming', 'around', 'you', 'know', 'and', 'they', 'are', 'trying', 'to', 'sell', 'something', 'or', 'or', 'they', 'are', 'from', 'a', 'religious', 'organization', 'and', 'i', 'really', 'hate', 'that', 'i', 'really', 'really', 'do', 'i', 'had', 'somebody', 'come', 'to', 'the', 'door', 'about', 'two', 'weeks', 'ago', 'and', 'um', 'go', '##sh', 'it', 'was', 'about', 'nine', 'o', \"'\", 'clock', 'at', 'night', 'too', 'it', 'was', 'n', \"'\", 't', 'even', 'what', 'i', 'would', 'consider', 'you', 'know', 'a', 'family', 'hour', 'it', \"'\", 's', 'time', 'to', 'you', 'know', 'start', 'going', 'to', 'bed', 'and', 'uh', 'and', 'it', 'was', 'somebody', 'from', 'um', 'oh', 'what', 'was', 'it', 'the', 'uh', 'jesus', 'christ', 'of', 'latter', 'day', 'saints', 'and', 'uh', 'i', 'have', 'read', 'a', 'lot', 'about', 'uh', 'that', 'particular', 'sect', 'and', 'i', 'do', 'n', \"'\", 't', 'particularly', 'care', 'for', 'it', 'so', 'i', 'especially', 'do', 'n', \"'\", 't', 'like', 'for', 'them', 'to', 'come', 'up', 'to', 'my', 'door', 'and', 'try', 'and', 'talk', 'to', 'me']\n",
      "\n",
      "\n",
      "Counts not matching on line 361 in dev.sent..\n",
      "i'm on my turf if i want them there i'll call for them otherwise i do n't want to know they exist\n",
      "['i', \"'\", 'm', 'on', 'my', 'turf', 'if', 'i', 'want', 'them', 'there', 'i', \"'\", 'll', 'call', 'for', 'them', 'otherwise', 'i', 'do', 'n', \"'\", 't', 'want', 'to', 'know', 'they', 'exist']\n",
      "['i', 'am', 'on', 'my', 'turf', 'if', 'i', 'want', 'them', 'there', 'i', 'will', 'call', 'for', 'them', 'otherwise', 'i', 'do', 'n', \"'\", 't', 'want', 'to', 'know', 'they', 'exist']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts not matching on line 363 in dev.sent..\n",
      "uh pretty close to it well i've enjoyed talking with you\n",
      "['uh', 'pretty', 'close', 'to', 'it', 'well', 'i', \"'\", 've', 'enjoyed', 'talking', 'with', 'you']\n",
      "['uh', 'pretty', 'close', 'to', 'it', 'well', 'i', 'have', 'enjoyed', 'talking', 'with', 'you']\n",
      "\n",
      "\n",
      "Counts not matching on line 369 in dev.sent..\n",
      "The announcement of a plan that is supposedly an alternative to the Kyoto Protocol , but which in practice rejects it in a way that cannot be taken seriously by the countries who committed themselves to it ( among which is Brazil ) , only deserves rejection in response and to provoke in retrospect an enormous concern about what the only world superpower intends in future .\n",
      "['the', 'announcement', 'of', 'a', 'plan', 'that', 'is', 'supposedly', 'an', 'alternative', 'to', 'the', 'kyoto', 'protocol', ',', 'but', 'which', 'in', 'practice', 'rejects', 'it', 'in', 'a', 'way', 'that', 'cannot', 'be', 'taken', 'seriously', 'by', 'the', 'countries', 'who', 'committed', 'themselves', 'to', 'it', '(', 'among', 'which', 'is', 'brazil', ')', ',', 'only', 'deserves', 'rejection', 'in', 'response', 'and', 'to', 'provoke', 'in', 'retro', '##sp', '##ect', 'an', 'enormous', 'concern', 'about', 'what', 'the', 'only', 'world', 'super', '##power', 'intends', 'in', 'future', '.']\n",
      "['the', 'announcement', 'of', 'a', 'plan', 'that', 'is', 'supposedly', 'an', 'alternative', 'to', 'the', 'kyoto', 'protocol', ',', 'but', 'which', 'in', 'practice', 'rejects', 'it', 'in', 'a', 'way', 'that', 'can', 'not', 'be', 'taken', 'seriously', 'by', 'the', 'countries', 'who', 'committed', 'themselves', 'to', 'it', '(', 'among', 'which', 'is', 'brazil', ')', ',', 'only', 'deserves', 'rejection', 'in', 'response', 'and', 'to', 'provoke', 'in', 'retro', '##sp', '##ect', 'an', 'enormous', 'concern', 'about', 'what', 'the', 'only', 'world', 'super', '##power', 'intends', 'in', 'future', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 370 in dev.sent..\n",
      "It is not implementing an immediate and total withdrawal -- as demanded by the international community as a whole and the United States in particular -- but a phased and partial withdrawal .\n",
      "['it', 'is', 'not', 'implementing', 'an', 'immediate', 'and', 'total', 'withdrawal', '-', '-', 'as', 'demanded', 'by', 'the', 'international', 'community', 'as', 'a', 'whole', 'and', 'the', 'united', 'states', 'in', 'particular', '-', '-', 'but', 'a', 'phased', 'and', 'partial', 'withdrawal', '.']\n",
      "['it', 'is', 'not', 'implementing', 'an', 'immediate', 'and', 'total', 'withdrawal', '-', 'as', 'demanded', 'by', 'the', 'international', 'community', 'as', 'a', 'whole', 'and', 'the', 'united', 'states', 'in', 'particular', '-', 'but', 'a', 'phased', 'and', 'partial', 'withdrawal', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 374 in dev.sent..\n",
      "\" Attitudes { toward being acquired } are still negative , but they 're becoming more positive , \" Mr. Murasawa said .\n",
      "['\"', 'attitudes', '{', 'toward', 'being', 'acquired', '}', 'are', 'still', 'negative', ',', 'but', 'they', \"'\", 're', 'becoming', 'more', 'positive', ',', '\"', 'mr', '.', 'mu', '##ras', '##awa', 'said', '.']\n",
      "['\"', 'attitudes', '{', 'toward', 'being', 'acquired', '}', 'are', 'still', 'negative', ',', 'but', 'they', 'are', 'becoming', 'more', 'positive', ',', '\"', 'mr', '.', 'mu', '##ras', '##awa', 'said', '.']\n",
      "\n",
      "\n",
      "[9, 26, 51, 53, 71, 72, 74, 75, 76, 81, 82, 84, 93, 95, 104, 108, 111, 113, 118, 124, 128, 130, 133, 158, 212, 237, 263, 265, 269, 277, 281, 284, 290, 293, 294, 303, 326, 327, 331, 332, 333, 341, 343, 349, 351, 354, 357, 360, 361, 363, 369, 370, 374]\n",
      "Deleted\n",
      "323\n",
      "\n",
      "\n",
      "Deleted\n",
      "323\n",
      "\n",
      "\n",
      "Deleted\n",
      "323\n",
      "\n",
      "\n",
      "Counts not matching on line 14 in test.sent..\n",
      "The way in which Pakistan has been fully supporting the United States after 11 September 2001 -- the total benefit of that has been earned by the United States .\n",
      "['the', 'way', 'in', 'which', 'pakistan', 'has', 'been', 'fully', 'supporting', 'the', 'united', 'states', 'after', '11', 'september', '2001', '-', '-', 'the', 'total', 'benefit', 'of', 'that', 'has', 'been', 'earned', 'by', 'the', 'united', 'states', '.']\n",
      "['the', 'way', 'in', 'which', 'pakistan', 'has', 'been', 'fully', 'supporting', 'the', 'united', 'states', 'after', '11', 'september', '2001', '-', 'the', 'total', 'benefit', 'of', 'that', 'has', 'been', 'earned', 'by', 'the', 'united', 'states', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 21 in test.sent..\n",
      "The Argentine TV station Todo Noticias [ \" All News \" ] reported yesterday that President Fernando Henrique Cardoso on Saturday night telephoned Cordoba Province Governor Jose Manuel de la Sota , of the Justicialist Party ( PJ ) -- who once served as ambassador to Brazil -- to voice his concern over incidents in the country .\n",
      "['the', 'argentine', 'tv', 'station', 'tod', '##o', 'not', '##icia', '##s', '[', '\"', 'all', 'news', '\"', ']', 'reported', 'yesterday', 'that', 'president', 'fernando', 'henri', '##que', 'card', '##oso', 'on', 'saturday', 'night', 'telephone', '##d', 'cordoba', 'province', 'governor', 'jose', 'manuel', 'de', 'la', 'so', '##ta', ',', 'of', 'the', 'just', '##icia', '##list', 'party', '(', 'p', '##j', ')', '-', '-', 'who', 'once', 'served', 'as', 'ambassador', 'to', 'brazil', '-', '-', 'to', 'voice', 'his', 'concern', 'over', 'incidents', 'in', 'the', 'country', '.']\n",
      "['the', 'argentine', 'tv', 'station', 'tod', '##o', 'not', '##icia', '##s', '[', '\"', 'all', 'news', '\"', ']', 'reported', 'yesterday', 'that', 'president', 'fernando', 'henri', '##que', 'card', '##oso', 'on', 'saturday', 'night', 'telephone', '##d', 'cordoba', 'province', 'governor', 'jose', 'manuel', 'de', 'la', 'so', '##ta', ',', 'of', 'the', 'just', '##icia', '##list', 'party', '(', 'p', '##j', ')', '-', 'who', 'once', 'served', 'as', 'ambassador', 'to', 'brazil', '-', 'to', 'voice', 'his', 'concern', 'over', 'incidents', 'in', 'the', 'country', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 28 in test.sent..\n",
      "Senator Heloisa Helena ( Workers Party -- Alagoas ) said that Latin American countries should always join together to speak with international economic institutions , in order to maintain autonomy in their economies : \" Now we see what happens when one country abdicates its financial autonomy .\n",
      "['senator', 'he', '##lo', '##isa', 'helena', '(', 'workers', 'party', '-', '-', 'ala', '##go', '##as', ')', 'said', 'that', 'latin', 'american', 'countries', 'should', 'always', 'join', 'together', 'to', 'speak', 'with', 'international', 'economic', 'institutions', ',', 'in', 'order', 'to', 'maintain', 'autonomy', 'in', 'their', 'economies', ':', '\"', 'now', 'we', 'see', 'what', 'happens', 'when', 'one', 'country', 'abd', '##icate', '##s', 'its', 'financial', 'autonomy', '.']\n",
      "['senator', 'he', '##lo', '##isa', 'helena', '(', 'workers', 'party', '-', 'ala', '##go', '##as', ')', 'said', 'that', 'latin', 'american', 'countries', 'should', 'always', 'join', 'together', 'to', 'speak', 'with', 'international', 'economic', 'institutions', ',', 'in', 'order', 'to', 'maintain', 'autonomy', 'in', 'their', 'economies', ':', '\"', 'now', 'we', 'see', 'what', 'happens', 'when', 'one', 'country', 'abd', '##icate', '##s', 'its', 'financial', 'autonomy', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 34 in test.sent..\n",
      "Dostum also favoured a possible return of Afghanistan 's former King Mohammad Zaher Shah .\n",
      "['dos', '##tum', 'also', 'favoured', 'a', 'possible', 'return', 'of', 'afghanistan', \"'\", 's', 'former', 'king', 'mohammad', 'za', '##her', 'shah', '.']\n",
      "['dos', '##tum', 'also', 'favored', 'a', 'possible', 'return', 'of', 'afghanistan', \"'\", 's', 'former', 'king', 'mohammad', 'za', '##her', 'shah', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 35 in test.sent..\n",
      "With the signing of the protocol , he said , GCEP hopes to attract more funding to contribute to the international community 's efforts in reducing greenhouse gases , which trap heat in the earth 's atmosphere thus causing climate change .\n",
      "['with', 'the', 'signing', 'of', 'the', 'protocol', ',', 'he', 'said', ',', 'g', '##ce', '##p', 'hopes', 'to', 'attract', 'more', 'funding', 'to', 'contribute', 'to', 'the', 'international', 'community', \"'\", 's', 'efforts', 'in', 'reducing', 'greenhouse', 'gases', ',', 'which', 'trap', 'heat', 'in', 'the', 'earth', \"'\", 's', 'atmosphere', 'thus', 'causing', 'climate', 'change', '.']\n",
      "['with', 'the', 'signing', 'of', 'the', 'protocol', ',', 'he', 'said', ',', 'g', '##ce', '##p', 'hopes', 'to', 'attract', 'more', 'funding', 'to', 'contribute', 'to', 'the', 'international', 'community', \"'\", 's', 'efforts', 'in', 'reducing', 'greenhouse', 'gas', '##ses', ',', 'which', 'trap', 'heat', 'in', 'the', 'earth', \"'\", 's', 'atmosphere', 'thus', 'causing', 'climate', 'change', '.']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts not matching on line 39 in test.sent..\n",
      "Beijing , December 20 ( XINHUA ) -- China believes that the Argentine government and people will overcome the current difficulties , revive their economy and maintain their social stability , said Chinese Foreign Ministry Spokeswoman Zhang Qiyue here Thursday .\n",
      "['beijing', ',', 'december', '20', '(', 'xi', '##nh', '##ua', ')', '-', '-', 'china', 'believes', 'that', 'the', 'argentine', 'government', 'and', 'people', 'will', 'overcome', 'the', 'current', 'difficulties', ',', 'revive', 'their', 'economy', 'and', 'maintain', 'their', 'social', 'stability', ',', 'said', 'chinese', 'foreign', 'ministry', 'spoke', '##sw', '##oman', 'zhang', 'qi', '##yu', '##e', 'here', 'thursday', '.']\n",
      "['beijing', ',', 'december', '20', '(', 'xi', '##nh', '##ua', ')', '-', 'china', 'believes', 'that', 'the', 'argentine', 'government', 'and', 'people', 'will', 'overcome', 'the', 'current', 'difficulties', ',', 'revive', 'their', 'economy', 'and', 'maintain', 'their', 'social', 'stability', ',', 'said', 'chinese', 'foreign', 'ministry', 'spoke', '##sw', '##oman', 'zhang', 'qi', '##yu', '##e', 'here', 'thursday', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 41 in test.sent..\n",
      "Following the presidential vote in Zimbabwe , there is just one thing Robert Mugabe cannot be reproached for , and that is having made a secret of his determination to stay in power by every possible means .\n",
      "['following', 'the', 'presidential', 'vote', 'in', 'zimbabwe', ',', 'there', 'is', 'just', 'one', 'thing', 'robert', 'mug', '##abe', 'cannot', 'be', 'rep', '##ro', '##ache', '##d', 'for', ',', 'and', 'that', 'is', 'having', 'made', 'a', 'secret', 'of', 'his', 'determination', 'to', 'stay', 'in', 'power', 'by', 'every', 'possible', 'means', '.']\n",
      "['following', 'the', 'presidential', 'vote', 'in', 'zimbabwe', ',', 'there', 'is', 'just', 'one', 'thing', 'robert', 'mug', '##abe', 'can', 'not', 'be', 'rep', '##ro', '##ache', '##d', 'for', ',', 'and', 'that', 'is', 'having', 'made', 'a', 'secret', 'of', 'his', 'determination', 'to', 'stay', 'in', 'power', 'by', 'every', 'possible', 'means', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 119 in test.sent..\n",
      "With the signing of the protocol , he said , GCEP hopes to attract more funding to contribute to the international community 's efforts in reducing greenhouse gases , which trap heat in the earth 's atmosphere thus causing climate change .\n",
      "['with', 'the', 'signing', 'of', 'the', 'protocol', ',', 'he', 'said', ',', 'g', '##ce', '##p', 'hopes', 'to', 'attract', 'more', 'funding', 'to', 'contribute', 'to', 'the', 'international', 'community', \"'\", 's', 'efforts', 'in', 'reducing', 'greenhouse', 'gases', ',', 'which', 'trap', 'heat', 'in', 'the', 'earth', \"'\", 's', 'atmosphere', 'thus', 'causing', 'climate', 'change', '.']\n",
      "['with', 'the', 'signing', 'of', 'the', 'protocol', ',', 'he', 'said', ',', 'g', '##ce', '##p', 'hopes', 'to', 'attract', 'more', 'funding', 'to', 'contribute', 'to', 'the', 'international', 'community', \"'\", 's', 'efforts', 'in', 'reducing', 'greenhouse', 'gas', '##ses', ',', 'which', 'trap', 'heat', 'in', 'the', 'earth', \"'\", 's', 'atmosphere', 'thus', 'causing', 'climate', 'change', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 128 in test.sent..\n",
      "But U.S. Army Capt. Darrell Sides , 30 , of Fort Benning , Ga. , makes no bones about considering them terrorists .\n",
      "['but', 'u', '.', 's', '.', 'army', 'capt', '.', 'darrell', 'sides', ',', '30', ',', 'of', 'fort', 'ben', '##ning', ',', 'ga', '.', ',', 'makes', 'no', 'bones', 'about', 'considering', 'them', 'terrorists', '.']\n",
      "['but', 'u', '.', 's', '.', 'army', 'capt', '.', 'darrell', 'sides', ',', '30', ',', 'of', 'fort', 'ben', '##ning', ',', 'georgia', ',', 'makes', 'no', 'bones', 'about', 'considering', 'them', 'terrorists', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 133 in test.sent..\n",
      "Paris , July 11 ( CNA ) -- Taiwan 's economy will become totally dependent on mainland China within the next few years , causing the island to lose control of its own political fate , a French weekly warned Thursday .\n",
      "['paris', ',', 'july', '11', '(', 'cn', '##a', ')', '-', '-', 'taiwan', \"'\", 's', 'economy', 'will', 'become', 'totally', 'dependent', 'on', 'mainland', 'china', 'within', 'the', 'next', 'few', 'years', ',', 'causing', 'the', 'island', 'to', 'lose', 'control', 'of', 'its', 'own', 'political', 'fate', ',', 'a', 'french', 'weekly', 'warned', 'thursday', '.']\n",
      "['paris', ',', 'july', '11', '(', 'cn', '##a', ')', '-', 'taiwan', \"'\", 's', 'economy', 'will', 'become', 'totally', 'dependent', 'on', 'mainland', 'china', 'within', 'the', 'next', 'few', 'years', ',', 'causing', 'the', 'island', 'to', 'lose', 'control', 'of', 'its', 'own', 'political', 'fate', ',', 'a', 'french', 'weekly', 'warned', 'thursday', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 142 in test.sent..\n",
      "Tehran , April 20 , IRNA -- President Mohammad Khatami on Friday evening congratulated the Venezuelan government and nation for the victory and restoration of the legitimate government of President Hugo Chavez after a failed military coup in that country .\n",
      "['tehran', ',', 'april', '20', ',', 'ir', '##na', '-', '-', 'president', 'mohammad', 'k', '##hat', '##ami', 'on', 'friday', 'evening', 'cong', '##rat', '##ulated', 'the', 'venezuelan', 'government', 'and', 'nation', 'for', 'the', 'victory', 'and', 'restoration', 'of', 'the', 'legitimate', 'government', 'of', 'president', 'hugo', 'chavez', 'after', 'a', 'failed', 'military', 'coup', 'in', 'that', 'country', '.']\n",
      "['tehran', ',', 'april', '20', ',', 'ir', '##na', '-', 'president', 'mohammad', 'k', '##hat', '##ami', 'on', 'friday', 'evening', 'cong', '##rat', '##ulated', 'the', 'venezuelan', 'government', 'and', 'nation', 'for', 'the', 'victory', 'and', 'restoration', 'of', 'the', 'legitimate', 'government', 'of', 'president', 'hugo', 'chavez', 'after', 'a', 'failed', 'military', 'coup', 'in', 'that', 'country', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 174 in test.sent..\n",
      "However , the massive participation of millions of Iranians in the grand rallies on Feb. 11 to mark the anniversary of the victory of the Islamic Revolution and defy U.S. threats against this country once again revealed the emptiness of U.S. charges against Iran .\n",
      "['however', ',', 'the', 'massive', 'participation', 'of', 'millions', 'of', 'iranian', '##s', 'in', 'the', 'grand', 'rallies', 'on', 'feb', '.', '11', 'to', 'mark', 'the', 'anniversary', 'of', 'the', 'victory', 'of', 'the', 'islamic', 'revolution', 'and', 'def', '##y', 'u', '.', 's', '.', 'threats', 'against', 'this', 'country', 'once', 'again', 'revealed', 'the', 'emptiness', 'of', 'u', '.', 's', '.', 'charges', 'against', 'iran', '.']\n",
      "['however', ',', 'the', 'massive', 'participation', 'of', 'millions', 'of', 'iranian', '##s', 'in', 'the', 'grand', 'rallies', 'on', 'february', '11', 'to', 'mark', 'the', 'anniversary', 'of', 'the', 'victory', 'of', 'the', 'islamic', 'revolution', 'and', 'def', '##y', 'u', '.', 's', '.', 'threats', 'against', 'this', 'country', 'once', 'again', 'revealed', 'the', 'emptiness', 'of', 'u', '.', 's', '.', 'charges', 'against', 'iran', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 196 in test.sent..\n",
      "\" Sometimes you 're afraid for your life because these people are trained to kill you , \" said Specialist Fabian Rivas .\n",
      "['\"', 'sometimes', 'you', \"'\", 're', 'afraid', 'for', 'your', 'life', 'because', 'these', 'people', 'are', 'trained', 'to', 'kill', 'you', ',', '\"', 'said', 'specialist', 'fabian', 'ri', '##vas', '.']\n",
      "['\"', 'sometimes', 'you', 'are', 'afraid', 'for', 'your', 'life', 'because', 'these', 'people', 'are', 'trained', 'to', 'kill', 'you', ',', '\"', 'said', 'specialist', 'fabian', 'ri', '##vas', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 208 in test.sent..\n",
      "Russia 's Ambassador to Mongolia Oleg Derkovskiy believes that there are no problems in relations between the two states and the common border stretching for 3,500 kilometres is a border of peace and good neighbourliness .\n",
      "['russia', \"'\", 's', 'ambassador', 'to', 'mongolia', 'oleg', 'der', '##kov', '##ski', '##y', 'believes', 'that', 'there', 'are', 'no', 'problems', 'in', 'relations', 'between', 'the', 'two', 'states', 'and', 'the', 'common', 'border', 'stretching', 'for', '3', ',', '500', 'kilometres', 'is', 'a', 'border', 'of', 'peace', 'and', 'good', 'neighbour', '##liness', '.']\n",
      "['russia', \"'\", 's', 'ambassador', 'to', 'mongolia', 'oleg', 'der', '##kov', '##ski', '##y', 'believes', 'that', 'there', 'are', 'no', 'problems', 'in', 'relations', 'between', 'the', 'two', 'states', 'and', 'the', 'common', 'border', 'stretching', 'for', '3', ',', '500', 'kilometers', 'is', 'a', 'border', 'of', 'peace', 'and', 'good', 'neighbor', '##liness', '.']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts not matching on line 243 in test.sent..\n",
      "The report also slammed US President George W. Bush 's administration for withdrawing from the Kyoto Protocol on cutting greenhouse gases .\n",
      "['the', 'report', 'also', 'slammed', 'us', 'president', 'george', 'w', '.', 'bush', \"'\", 's', 'administration', 'for', 'withdrawing', 'from', 'the', 'kyoto', 'protocol', 'on', 'cutting', 'greenhouse', 'gases', '.']\n",
      "['the', 'report', 'also', 'slammed', 'us', 'president', 'george', 'w', '.', 'bush', \"'\", 's', 'administration', 'for', 'withdrawing', 'from', 'the', 'kyoto', 'protocol', 'on', 'cutting', 'greenhouse', 'gas', '##ses', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 245 in test.sent..\n",
      "\" Once again the United States , assuming the role of ` world judge of human rights ' has distorted human rights conditions in many countries and regions in the world , including China , and accused them of human rights violations , all the while turning a blind eye to its own human rights - related problems , \" the Chinese report said .\n",
      "['\"', 'once', 'again', 'the', 'united', 'states', ',', 'assuming', 'the', 'role', 'of', '`', 'world', 'judge', 'of', 'human', 'rights', \"'\", 'has', 'distorted', 'human', 'rights', 'conditions', 'in', 'many', 'countries', 'and', 'regions', 'in', 'the', 'world', ',', 'including', 'china', ',', 'and', 'accused', 'them', 'of', 'human', 'rights', 'violations', ',', 'all', 'the', 'while', 'turning', 'a', 'blind', 'eye', 'to', 'its', 'own', 'human', 'rights', '-', 'related', 'problems', ',', '\"', 'the', 'chinese', 'report', 'said', '.']\n",
      "['\"', 'once', 'again', 'the', 'united', 'states', ',', 'assuming', 'the', 'role', 'of', \"'\", 'world', 'judge', 'of', 'human', 'rights', \"'\", 'has', 'distorted', 'human', 'rights', 'conditions', 'in', 'many', 'countries', 'and', 'regions', 'in', 'the', 'world', ',', 'including', 'china', ',', 'and', 'accused', 'them', 'of', 'human', 'rights', 'violations', ',', 'all', 'the', 'while', 'turning', 'a', 'blind', 'eye', 'to', 'its', 'own', 'human', 'rights', '-', 'related', 'problems', ',', '\"', 'the', 'chinese', 'report', 'said', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 255 in test.sent..\n",
      "- The commander of Venezuela 's paratrooper brigade - Chavez 's old unit - refuses to recognise orders of the interim government .\n",
      "['-', 'the', 'commander', 'of', 'venezuela', \"'\", 's', 'para', '##tro', '##oper', 'brigade', '-', 'chavez', \"'\", 's', 'old', 'unit', '-', 'refuses', 'to', 'recognise', 'orders', 'of', 'the', 'interim', 'government', '.']\n",
      "['-', 'the', 'commander', 'of', 'venezuela', \"'\", 's', 'para', '##tro', '##oper', 'brigade', '-', 'chavez', \"'\", 's', 'old', 'unit', '-', 'refuses', 'to', 'recognize', 'orders', 'of', 'the', 'interim', 'government', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 258 in test.sent..\n",
      "He then calls for peace , calm , and ` the unity of the country . '\n",
      "['he', 'then', 'calls', 'for', 'peace', ',', 'calm', ',', 'and', '`', 'the', 'unity', 'of', 'the', 'country', '.', \"'\"]\n",
      "['he', 'then', 'calls', 'for', 'peace', ',', 'calm', ',', 'and', \"'\", 'the', 'unity', 'of', 'the', 'country', '.', \"'\"]\n",
      "\n",
      "\n",
      "Counts not matching on line 267 in test.sent..\n",
      "San Salvador , 17 April ( ACAN - EFE ) -- Salvadorian President , Francisco Flores , today defended his declaration of support for the interim Venezuelan Government headed by industrialist Pedro Carmona , indicating that the information that he had at the time was that Hugo Chavez had resigned the Presidency .\n",
      "['san', 'salvador', ',', '17', 'april', '(', 'ac', '##an', '-', 'e', '##fe', ')', '-', '-', 'salvador', '##ian', 'president', ',', 'francisco', 'flores', ',', 'today', 'defended', 'his', 'declaration', 'of', 'support', 'for', 'the', 'interim', 'venezuelan', 'government', 'headed', 'by', 'industrialist', 'pedro', 'car', '##mona', ',', 'indicating', 'that', 'the', 'information', 'that', 'he', 'had', 'at', 'the', 'time', 'was', 'that', 'hugo', 'chavez', 'had', 'resigned', 'the', 'presidency', '.']\n",
      "['san', 'salvador', ',', '17', 'april', '(', 'ac', '##an', '-', 'e', '##fe', ')', '-', 'salvador', '##ian', 'president', ',', 'francisco', 'flores', ',', 'today', 'defended', 'his', 'declaration', 'of', 'support', 'for', 'the', 'interim', 'venezuelan', 'government', 'headed', 'by', 'industrialist', 'pedro', 'car', '##mona', ',', 'indicating', 'that', 'the', 'information', 'that', 'he', 'had', 'at', 'the', 'time', 'was', 'that', 'hugo', 'chavez', 'had', 'resigned', 'the', 'presidency', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 275 in test.sent..\n",
      "uh on the scale they gave one to ten i'd say i'm probably a four i'm not totally i'm not one of these people that believes that we should not be able to buy guns but i do n't think we should be carrying Uzis either you know what i mean yeah i know i mean i do n't think machine guns automatic weapons i do n't believe in things like that but i think\n",
      "['uh', 'on', 'the', 'scale', 'they', 'gave', 'one', 'to', 'ten', 'i', \"'\", 'd', 'say', 'i', \"'\", 'm', 'probably', 'a', 'four', 'i', \"'\", 'm', 'not', 'totally', 'i', \"'\", 'm', 'not', 'one', 'of', 'these', 'people', 'that', 'believes', 'that', 'we', 'should', 'not', 'be', 'able', 'to', 'buy', 'guns', 'but', 'i', 'do', 'n', \"'\", 't', 'think', 'we', 'should', 'be', 'carrying', 'u', '##zi', '##s', 'either', 'you', 'know', 'what', 'i', 'mean', 'yeah', 'i', 'know', 'i', 'mean', 'i', 'do', 'n', \"'\", 't', 'think', 'machine', 'guns', 'automatic', 'weapons', 'i', 'do', 'n', \"'\", 't', 'believe', 'in', 'things', 'like', 'that', 'but', 'i', 'think']\n",
      "['uh', 'on', 'the', 'scale', 'they', 'gave', 'one', 'to', 'ten', 'i', \"'\", 'd', 'say', 'i', 'am', 'probably', 'a', 'four', 'i', 'am', 'not', 'totally', 'i', 'am', 'not', 'one', 'of', 'these', 'people', 'that', 'believes', 'that', 'we', 'should', 'not', 'be', 'able', 'to', 'buy', 'guns', 'but', 'i', 'do', 'n', \"'\", 't', 'think', 'we', 'should', 'be', 'carrying', 'u', '##zi', '##s', 'either', 'you', 'know', 'what', 'i', 'mean', 'yeah', 'i', 'know', 'i', 'mean', 'i', 'do', 'n', \"'\", 't', 'think', 'machine', 'guns', 'automatic', 'weapons', 'i', 'do', 'n', \"'\", 't', 'believe', 'in', 'things', 'like', 'that', 'but', 'i', 'think']\n",
      "\n",
      "\n",
      "Counts not matching on line 276 in test.sent..\n",
      "i'm from California my mom the last time i was like purchased a gun my my mom was getting a rifle for my brother that he wanted like an antique one and\n",
      "['i', \"'\", 'm', 'from', 'california', 'my', 'mom', 'the', 'last', 'time', 'i', 'was', 'like', 'purchased', 'a', 'gun', 'my', 'my', 'mom', 'was', 'getting', 'a', 'rifle', 'for', 'my', 'brother', 'that', 'he', 'wanted', 'like', 'an', 'antique', 'one', 'and']\n",
      "['i', 'am', 'from', 'california', 'my', 'mom', 'the', 'last', 'time', 'i', 'was', 'like', 'purchased', 'a', 'gun', 'my', 'my', 'mom', 'was', 'getting', 'a', 'rifle', 'for', 'my', 'brother', 'that', 'he', 'wanted', 'like', 'an', 'antique', 'one', 'and']\n",
      "\n",
      "\n",
      "Counts not matching on line 278 in test.sent..\n",
      "yep oh yeah they do they get real emotional about it all the i've worked with a lot of people that hunt and they just they they do n't see any sense in it at all they think it 's ridiculous to have any kind of gun control but then of course they 're hunters they know what they 're doing they do n't realize there 're a bunch of crazy people out there that\n",
      "['yep', 'oh', 'yeah', 'they', 'do', 'they', 'get', 'real', 'emotional', 'about', 'it', 'all', 'the', 'i', \"'\", 've', 'worked', 'with', 'a', 'lot', 'of', 'people', 'that', 'hunt', 'and', 'they', 'just', 'they', 'they', 'do', 'n', \"'\", 't', 'see', 'any', 'sense', 'in', 'it', 'at', 'all', 'they', 'think', 'it', \"'\", 's', 'ridiculous', 'to', 'have', 'any', 'kind', 'of', 'gun', 'control', 'but', 'then', 'of', 'course', 'they', \"'\", 're', 'hunters', 'they', 'know', 'what', 'they', \"'\", 're', 'doing', 'they', 'do', 'n', \"'\", 't', 'realize', 'there', \"'\", 're', 'a', 'bunch', 'of', 'crazy', 'people', 'out', 'there', 'that']\n",
      "['yep', 'oh', 'yeah', 'they', 'do', 'they', 'get', 'real', 'emotional', 'about', 'it', 'all', 'the', 'i', 'have', 'worked', 'with', 'a', 'lot', 'of', 'people', 'that', 'hunt', 'and', 'they', 'just', 'they', 'they', 'do', 'n', \"'\", 't', 'see', 'any', 'sense', 'in', 'it', 'at', 'all', 'they', 'think', 'it', \"'\", 's', 'ridiculous', 'to', 'have', 'any', 'kind', 'of', 'gun', 'control', 'but', 'then', 'of', 'course', 'they', 'are', 'hunters', 'they', 'know', 'what', 'they', 'are', 'doing', 'they', 'do', 'n', \"'\", 't', 'realize', 'there', 'are', 'a', 'bunch', 'of', 'crazy', 'people', 'out', 'there', 'that']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts not matching on line 282 in test.sent..\n",
      "However , U.S. officials also note that some of the rebels do not have international ties , and they have criticized Russian military and police abuse of civilians -- although the criticism was toned down greatly after Russia became an enthusiastic member of the anti-terrorist coalition , sharing intelligence information , opening its airspace to humanitarian flights and giving a green light to U.S. military deployment in Central Asia .\n",
      "['however', ',', 'u', '.', 's', '.', 'officials', 'also', 'note', 'that', 'some', 'of', 'the', 'rebels', 'do', 'not', 'have', 'international', 'ties', ',', 'and', 'they', 'have', 'criticized', 'russian', 'military', 'and', 'police', 'abuse', 'of', 'civilians', '-', '-', 'although', 'the', 'criticism', 'was', 'toned', 'down', 'greatly', 'after', 'russia', 'became', 'an', 'enthusiastic', 'member', 'of', 'the', 'anti', '-', 'terrorist', 'coalition', ',', 'sharing', 'intelligence', 'information', ',', 'opening', 'its', 'airspace', 'to', 'humanitarian', 'flights', 'and', 'giving', 'a', 'green', 'light', 'to', 'u', '.', 's', '.', 'military', 'deployment', 'in', 'central', 'asia', '.']\n",
      "['however', ',', 'u', '.', 's', '.', 'officials', 'also', 'note', 'that', 'some', 'of', 'the', 'rebels', 'do', 'not', 'have', 'international', 'ties', ',', 'and', 'they', 'have', 'criticized', 'russian', 'military', 'and', 'police', 'abuse', 'of', 'civilians', '-', 'although', 'the', 'criticism', 'was', 'toned', 'down', 'greatly', 'after', 'russia', 'became', 'an', 'enthusiastic', 'member', 'of', 'the', 'anti', '-', 'terrorist', 'coalition', ',', 'sharing', 'intelligence', 'information', ',', 'opening', 'its', 'airspace', 'to', 'humanitarian', 'flights', 'and', 'giving', 'a', 'green', 'light', 'to', 'u', '.', 's', '.', 'military', 'deployment', 'in', 'central', 'asia', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 289 in test.sent..\n",
      "Three leading international organisations warned jointly Thursday [ 29 November ] that the international fight against terrorism should not be a pretext for the violation of human rights .\n",
      "['three', 'leading', 'international', 'organisations', 'warned', 'jointly', 'thursday', '[', '29', 'november', ']', 'that', 'the', 'international', 'fight', 'against', 'terrorism', 'should', 'not', 'be', 'a', 'pre', '##text', 'for', 'the', 'violation', 'of', 'human', 'rights', '.']\n",
      "['three', 'leading', 'international', 'organizations', 'warned', 'jointly', 'thursday', '[', '29', 'november', ']', 'that', 'the', 'international', 'fight', 'against', 'terrorism', 'should', 'not', 'be', 'a', 'pre', '##text', 'for', 'the', 'violation', 'of', 'human', 'rights', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 298 in test.sent..\n",
      "TOKYO , Feb 15 ( AFP ) - Japan Friday welcomed President George W. Bush 's alternative to the Kyoto Protocol on reducing greenhouse gases , but said it will press on with ratification of the pact the US rejected .\n",
      "['tokyo', ',', 'feb', '15', '(', 'af', '##p', ')', '-', 'japan', 'friday', 'welcomed', 'president', 'george', 'w', '.', 'bush', \"'\", 's', 'alternative', 'to', 'the', 'kyoto', 'protocol', 'on', 'reducing', 'greenhouse', 'gases', ',', 'but', 'said', 'it', 'will', 'press', 'on', 'with', 'ratification', 'of', 'the', 'pact', 'the', 'us', 'rejected', '.']\n",
      "['tokyo', ',', 'feb', '15', '(', 'af', '##p', ')', '-', 'japan', 'friday', 'welcomed', 'president', 'george', 'w', '.', 'bush', \"'\", 's', 'alternative', 'to', 'the', 'kyoto', 'protocol', 'on', 'reducing', 'greenhouse', 'gas', '##ses', ',', 'but', 'said', 'it', 'will', 'press', 'on', 'with', 'ratification', 'of', 'the', 'pact', 'the', 'us', 'rejected', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 302 in test.sent..\n",
      "We 're proud of our children and all that they overcome .\n",
      "['we', \"'\", 're', 'proud', 'of', 'our', 'children', 'and', 'all', 'that', 'they', 'overcome', '.']\n",
      "['we', 'are', 'proud', 'of', 'our', 'children', 'and', 'all', 'that', 'they', 'overcome', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 313 in test.sent..\n",
      "How odd -- and a good illustration of how trying to shoe-horn in a \" witty \" headline can drive you into an idea that does n't fit or is undeserved .\n",
      "['how', 'odd', '-', '-', 'and', 'a', 'good', 'illustration', 'of', 'how', 'trying', 'to', 'shoe', '-', 'horn', 'in', 'a', '\"', 'witty', '\"', 'headline', 'can', 'drive', 'you', 'into', 'an', 'idea', 'that', 'does', 'n', \"'\", 't', 'fit', 'or', 'is', 'und', '##ese', '##r', '##ved', '.']\n",
      "['how', 'odd', '-', 'and', 'a', 'good', 'illustration', 'of', 'how', 'trying', 'to', 'shoe', '-', 'horn', 'in', 'a', '\"', 'witty', '\"', 'headline', 'can', 'drive', 'you', 'into', 'an', 'idea', 'that', 'does', 'n', \"'\", 't', 'fit', 'or', 'is', 'und', '##ese', '##r', '##ved', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 326 in test.sent..\n",
      "With international consensus having been reached regarding a treaty to combat climate change , a ``red light '' has been issued to South Korea 's heavily carbon - dependent industries .\n",
      "['with', 'international', 'consensus', 'having', 'been', 'reached', 'regarding', 'a', 'treaty', 'to', 'combat', 'climate', 'change', ',', 'a', '`', '`', 'red', 'light', \"'\", \"'\", 'has', 'been', 'issued', 'to', 'south', 'korea', \"'\", 's', 'heavily', 'carbon', '-', 'dependent', 'industries', '.']\n",
      "['with', 'international', 'consensus', 'having', 'been', 'reached', 'regarding', 'a', 'treaty', 'to', 'combat', 'climate', 'change', ',', 'a', \"'\", \"'\", 'red', 'light', '\"', 'has', 'been', 'issued', 'to', 'south', 'korea', \"'\", 's', 'heavily', 'carbon', '-', 'dependent', 'industries', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 327 in test.sent..\n",
      "But considering that South Korea has the highest growth rate of carbon dioxide emissions in the world , it will not be able to fend off international pressure to join in the global campaign to reduce greenhouse gases much longer , experts note .\n",
      "['but', 'considering', 'that', 'south', 'korea', 'has', 'the', 'highest', 'growth', 'rate', 'of', 'carbon', 'dioxide', 'emissions', 'in', 'the', 'world', ',', 'it', 'will', 'not', 'be', 'able', 'to', 'fen', '##d', 'off', 'international', 'pressure', 'to', 'join', 'in', 'the', 'global', 'campaign', 'to', 'reduce', 'greenhouse', 'gases', 'much', 'longer', ',', 'experts', 'note', '.']\n",
      "['but', 'considering', 'that', 'south', 'korea', 'has', 'the', 'highest', 'growth', 'rate', 'of', 'carbon', 'dioxide', 'emissions', 'in', 'the', 'world', ',', 'it', 'will', 'not', 'be', 'able', 'to', 'fen', '##d', 'off', 'international', 'pressure', 'to', 'join', 'in', 'the', 'global', 'campaign', 'to', 'reduce', 'greenhouse', 'gas', '##ses', 'much', 'longer', ',', 'experts', 'note', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 330 in test.sent..\n",
      "I think that is why I welcomed doing a book -- it gives one the ability to use so much of what is left on the cutting room floor of daily journalism .\n",
      "['i', 'think', 'that', 'is', 'why', 'i', 'welcomed', 'doing', 'a', 'book', '-', '-', 'it', 'gives', 'one', 'the', 'ability', 'to', 'use', 'so', 'much', 'of', 'what', 'is', 'left', 'on', 'the', 'cutting', 'room', 'floor', 'of', 'daily', 'journalism', '.']\n",
      "['i', 'think', 'that', 'is', 'why', 'i', 'welcomed', 'doing', 'a', 'book', '-', 'it', 'gives', 'one', 'the', 'ability', 'to', 'use', 'so', 'much', 'of', 'what', 'is', 'left', 'on', 'the', 'cutting', 'room', 'floor', 'of', 'daily', 'journalism', '.']\n",
      "\n",
      "\n",
      "Counts not matching on line 346 in test.sent..\n",
      "Argentina was expecting to receive 1.3 billion USD to help the state meet its immediate expenses but after an unfavourable report submitted by Thomas Reichmann , it was decided that now is not \" the right moment \" to lend any more money .\n",
      "['argentina', 'was', 'expecting', 'to', 'receive', '1', '.', '3', 'billion', 'usd', 'to', 'help', 'the', 'state', 'meet', 'its', 'immediate', 'expenses', 'but', 'after', 'an', 'un', '##fa', '##vo', '##urable', 'report', 'submitted', 'by', 'thomas', 'reich', '##mann', ',', 'it', 'was', 'decided', 'that', 'now', 'is', 'not', '\"', 'the', 'right', 'moment', '\"', 'to', 'lend', 'any', 'more', 'money', '.']\n",
      "['argentina', 'was', 'expecting', 'to', 'receive', '1', '.', '3', 'billion', 'usd', 'to', 'help', 'the', 'state', 'meet', 'its', 'immediate', 'expenses', 'but', 'after', 'an', 'un', '##fa', '##vor', '##able', 'report', 'submitted', 'by', 'thomas', 'reich', '##mann', ',', 'it', 'was', 'decided', 'that', 'now', 'is', 'not', '\"', 'the', 'right', 'moment', '\"', 'to', 'lend', 'any', 'more', 'money', '.']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 21, 28, 34, 35, 39, 41, 119, 128, 133, 142, 174, 196, 208, 243, 245, 255, 258, 267, 275, 276, 278, 282, 289, 298, 302, 313, 326, 327, 330, 346]\r\n",
      "Deleted\r\n",
      "322\r\n",
      "\r\n",
      "\r\n",
      "Deleted\r\n",
      "322\r\n",
      "\r\n",
      "\r\n",
      "Deleted\r\n",
      "322\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python prep_POS_DEP_forBERT.py gen mpqa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39b9a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python prep_BERTData.py gen mpqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6524102d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'Aligner'.\n",
      "[]\n",
      "Deleted\n",
      "996\n",
      "\n",
      "\n",
      "Deleted\n",
      "996\n",
      "\n",
      "\n",
      "Deleted\n",
      "996\n",
      "\n",
      "\n",
      "[]\n",
      "Deleted\n",
      "323\n",
      "\n",
      "\n",
      "Deleted\n",
      "323\n",
      "\n",
      "\n",
      "Deleted\n",
      "323\n",
      "\n",
      "\n",
      "[]\n",
      "Deleted\n",
      "322\n",
      "\n",
      "\n",
      "Deleted\n",
      "322\n",
      "\n",
      "\n",
      "Deleted\n",
      "322\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python prep_POS_DEP_forBERT.py gen mpqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "252b6f35",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/shivam/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/shivam/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/shivam/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "enc_hidden_size: 768\n",
      "dec_inp_size: 768\n",
      "dec_hidden_size: 768\n",
      "pointer_net_hidden_size: 300\n",
      "['PASTE_BERT.py', '--gpu_id', '0', '--src_folder', 'mpqa/', '--trg_folder', 'mpqa/PASTE_BERT', '--bert_mode', 'gen', '--gen_direct', 'af', '--l2', 'y']\n",
      "100  10  0.5\n",
      "BERT\n",
      "loading data......\n",
      "No. of sentences:  996\n",
      "No. of lines in Target file:  996\n",
      "No. of lines in POS file:  996\n",
      "No. of lines in DEP file:  996\n",
      "No. of sentences:  323\n",
      "No. of lines in Target file:  323\n",
      "No. of lines in POS file:  323\n",
      "No. of lines in DEP file:  323\n",
      "No. of sentences:  322\n",
      "No. of lines in Target file:  322\n",
      "No. of lines in POS file:  322\n",
      "No. of lines in DEP file:  322\n",
      "Training data size:  994\n",
      "Development data size:  323\n",
      "Test data size:  322\n",
      "Building POS TAG Vocab..\n",
      "Building DEP TAG Vocab..\n",
      "Training started......\n",
      "Batch Count:   63\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_attentions\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/shivam/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Parameters size:  127959659\n",
      "weight factor:  1\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "Epoch:  1\n",
      "  0%|                                                    | 0/63 [00:00<?, ?it/s]/home/shivam/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2251: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 35%|                            | 22/63 [00:10<00:21,  1.89it/s]^C\n",
      " 35%|                            | 22/63 [00:10<00:20,  2.01it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"PASTE_BERT.py\", line 1578, in <module>\n",
      "    train_model(model_name, train_data, dev_data, test_data, test_gt_lines, model_file_name)\n",
      "  File \"PASTE_BERT.py\", line 1265, in train_model\n",
      "    outputs = model(src_words_seq, src_words_mask, src_pos_seq, src_dep_seq, trg_words_seq, \n",
      "  File \"/home/shivam/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"PASTE_BERT.py\", line 1034, in forward\n",
      "    dec_outs = self.decoder(prev_tuples, dec_hid, enc_hs, src_mask,\n",
      "  File \"/home/shivam/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"PASTE_BERT.py\", line 950, in forward\n",
      "    op_start_weights = F.softmax(op_start, dim=-1)\n",
      "  File \"/home/shivam/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\", line 1680, in softmax\n",
      "    ret = input.softmax(dim)\n",
      "  File \"/home/shivam/anaconda3/lib/python3.8/traceback.py\", line 197, in format_stack\n",
      "    return format_list(extract_stack(f, limit=limit))\n",
      "  File \"/home/shivam/anaconda3/lib/python3.8/traceback.py\", line 211, in extract_stack\n",
      "    stack = StackSummary.extract(walk_stack(f), limit=limit)\n",
      "  File \"/home/shivam/anaconda3/lib/python3.8/traceback.py\", line 362, in extract\n",
      "    linecache.checkcache(filename)\n",
      "  File \"/home/shivam/anaconda3/lib/python3.8/linecache.py\", line 74, in checkcache\n",
      "    stat = os.stat(fullname)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python3 PASTE_BERT.py --gpu_id 0 --src_folder mpqa/ --trg_folder mpqa/PASTE_BERT --bert_mode gen --gen_direct af --l2 y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7076029b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7cf585",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7971c9e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee43ece8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/shivam/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/shivam/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/shivam/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "enc_hidden_size: 768\n",
      "dec_inp_size: 768\n",
      "dec_hidden_size: 768\n",
      "pointer_net_hidden_size: 300\n",
      "['PASTE_BERT.py', '--gpu_id', '0', '--src_folder', 'mpqa/', '--trg_folder', 'mpqa/PASTE_BERT', '--bert_mode', 'gen', '--gen_direct', 'af', '--l2', 'y']\n",
      "100  10  0.5\n",
      "BERT\n",
      "loading data......\n",
      "No. of sentences:  996\n",
      "No. of lines in Target file:  996\n",
      "No. of lines in POS file:  996\n",
      "No. of lines in DEP file:  996\n",
      "No. of sentences:  323\n",
      "No. of lines in Target file:  323\n",
      "No. of lines in POS file:  323\n",
      "No. of lines in DEP file:  323\n",
      "No. of sentences:  322\n",
      "No. of lines in Target file:  322\n",
      "No. of lines in POS file:  322\n",
      "No. of lines in DEP file:  322\n",
      "Training data size:  994\n",
      "Development data size:  323\n",
      "Test data size:  322\n",
      "Building POS TAG Vocab..\n",
      "Building DEP TAG Vocab..\n",
      "Training started......\n",
      "Batch Count:   63\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_attentions\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/shivam/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Parameters size:  127959659\n",
      "weight factor:  1\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "Epoch:  1\n",
      "  0%|                                                    | 0/63 [00:00<?, ?it/s]/home/shivam/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2251: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|| 63/63 [00:24<00:00,  2.54it/s]\n",
      "Training loss:  9.872241973876953\n",
      "Training time:  0:00:24.764964\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.49it/s]\n",
      "Prediction time:  0:00:06.019953\n",
      "333  \t  426  \t  45\n",
      "Dev P:  0.135\n",
      "Dev R:  0.106\n",
      "Dev F1:  0.119\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.71it/s]\n",
      "Prediction time:  0:00:05.665681\n",
      "327  \t  421  \t  39\n",
      "Test P:  0.119\n",
      "Test R:  0.093\n",
      "Test F1:  0.104\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  2\n",
      "100%|| 63/63 [00:22<00:00,  2.82it/s]\n",
      "Training loss:  7.098644120352609\n",
      "Training time:  0:00:22.343792\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.45it/s]\n",
      "Prediction time:  0:00:06.084399\n",
      "322  \t  426  \t  64\n",
      "Dev P:  0.199\n",
      "Dev R:  0.15\n",
      "Dev F1:  0.171\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.69it/s]\n",
      "Prediction time:  0:00:05.698732\n",
      "322  \t  421  \t  46\n",
      "Test P:  0.143\n",
      "Test R:  0.109\n",
      "Test F1:  0.124\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  3\n",
      "100%|| 63/63 [00:22<00:00,  2.86it/s]\n",
      "Training loss:  6.244579095689077\n",
      "Training time:  0:00:22.027489\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.124218\n",
      "324  \t  426  \t  60\n",
      "Dev P:  0.185\n",
      "Dev R:  0.141\n",
      "Dev F1:  0.16\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.723119\n",
      "323  \t  421  \t  50\n",
      "Test P:  0.155\n",
      "Test R:  0.119\n",
      "Test F1:  0.134\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  4\n",
      "100%|| 63/63 [00:21<00:00,  2.89it/s]\n",
      "Training loss:  5.60404284038241\n",
      "Training time:  0:00:21.779332\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.46it/s]\n",
      "Prediction time:  0:00:06.063182\n",
      "324  \t  426  \t  65\n",
      "Dev P:  0.201\n",
      "Dev R:  0.153\n",
      "Dev F1:  0.173\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.70it/s]\n",
      "Prediction time:  0:00:05.679934\n",
      "324  \t  421  \t  52\n",
      "Test P:  0.16\n",
      "Test R:  0.124\n",
      "Test F1:  0.14\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  5\n",
      "100%|| 63/63 [00:21<00:00,  2.87it/s]\n",
      "Training loss:  5.023590962092082\n",
      "Training time:  0:00:21.960808\n",
      "\n",
      "Dev Results\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:06<00:00,  3.48it/s]\n",
      "Prediction time:  0:00:06.028367\n",
      "382  \t  426  \t  74\n",
      "Dev P:  0.194\n",
      "Dev R:  0.174\n",
      "Dev F1:  0.183\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.71it/s]\n",
      "Prediction time:  0:00:05.667262\n",
      "371  \t  421  \t  59\n",
      "Test P:  0.159\n",
      "Test R:  0.14\n",
      "Test F1:  0.149\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  6\n",
      "100%|| 63/63 [00:22<00:00,  2.84it/s]\n",
      "Training loss:  4.4488204547337125\n",
      "Training time:  0:00:22.147212\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.46it/s]\n",
      "Prediction time:  0:00:06.076936\n",
      "388  \t  426  \t  69\n",
      "Dev P:  0.178\n",
      "Dev R:  0.162\n",
      "Dev F1:  0.17\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.69it/s]\n",
      "Prediction time:  0:00:05.689340\n",
      "377  \t  421  \t  59\n",
      "Test P:  0.156\n",
      "Test R:  0.14\n",
      "Test F1:  0.148\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  7\n",
      "100%|| 63/63 [00:22<00:00,  2.82it/s]\n",
      "Training loss:  4.070652734665644\n",
      "Training time:  0:00:22.310544\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.46it/s]\n",
      "Prediction time:  0:00:06.066524\n",
      "345  \t  426  \t  79\n",
      "Dev P:  0.229\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.205\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.70it/s]\n",
      "Prediction time:  0:00:05.683519\n",
      "351  \t  421  \t  60\n",
      "Test P:  0.171\n",
      "Test R:  0.143\n",
      "Test F1:  0.155\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  8\n",
      "100%|| 63/63 [00:22<00:00,  2.85it/s]\n",
      "Training loss:  3.4237165753803556\n",
      "Training time:  0:00:22.120383\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.45it/s]\n",
      "Prediction time:  0:00:06.091363\n",
      "352  \t  426  \t  68\n",
      "Dev P:  0.193\n",
      "Dev R:  0.16\n",
      "Dev F1:  0.175\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.68it/s]\n",
      "Prediction time:  0:00:05.703016\n",
      "362  \t  421  \t  58\n",
      "Test P:  0.16\n",
      "Test R:  0.138\n",
      "Test F1:  0.148\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  9\n",
      "100%|| 63/63 [00:21<00:00,  2.87it/s]\n",
      "Training loss:  3.0895401788136314\n",
      "Training time:  0:00:21.930772\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.45it/s]\n",
      "Prediction time:  0:00:06.086728\n",
      "334  \t  426  \t  66\n",
      "Dev P:  0.198\n",
      "Dev R:  0.155\n",
      "Dev F1:  0.174\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.68it/s]\n",
      "Prediction time:  0:00:05.707997\n",
      "337  \t  421  \t  61\n",
      "Test P:  0.181\n",
      "Test R:  0.145\n",
      "Test F1:  0.161\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  10\n",
      "100%|| 63/63 [00:22<00:00,  2.84it/s]\n",
      "Training loss:  2.7605379025141397\n",
      "Training time:  0:00:22.205123\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.46it/s]\n",
      "Prediction time:  0:00:06.067544\n",
      "365  \t  426  \t  73\n",
      "Dev P:  0.2\n",
      "Dev R:  0.171\n",
      "Dev F1:  0.185\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.69it/s]\n",
      "Prediction time:  0:00:05.696308\n",
      "370  \t  421  \t  65\n",
      "Test P:  0.176\n",
      "Test R:  0.154\n",
      "Test F1:  0.164\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  11\n",
      "100%|| 63/63 [00:22<00:00,  2.86it/s]\n",
      "Training loss:  2.415963529594361\n",
      "Training time:  0:00:22.009247\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.44it/s]\n",
      "Prediction time:  0:00:06.097528\n",
      "353  \t  426  \t  69\n",
      "Dev P:  0.195\n",
      "Dev R:  0.162\n",
      "Dev F1:  0.177\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.715564\n",
      "372  \t  421  \t  61\n",
      "Test P:  0.164\n",
      "Test R:  0.145\n",
      "Test F1:  0.154\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  12\n",
      "100%|| 63/63 [00:22<00:00,  2.85it/s]\n",
      "Training loss:  2.2044750773717485\n",
      "Training time:  0:00:22.099304\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.45it/s]\n",
      "Prediction time:  0:00:06.090422\n",
      "344  \t  426  \t  68\n",
      "Dev P:  0.198\n",
      "Dev R:  0.16\n",
      "Dev F1:  0.177\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.68it/s]\n",
      "Prediction time:  0:00:05.712043\n",
      "360  \t  421  \t  62\n",
      "Test P:  0.172\n",
      "Test R:  0.147\n",
      "Test F1:  0.159\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  13\n",
      "100%|| 63/63 [00:22<00:00,  2.81it/s]\n",
      "Training loss:  2.1458281070467025\n",
      "Training time:  0:00:22.453064\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.46it/s]\n",
      "Prediction time:  0:00:06.074820\n",
      "328  \t  426  \t  70\n",
      "Dev P:  0.213\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.186\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.68it/s]\n",
      "Prediction time:  0:00:05.699800\n",
      "325  \t  421  \t  61\n",
      "Test P:  0.188\n",
      "Test R:  0.145\n",
      "Test F1:  0.164\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  14\n",
      "100%|| 63/63 [00:22<00:00,  2.85it/s]\n",
      "Training loss:  1.955715883345831\n",
      "Training time:  0:00:22.070188\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.45it/s]\n",
      "Prediction time:  0:00:06.085602\n",
      "347  \t  426  \t  71\n",
      "Dev P:  0.205\n",
      "Dev R:  0.167\n",
      "Dev F1:  0.184\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.68it/s]\n",
      "Prediction time:  0:00:05.709659\n",
      "357  \t  421  \t  65\n",
      "Test P:  0.182\n",
      "Test R:  0.154\n",
      "Test F1:  0.167\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  15\n",
      "100%|| 63/63 [00:22<00:00,  2.82it/s]\n",
      "Training loss:  1.6725155086744399\n",
      "Training time:  0:00:22.319893\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.116133\n",
      "381  \t  426  \t  75\n",
      "Dev P:  0.197\n",
      "Dev R:  0.176\n",
      "Dev F1:  0.186\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.720375\n",
      "392  \t  421  \t  65\n",
      "Test P:  0.166\n",
      "Test R:  0.154\n",
      "Test F1:  0.16\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  16\n",
      "100%|| 63/63 [00:22<00:00,  2.81it/s]\n",
      "Training loss:  1.5270735441692291\n",
      "Training time:  0:00:22.426889\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.44it/s]\n",
      "Prediction time:  0:00:06.111646\n",
      "380  \t  426  \t  78\n",
      "Dev P:  0.205\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.194\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.66it/s]\n",
      "Prediction time:  0:00:05.738986\n",
      "393  \t  421  \t  67\n",
      "Test P:  0.17\n",
      "Test R:  0.159\n",
      "Test F1:  0.165\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  17\n",
      "100%|| 63/63 [00:22<00:00,  2.86it/s]\n",
      "Training loss:  1.4864899270118228\n",
      "Training time:  0:00:22.021501\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.45it/s]\n",
      "Prediction time:  0:00:06.089184\n",
      "332  \t  426  \t  71\n",
      "Dev P:  0.214\n",
      "Dev R:  0.167\n",
      "Dev F1:  0.187\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.68it/s]\n",
      "Prediction time:  0:00:05.704166\n",
      "332  \t  421  \t  64\n",
      "Test P:  0.193\n",
      "Test R:  0.152\n",
      "Test F1:  0.17\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  18\n",
      "100%|| 63/63 [00:22<00:00,  2.83it/s]\n",
      "Training loss:  1.3293826494898116\n",
      "Training time:  0:00:22.239226\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.42it/s]\n",
      "Prediction time:  0:00:06.141688\n",
      "361  \t  426  \t  68\n",
      "Dev P:  0.188\n",
      "Dev R:  0.16\n",
      "Dev F1:  0.173\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.66it/s]\n",
      "Prediction time:  0:00:05.739329\n",
      "375  \t  421  \t  68\n",
      "Test P:  0.181\n",
      "Test R:  0.162\n",
      "Test F1:  0.171\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  19\n",
      "100%|| 63/63 [00:22<00:00,  2.82it/s]\n",
      "Training loss:  1.3113106697324723\n",
      "Training time:  0:00:22.327974\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.44it/s]\n",
      "Prediction time:  0:00:06.109114\n",
      "343  \t  426  \t  73\n",
      "Dev P:  0.213\n",
      "Dev R:  0.171\n",
      "Dev F1:  0.19\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.716646\n",
      "353  \t  421  \t  65\n",
      "Test P:  0.184\n",
      "Test R:  0.154\n",
      "Test F1:  0.168\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  20\n",
      "100%|| 63/63 [00:21<00:00,  2.87it/s]\n",
      "Training loss:  1.256508652653013\n",
      "Training time:  0:00:21.956711\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.46it/s]\n",
      "Prediction time:  0:00:06.072516\n",
      "382  \t  426  \t  79\n",
      "Dev P:  0.207\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.196\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.68it/s]\n",
      "Prediction time:  0:00:05.700570\n",
      "404  \t  421  \t  67\n",
      "Test P:  0.166\n",
      "Test R:  0.159\n",
      "Test F1:  0.162\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  21\n",
      "100%|| 63/63 [00:21<00:00,  2.89it/s]\n",
      "Training loss:  1.200836834453401\n",
      "Training time:  0:00:21.816216\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.124474\n",
      "338  \t  426  \t  70\n",
      "Dev P:  0.207\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.183\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.66it/s]\n",
      "Prediction time:  0:00:05.737912\n",
      "353  \t  421  \t  70\n",
      "Test P:  0.198\n",
      "Test R:  0.166\n",
      "Test F1:  0.181\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  22\n",
      "100%|| 63/63 [00:22<00:00,  2.86it/s]\n",
      "Training loss:  1.0911783192838942\n",
      "Training time:  0:00:22.052588\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.44it/s]\n",
      "Prediction time:  0:00:06.112190\n",
      "359  \t  426  \t  76\n",
      "Dev P:  0.212\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.194\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.724458\n",
      "359  \t  421  \t  58\n",
      "Test P:  0.162\n",
      "Test R:  0.138\n",
      "Test F1:  0.149\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  23\n",
      "100%|| 63/63 [00:22<00:00,  2.85it/s]\n",
      "Training loss:  0.9938702815108829\n",
      "Training time:  0:00:22.079297\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.123760\n",
      "366  \t  426  \t  73\n",
      "Dev P:  0.199\n",
      "Dev R:  0.171\n",
      "Dev F1:  0.184\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.66it/s]\n",
      "Prediction time:  0:00:05.739999\n",
      "396  \t  421  \t  61\n",
      "Test P:  0.154\n",
      "Test R:  0.145\n",
      "Test F1:  0.149\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  24\n",
      "100%|| 63/63 [00:22<00:00,  2.84it/s]\n",
      "Training loss:  0.9103284615372854\n",
      "Training time:  0:00:22.188562\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.44it/s]\n",
      "Prediction time:  0:00:06.105889\n",
      "337  \t  426  \t  65\n",
      "Dev P:  0.193\n",
      "Dev R:  0.153\n",
      "Dev F1:  0.17\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.724187\n",
      "348  \t  421  \t  61\n",
      "Test P:  0.175\n",
      "Test R:  0.145\n",
      "Test F1:  0.159\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  25\n",
      "100%|| 63/63 [00:22<00:00,  2.83it/s]\n",
      "Training loss:  0.9257684988634927\n",
      "Training time:  0:00:22.227797\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.42it/s]\n",
      "Prediction time:  0:00:06.139360\n",
      "358  \t  426  \t  76\n",
      "Dev P:  0.212\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.194\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.66it/s]\n",
      "Prediction time:  0:00:05.745793\n",
      "375  \t  421  \t  65\n",
      "Test P:  0.173\n",
      "Test R:  0.154\n",
      "Test F1:  0.163\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  26\n",
      "100%|| 63/63 [00:22<00:00,  2.81it/s]\n",
      "Training loss:  0.9503270870163327\n",
      "Training time:  0:00:22.402803\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.44it/s]\n",
      "Prediction time:  0:00:06.111113\n",
      "337  \t  426  \t  71\n",
      "Dev P:  0.211\n",
      "Dev R:  0.167\n",
      "Dev F1:  0.186\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.728206\n",
      "339  \t  421  \t  58\n",
      "Test P:  0.171\n",
      "Test R:  0.138\n",
      "Test F1:  0.153\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  27\n",
      "100%|| 63/63 [00:22<00:00,  2.81it/s]\n",
      "Training loss:  0.9452324779260726\n",
      "Training time:  0:00:22.431321\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.129462\n",
      "358  \t  426  \t  70\n",
      "Dev P:  0.196\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.179\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.728562\n",
      "361  \t  421  \t  66\n",
      "Test P:  0.183\n",
      "Test R:  0.157\n",
      "Test F1:  0.169\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  28\n",
      "100%|| 63/63 [00:22<00:00,  2.83it/s]\n",
      "Training loss:  0.8555081694845169\n",
      "Training time:  0:00:22.256208\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.44it/s]\n",
      "Prediction time:  0:00:06.102659\n",
      "342  \t  426  \t  72\n",
      "Dev P:  0.211\n",
      "Dev R:  0.169\n",
      "Dev F1:  0.187\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.723894\n",
      "353  \t  421  \t  56\n",
      "Test P:  0.159\n",
      "Test R:  0.133\n",
      "Test F1:  0.145\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  29\n",
      "100%|| 63/63 [00:22<00:00,  2.86it/s]\n",
      "Training loss:  0.8482051264672053\n",
      "Training time:  0:00:22.013043\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.42it/s]\n",
      "Prediction time:  0:00:06.134934\n",
      "346  \t  426  \t  70\n",
      "Dev P:  0.202\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.181\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.65it/s]\n",
      "Prediction time:  0:00:05.752132\n",
      "354  \t  421  \t  56\n",
      "Test P:  0.158\n",
      "Test R:  0.133\n",
      "Test F1:  0.145\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  30\n",
      "100%|| 63/63 [00:22<00:00,  2.84it/s]\n",
      "Training loss:  0.8343737508569445\n",
      "Training time:  0:00:22.198684\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.120255\n",
      "369  \t  426  \t  74\n",
      "Dev P:  0.201\n",
      "Dev R:  0.174\n",
      "Dev F1:  0.186\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.66it/s]\n",
      "Prediction time:  0:00:05.735301\n",
      "392  \t  421  \t  59\n",
      "Test P:  0.151\n",
      "Test R:  0.14\n",
      "Test F1:  0.145\n",
      "\n",
      "\n",
      "\n",
      "*******\n",
      "Best Epoch:  7\n",
      "Best Epoch Seed:  49\n",
      "Corresponding P:  0.171\n",
      "Corresponding R:  0.143\n",
      "Corresponding F1:  0.155\n",
      "\n",
      "\n",
      "\n",
      "Best Test Epoch:  21\n",
      "Corresponding P:  0.198\n",
      "Corresponding R:  0.166\n",
      "Corresponding F1:  0.181\n",
      "\n",
      "\n",
      "\n",
      "Test size: 322\n",
      "Re-checking the scores of entire Test data with the best saved model:\n",
      "Total sentences in the test set:  322\n",
      "GT Triple Count:  421  \tPRED Triple Count:  351  \tCORRECT Triple Count:  60\n",
      "Test P:  0.171\n",
      "Test R:  0.143\n",
      "Test F1:  0.155\n",
      "Now printing the scores for various subsets of Test Data with the best saved model:\n",
      "Total sentences with single triples:  243\n",
      "GT Triple Count:  243  \tPRED Triple Count:  256  \tCORRECT Triple Count:  44\n",
      "Test P:  0.172\n",
      "Test R:  0.181\n",
      "Test F1:  0.176\n",
      "Total sentences with multiple triples:  79\n",
      "GT Triple Count:  178  \tPRED Triple Count:  95  \tCORRECT Triple Count:  16\n",
      "Test P:  0.168\n",
      "Test R:  0.09\n",
      "Test F1:  0.117\n",
      "Total sentences triples with varying sentiments:  31\n",
      "GT Triple Count:  79  \tPRED Triple Count:  35  \tCORRECT Triple Count:  4\n",
      "Test P:  0.114\n",
      "Test R:  0.051\n",
      "Test F1:  0.07\n",
      "Total sentences with overlapping triples:  42\n",
      "GT Triple Count:  95  \tPRED Triple Count:  48  \tCORRECT Triple Count:  7\n",
      "Test P:  0.146\n",
      "Test R:  0.074\n",
      "Test F1:  0.098\n"
     ]
    }
   ],
   "source": [
    "!python3 PASTE_BERT.py --gpu_id 0 --src_folder mpqa/ --trg_folder mpqa/PASTE_BERT --bert_mode gen --gen_direct af --l2 y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42950e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/shivam/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/shivam/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/shivam/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "enc_hidden_size: 818\n",
      "dec_inp_size: 818\n",
      "dec_hidden_size: 818\n",
      "pointer_net_hidden_size: 300\n",
      "['PASTE_BERT.py', '--gpu_id', '0', '--src_folder', 'mpqa/', '--trg_folder', 'mpqa/PASTE_BERT', '--bert_mode', 'gen', '--gen_direct', 'af', '--l2', 'y', '--use_pos_tags', 'y']\n",
      "100  10  0.5\n",
      "BERT\n",
      "loading data......\n",
      "No. of sentences:  996\n",
      "No. of lines in Target file:  996\n",
      "No. of lines in POS file:  996\n",
      "No. of lines in DEP file:  996\n",
      "No. of sentences:  323\n",
      "No. of lines in Target file:  323\n",
      "No. of lines in POS file:  323\n",
      "No. of lines in DEP file:  323\n",
      "No. of sentences:  322\n",
      "No. of lines in Target file:  322\n",
      "No. of lines in POS file:  322\n",
      "No. of lines in DEP file:  322\n",
      "Training data size:  994\n",
      "Development data size:  323\n",
      "Test data size:  322\n",
      "Building POS TAG Vocab..\n",
      "Building DEP TAG Vocab..\n",
      "Training started......\n",
      "Batch Count:   63\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_attentions\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/shivam/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Parameters size:  129772009\n",
      "weight factor:  1\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "Epoch:  1\n",
      "  0%|                                                    | 0/63 [00:00<?, ?it/s]/home/shivam/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2251: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  9.857314011407277\n",
      "Training time:  0:00:23.492599\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.250080\n",
      "323  \t  426  \t  45\n",
      "Dev P:  0.139\n",
      "Dev R:  0.106\n",
      "Dev F1:  0.12\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.61it/s]\n",
      "Prediction time:  0:00:05.810301\n",
      "323  \t  421  \t  35\n",
      "Test P:  0.108\n",
      "Test R:  0.083\n",
      "Test F1:  0.094\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  2\n",
      "100%|| 63/63 [00:23<00:00,  2.66it/s]\n",
      "Training loss:  7.059018785991366\n",
      "Training time:  0:00:23.640670\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.37it/s]\n",
      "Prediction time:  0:00:06.233625\n",
      "323  \t  426  \t  51\n",
      "Dev P:  0.158\n",
      "Dev R:  0.12\n",
      "Dev F1:  0.136\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.62it/s]\n",
      "Prediction time:  0:00:05.807512\n",
      "322  \t  421  \t  50\n",
      "Test P:  0.155\n",
      "Test R:  0.119\n",
      "Test F1:  0.135\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  3\n",
      "100%|| 63/63 [00:23<00:00,  2.70it/s]\n",
      "Training loss:  6.341446119641501\n",
      "Training time:  0:00:23.320566\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.272394\n",
      "323  \t  426  \t  64\n",
      "Dev P:  0.198\n",
      "Dev R:  0.15\n",
      "Dev F1:  0.171\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.851869\n",
      "322  \t  421  \t  45\n",
      "Test P:  0.14\n",
      "Test R:  0.107\n",
      "Test F1:  0.121\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  4\n",
      "100%|| 63/63 [00:23<00:00,  2.72it/s]\n",
      "Training loss:  5.741263276054745\n",
      "Training time:  0:00:23.185466\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.37it/s]\n",
      "Prediction time:  0:00:06.234351\n",
      "324  \t  426  \t  66\n",
      "Dev P:  0.204\n",
      "Dev R:  0.155\n",
      "Dev F1:  0.176\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.62it/s]\n",
      "Prediction time:  0:00:05.809458\n",
      "322  \t  421  \t  53\n",
      "Test P:  0.165\n",
      "Test R:  0.126\n",
      "Test F1:  0.143\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  5\n",
      "100%|| 63/63 [00:23<00:00,  2.70it/s]\n",
      "Training loss:  5.1350722615681\n",
      "Training time:  0:00:23.317968\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.38it/s]\n",
      "Prediction time:  0:00:06.216817\n",
      "393  \t  426  \t  78\n",
      "Dev P:  0.198\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.19\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.62it/s]\n",
      "Prediction time:  0:00:05.801055\n",
      "386  \t  421  \t  68\n",
      "Test P:  0.176\n",
      "Test R:  0.162\n",
      "Test F1:  0.169\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  6\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  4.512058083973233\n",
      "Training time:  0:00:23.476355\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.257568\n",
      "377  \t  426  \t  81\n",
      "Dev P:  0.215\n",
      "Dev R:  0.19\n",
      "Dev F1:  0.202\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.61it/s]\n",
      "Prediction time:  0:00:05.823897\n",
      "362  \t  421  \t  61\n",
      "Test P:  0.169\n",
      "Test R:  0.145\n",
      "Test F1:  0.156\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  7\n",
      "100%|| 63/63 [00:23<00:00,  2.65it/s]\n",
      "Training loss:  4.1837721022348555\n",
      "Training time:  0:00:23.740019\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.37it/s]\n",
      "Prediction time:  0:00:06.228103\n",
      "349  \t  426  \t  73\n",
      "Dev P:  0.209\n",
      "Dev R:  0.171\n",
      "Dev F1:  0.188\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.839678\n",
      "348  \t  421  \t  59\n",
      "Test P:  0.17\n",
      "Test R:  0.14\n",
      "Test F1:  0.153\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  8\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  3.692970281555539\n",
      "Training time:  0:00:23.497183\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.37it/s]\n",
      "Prediction time:  0:00:06.233136\n",
      "344  \t  426  \t  81\n",
      "Dev P:  0.235\n",
      "Dev R:  0.19\n",
      "Dev F1:  0.21\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.61it/s]\n",
      "Prediction time:  0:00:05.816847\n",
      "347  \t  421  \t  59\n",
      "Test P:  0.17\n",
      "Test R:  0.14\n",
      "Test F1:  0.154\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  9\n",
      "100%|| 63/63 [00:23<00:00,  2.69it/s]\n",
      "Training loss:  3.2795152172209723\n",
      "Training time:  0:00:23.419948\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.249704\n",
      "338  \t  426  \t  80\n",
      "Dev P:  0.237\n",
      "Dev R:  0.188\n",
      "Dev F1:  0.209\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.837648\n",
      "345  \t  421  \t  63\n",
      "Test P:  0.183\n",
      "Test R:  0.15\n",
      "Test F1:  0.164\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  10\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  2.934456787412129\n",
      "Training time:  0:00:23.596390\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.261558\n",
      "377  \t  426  \t  83\n",
      "Dev P:  0.22\n",
      "Dev R:  0.195\n",
      "Dev F1:  0.207\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.829039\n",
      "375  \t  421  \t  67\n",
      "Test P:  0.179\n",
      "Test R:  0.159\n",
      "Test F1:  0.168\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  11\n",
      "100%|| 63/63 [00:23<00:00,  2.70it/s]\n",
      "Training loss:  2.5964873295927804\n",
      "Training time:  0:00:23.345443\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.250241\n",
      "334  \t  426  \t  74\n",
      "Dev P:  0.222\n",
      "Dev R:  0.174\n",
      "Dev F1:  0.195\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.828816\n",
      "335  \t  421  \t  62\n",
      "Test P:  0.185\n",
      "Test R:  0.147\n",
      "Test F1:  0.164\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  12\n",
      "100%|| 63/63 [00:23<00:00,  2.71it/s]\n",
      "Training loss:  2.3597497694076055\n",
      "Training time:  0:00:23.245978\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.37it/s]\n",
      "Prediction time:  0:00:06.234704\n",
      "329  \t  426  \t  73\n",
      "Dev P:  0.222\n",
      "Dev R:  0.171\n",
      "Dev F1:  0.193\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.62it/s]\n",
      "Prediction time:  0:00:05.805709\n",
      "329  \t  421  \t  64\n",
      "Test P:  0.195\n",
      "Test R:  0.152\n",
      "Test F1:  0.171\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  13\n",
      "100%|| 63/63 [00:23<00:00,  2.65it/s]\n",
      "Training loss:  2.1230714396824912\n",
      "Training time:  0:00:23.784982\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.37it/s]\n",
      "Prediction time:  0:00:06.236964\n",
      "342  \t  426  \t  78\n",
      "Dev P:  0.228\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.203\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.829157\n",
      "349  \t  421  \t  60\n",
      "Test P:  0.172\n",
      "Test R:  0.143\n",
      "Test F1:  0.156\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  14\n",
      "100%|| 63/63 [00:23<00:00,  2.69it/s]\n",
      "Training loss:  2.008579578664568\n",
      "Training time:  0:00:23.409479\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.250435\n",
      "330  \t  426  \t  74\n",
      "Dev P:  0.224\n",
      "Dev R:  0.174\n",
      "Dev F1:  0.196\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.843898\n",
      "330  \t  421  \t  62\n",
      "Test P:  0.188\n",
      "Test R:  0.147\n",
      "Test F1:  0.165\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  15\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  1.740304310170431\n",
      "Training time:  0:00:23.624386\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.266354\n",
      "334  \t  426  \t  78\n",
      "Dev P:  0.234\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.205\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.831648\n",
      "345  \t  421  \t  63\n",
      "Test P:  0.183\n",
      "Test R:  0.15\n",
      "Test F1:  0.164\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  16\n",
      "100%|| 63/63 [00:23<00:00,  2.65it/s]\n",
      "Training loss:  1.7367031271495517\n",
      "Training time:  0:00:23.782317\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.241314\n",
      "381  \t  426  \t  77\n",
      "Dev P:  0.202\n",
      "Dev R:  0.181\n",
      "Dev F1:  0.191\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.62it/s]\n",
      "Prediction time:  0:00:05.797035\n",
      "386  \t  421  \t  66\n",
      "Test P:  0.171\n",
      "Test R:  0.157\n",
      "Test F1:  0.164\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  17\n",
      "100%|| 63/63 [00:23<00:00,  2.69it/s]\n",
      "Training loss:  1.570548877829597\n",
      "Training time:  0:00:23.391903\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.249776\n",
      "341  \t  426  \t  80\n",
      "Dev P:  0.235\n",
      "Dev R:  0.188\n",
      "Dev F1:  0.209\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.833292\n",
      "334  \t  421  \t  60\n",
      "Test P:  0.18\n",
      "Test R:  0.143\n",
      "Test F1:  0.159\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  18\n",
      "100%|| 63/63 [00:23<00:00,  2.66it/s]\n",
      "Training loss:  1.486298606509254\n",
      "Training time:  0:00:23.679887\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.255410\n",
      "337  \t  426  \t  82\n",
      "Dev P:  0.243\n",
      "Dev R:  0.192\n",
      "Dev F1:  0.215\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.826834\n",
      "335  \t  421  \t  56\n",
      "Test P:  0.167\n",
      "Test R:  0.133\n",
      "Test F1:  0.148\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  19\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  1.3544624566085754\n",
      "Training time:  0:00:23.553067\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.252441\n",
      "331  \t  426  \t  71\n",
      "Dev P:  0.215\n",
      "Dev R:  0.167\n",
      "Dev F1:  0.188\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.826728\n",
      "333  \t  421  \t  59\n",
      "Test P:  0.177\n",
      "Test R:  0.14\n",
      "Test F1:  0.156\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:23<00:00,  2.70it/s]\n",
      "Training loss:  1.3472653882844108\n",
      "Training time:  0:00:23.341338\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.38it/s]\n",
      "Prediction time:  0:00:06.217696\n",
      "368  \t  426  \t  88\n",
      "Dev P:  0.239\n",
      "Dev R:  0.207\n",
      "Dev F1:  0.222\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.61it/s]\n",
      "Prediction time:  0:00:05.816528\n",
      "383  \t  421  \t  67\n",
      "Test P:  0.175\n",
      "Test R:  0.159\n",
      "Test F1:  0.167\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  21\n",
      "100%|| 63/63 [00:23<00:00,  2.70it/s]\n",
      "Training loss:  1.2330296436945598\n",
      "Training time:  0:00:23.308195\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.247968\n",
      "366  \t  426  \t  74\n",
      "Dev P:  0.202\n",
      "Dev R:  0.174\n",
      "Dev F1:  0.187\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.844624\n",
      "378  \t  421  \t  57\n",
      "Test P:  0.151\n",
      "Test R:  0.135\n",
      "Test F1:  0.143\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  22\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  1.1433447518992046\n",
      "Training time:  0:00:23.558370\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.263561\n",
      "350  \t  426  \t  81\n",
      "Dev P:  0.231\n",
      "Dev R:  0.19\n",
      "Dev F1:  0.209\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.852033\n",
      "356  \t  421  \t  61\n",
      "Test P:  0.171\n",
      "Test R:  0.145\n",
      "Test F1:  0.157\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  23\n",
      "100%|| 63/63 [00:23<00:00,  2.69it/s]\n",
      "Training loss:  1.0290321054912748\n",
      "Training time:  0:00:23.408230\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.268236\n",
      "342  \t  426  \t  75\n",
      "Dev P:  0.219\n",
      "Dev R:  0.176\n",
      "Dev F1:  0.195\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.835205\n",
      "347  \t  421  \t  55\n",
      "Test P:  0.159\n",
      "Test R:  0.131\n",
      "Test F1:  0.143\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  24\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  1.0112287946163663\n",
      "Training time:  0:00:23.582087\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.241451\n",
      "351  \t  426  \t  78\n",
      "Dev P:  0.222\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.201\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.61it/s]\n",
      "Prediction time:  0:00:05.819328\n",
      "356  \t  421  \t  61\n",
      "Test P:  0.171\n",
      "Test R:  0.145\n",
      "Test F1:  0.157\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  25\n",
      "100%|| 63/63 [00:23<00:00,  2.69it/s]\n",
      "Training loss:  1.0729672918244013\n",
      "Training time:  0:00:23.456504\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.260200\n",
      "380  \t  426  \t  87\n",
      "Dev P:  0.229\n",
      "Dev R:  0.204\n",
      "Dev F1:  0.216\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.830270\n",
      "394  \t  421  \t  66\n",
      "Test P:  0.168\n",
      "Test R:  0.157\n",
      "Test F1:  0.162\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  26\n",
      "100%|| 63/63 [00:23<00:00,  2.65it/s]\n",
      "Training loss:  1.0895674006333427\n",
      "Training time:  0:00:23.804210\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.246693\n",
      "355  \t  426  \t  82\n",
      "Dev P:  0.231\n",
      "Dev R:  0.192\n",
      "Dev F1:  0.21\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.61it/s]\n",
      "Prediction time:  0:00:05.819113\n",
      "362  \t  421  \t  62\n",
      "Test P:  0.171\n",
      "Test R:  0.147\n",
      "Test F1:  0.158\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  27\n",
      "100%|| 63/63 [00:23<00:00,  2.65it/s]\n",
      "Training loss:  0.9713801131362007\n",
      "Training time:  0:00:23.789183\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.249511\n",
      "346  \t  426  \t  75\n",
      "Dev P:  0.217\n",
      "Dev R:  0.176\n",
      "Dev F1:  0.194\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.825918\n",
      "354  \t  421  \t  57\n",
      "Test P:  0.161\n",
      "Test R:  0.135\n",
      "Test F1:  0.147\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  28\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  0.8738558857686936\n",
      "Training time:  0:00:23.588339\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.265526\n",
      "359  \t  426  \t  85\n",
      "Dev P:  0.237\n",
      "Dev R:  0.2\n",
      "Dev F1:  0.217\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.845244\n",
      "362  \t  421  \t  58\n",
      "Test P:  0.16\n",
      "Test R:  0.138\n",
      "Test F1:  0.148\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  29\n",
      "100%|| 63/63 [00:23<00:00,  2.70it/s]\n",
      "Training loss:  0.7481573517360385\n",
      "Training time:  0:00:23.307140\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.249774\n",
      "382  \t  426  \t  89\n",
      "Dev P:  0.233\n",
      "Dev R:  0.209\n",
      "Dev F1:  0.22\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.61it/s]\n",
      "Prediction time:  0:00:05.821998\n",
      "389  \t  421  \t  52\n",
      "Test P:  0.134\n",
      "Test R:  0.124\n",
      "Test F1:  0.128\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  30\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  0.6972038256270545\n",
      "Training time:  0:00:23.589744\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.281350\n",
      "353  \t  426  \t  81\n",
      "Dev P:  0.229\n",
      "Dev R:  0.19\n",
      "Dev F1:  0.208\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.833596\n",
      "357  \t  421  \t  60\n",
      "Test P:  0.168\n",
      "Test R:  0.143\n",
      "Test F1:  0.154\n",
      "\n",
      "\n",
      "\n",
      "*******\n",
      "Best Epoch:  20\n",
      "Best Epoch Seed:  62\n",
      "Corresponding P:  0.175\n",
      "Corresponding R:  0.159\n",
      "Corresponding F1:  0.167\n",
      "\n",
      "\n",
      "\n",
      "Best Test Epoch:  12\n",
      "Corresponding P:  0.195\n",
      "Corresponding R:  0.152\n",
      "Corresponding F1:  0.171\n",
      "\n",
      "\n",
      "\n",
      "Test size: 322\n",
      "Re-checking the scores of entire Test data with the best saved model:\n",
      "Total sentences in the test set:  322\n",
      "GT Triple Count:  421  \tPRED Triple Count:  383  \tCORRECT Triple Count:  67\n",
      "Test P:  0.175\n",
      "Test R:  0.159\n",
      "Test F1:  0.167\n",
      "Now printing the scores for various subsets of Test Data with the best saved model:\n",
      "Total sentences with single triples:  243\n",
      "GT Triple Count:  243  \tPRED Triple Count:  273  \tCORRECT Triple Count:  44\n",
      "Test P:  0.161\n",
      "Test R:  0.181\n",
      "Test F1:  0.171\n",
      "Total sentences with multiple triples:  79\n",
      "GT Triple Count:  178  \tPRED Triple Count:  110  \tCORRECT Triple Count:  23\n",
      "Test P:  0.209\n",
      "Test R:  0.129\n",
      "Test F1:  0.16\n",
      "Total sentences triples with varying sentiments:  31\n",
      "GT Triple Count:  79  \tPRED Triple Count:  44  \tCORRECT Triple Count:  5\n",
      "Test P:  0.114\n",
      "Test R:  0.063\n",
      "Test F1:  0.081\n",
      "Total sentences with overlapping triples:  42\n",
      "GT Triple Count:  95  \tPRED Triple Count:  51  \tCORRECT Triple Count:  8\n",
      "Test P:  0.157\n",
      "Test R:  0.084\n",
      "Test F1:  0.11\n"
     ]
    }
   ],
   "source": [
    "!python3 PASTE_BERT.py --gpu_id 0 --src_folder mpqa/ --trg_folder mpqa/PASTE_BERT --bert_mode gen --gen_direct af --l2 y --use_pos_tags y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23b15764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/shivam/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/shivam/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/shivam/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "enc_hidden_size: 818\n",
      "dec_inp_size: 818\n",
      "dec_hidden_size: 818\n",
      "pointer_net_hidden_size: 300\n",
      "['PASTE_BERT.py', '--gpu_id', '0', '--src_folder', 'mpqa/', '--trg_folder', 'mpqa/PASTE_BERT', '--bert_mode', 'gen', '--gen_direct', 'af', '--l2', 'y', '--use_dep_emb', 'y']\n",
      "100  10  0.5\n",
      "BERT\n",
      "loading data......\n",
      "No. of sentences:  996\n",
      "No. of lines in Target file:  996\n",
      "No. of lines in POS file:  996\n",
      "No. of lines in DEP file:  996\n",
      "No. of sentences:  323\n",
      "No. of lines in Target file:  323\n",
      "No. of lines in POS file:  323\n",
      "No. of lines in DEP file:  323\n",
      "No. of sentences:  322\n",
      "No. of lines in Target file:  322\n",
      "No. of lines in POS file:  322\n",
      "No. of lines in DEP file:  322\n",
      "Training data size:  994\n",
      "Development data size:  323\n",
      "Test data size:  322\n",
      "Building POS TAG Vocab..\n",
      "Building DEP TAG Vocab..\n",
      "Training started......\n",
      "Batch Count:   63\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_attentions\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/shivam/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Parameters size:  129771609\n",
      "weight factor:  1\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "Epoch:  1\n",
      "  0%|                                                    | 0/63 [00:00<?, ?it/s]/home/shivam/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2251: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  9.916003098563543\n",
      "Training time:  0:00:23.484791\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.248929\n",
      "324  \t  426  \t  48\n",
      "Dev P:  0.148\n",
      "Dev R:  0.113\n",
      "Dev F1:  0.128\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.61it/s]\n",
      "Prediction time:  0:00:05.819147\n",
      "322  \t  421  \t  35\n",
      "Test P:  0.109\n",
      "Test R:  0.083\n",
      "Test F1:  0.094\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  2\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  7.111722590431334\n",
      "Training time:  0:00:23.605682\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.37it/s]\n",
      "Prediction time:  0:00:06.237942\n",
      "323  \t  426  \t  56\n",
      "Dev P:  0.173\n",
      "Dev R:  0.131\n",
      "Dev F1:  0.15\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.61it/s]\n",
      "Prediction time:  0:00:05.819049\n",
      "322  \t  421  \t  50\n",
      "Test P:  0.155\n",
      "Test R:  0.119\n",
      "Test F1:  0.135\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  3\n",
      "100%|| 63/63 [00:23<00:00,  2.69it/s]\n",
      "Training loss:  6.333568762219142\n",
      "Training time:  0:00:23.400745\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.37it/s]\n",
      "Prediction time:  0:00:06.238707\n",
      "324  \t  426  \t  61\n",
      "Dev P:  0.188\n",
      "Dev R:  0.143\n",
      "Dev F1:  0.163\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.61it/s]\n",
      "Prediction time:  0:00:05.813455\n",
      "322  \t  421  \t  54\n",
      "Test P:  0.168\n",
      "Test R:  0.128\n",
      "Test F1:  0.145\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  4\n",
      "100%|| 63/63 [00:23<00:00,  2.72it/s]\n",
      "Training loss:  5.749711793566507\n",
      "Training time:  0:00:23.185876\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.37it/s]\n",
      "Prediction time:  0:00:06.237085\n",
      "323  \t  426  \t  70\n",
      "Dev P:  0.217\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.187\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.61it/s]\n",
      "Prediction time:  0:00:05.817078\n",
      "323  \t  421  \t  57\n",
      "Test P:  0.176\n",
      "Test R:  0.135\n",
      "Test F1:  0.153\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  5\n",
      "100%|| 63/63 [00:23<00:00,  2.71it/s]\n",
      "Training loss:  5.19585685124473\n",
      "Training time:  0:00:23.283724\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.37it/s]\n",
      "Prediction time:  0:00:06.232966\n",
      "406  \t  426  \t  72\n",
      "Dev P:  0.177\n",
      "Dev R:  0.169\n",
      "Dev F1:  0.173\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.830465\n",
      "391  \t  421  \t  61\n",
      "Test P:  0.156\n",
      "Test R:  0.145\n",
      "Test F1:  0.15\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  6\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  4.611025556685433\n",
      "Training time:  0:00:23.503773\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.276195\n",
      "369  \t  426  \t  76\n",
      "Dev P:  0.206\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.191\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.857555\n",
      "383  \t  421  \t  74\n",
      "Test P:  0.193\n",
      "Test R:  0.176\n",
      "Test F1:  0.184\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  7\n",
      "100%|| 63/63 [00:23<00:00,  2.66it/s]\n",
      "Training loss:  4.260310127621605\n",
      "Training time:  0:00:23.684357\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.244239\n",
      "337  \t  426  \t  75\n",
      "Dev P:  0.223\n",
      "Dev R:  0.176\n",
      "Dev F1:  0.197\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.61it/s]\n",
      "Prediction time:  0:00:05.818445\n",
      "338  \t  421  \t  61\n",
      "Test P:  0.18\n",
      "Test R:  0.145\n",
      "Test F1:  0.161\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  8\n",
      "100%|| 63/63 [00:23<00:00,  2.70it/s]\n",
      "Training loss:  3.649136774123661\n",
      "Training time:  0:00:23.367392\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.243355\n",
      "345  \t  426  \t  80\n",
      "Dev P:  0.232\n",
      "Dev R:  0.188\n",
      "Dev F1:  0.208\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.61it/s]\n",
      "Prediction time:  0:00:05.825720\n",
      "353  \t  421  \t  64\n",
      "Test P:  0.181\n",
      "Test R:  0.152\n",
      "Test F1:  0.165\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  9\n",
      "100%|| 63/63 [00:23<00:00,  2.70it/s]\n",
      "Training loss:  3.227599503502013\n",
      "Training time:  0:00:23.300227\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.260276\n",
      "330  \t  426  \t  70\n",
      "Dev P:  0.212\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.185\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.830227\n",
      "329  \t  421  \t  68\n",
      "Test P:  0.207\n",
      "Test R:  0.162\n",
      "Test F1:  0.181\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  10\n",
      "100%|| 63/63 [00:23<00:00,  2.69it/s]\n",
      "Training loss:  3.018115929194859\n",
      "Training time:  0:00:23.439895\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.262297\n",
      "376  \t  426  \t  82\n",
      "Dev P:  0.218\n",
      "Dev R:  0.192\n",
      "Dev F1:  0.204\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.826991\n",
      "377  \t  421  \t  66\n",
      "Test P:  0.175\n",
      "Test R:  0.157\n",
      "Test F1:  0.165\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  11\n",
      "100%|| 63/63 [00:23<00:00,  2.70it/s]\n",
      "Training loss:  2.604730068691193\n",
      "Training time:  0:00:23.295834\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.262098\n",
      "384  \t  426  \t  86\n",
      "Dev P:  0.224\n",
      "Dev R:  0.202\n",
      "Dev F1:  0.212\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.832335\n",
      "381  \t  421  \t  64\n",
      "Test P:  0.168\n",
      "Test R:  0.152\n",
      "Test F1:  0.16\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  12\n",
      "100%|| 63/63 [00:23<00:00,  2.70it/s]\n",
      "Training loss:  2.318778499724373\n",
      "Training time:  0:00:23.355541\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.266788\n",
      "326  \t  426  \t  75\n",
      "Dev P:  0.23\n",
      "Dev R:  0.176\n",
      "Dev F1:  0.199\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.827329\n",
      "325  \t  421  \t  63\n",
      "Test P:  0.194\n",
      "Test R:  0.15\n",
      "Test F1:  0.169\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  13\n",
      "100%|| 63/63 [00:23<00:00,  2.66it/s]\n",
      "Training loss:  2.253925942239307\n",
      "Training time:  0:00:23.676914\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.262490\n",
      "341  \t  426  \t  74\n",
      "Dev P:  0.217\n",
      "Dev R:  0.174\n",
      "Dev F1:  0.193\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.841246\n",
      "350  \t  421  \t  70\n",
      "Test P:  0.2\n",
      "Test R:  0.166\n",
      "Test F1:  0.182\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  14\n",
      "100%|| 63/63 [00:23<00:00,  2.70it/s]\n",
      "Training loss:  2.042642105193365\n",
      "Training time:  0:00:23.329613\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.260643\n",
      "362  \t  426  \t  83\n",
      "Dev P:  0.229\n",
      "Dev R:  0.195\n",
      "Dev F1:  0.211\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.827523\n",
      "372  \t  421  \t  68\n",
      "Test P:  0.183\n",
      "Test R:  0.162\n",
      "Test F1:  0.172\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  15\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  1.836225347859519\n",
      "Training time:  0:00:23.526552\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.258435\n",
      "350  \t  426  \t  76\n",
      "Dev P:  0.217\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.196\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.61it/s]\n",
      "Prediction time:  0:00:05.823481\n",
      "362  \t  421  \t  69\n",
      "Test P:  0.191\n",
      "Test R:  0.164\n",
      "Test F1:  0.176\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  16\n",
      "100%|| 63/63 [00:23<00:00,  2.66it/s]\n",
      "Training loss:  1.7295907035706535\n",
      "Training time:  0:00:23.670449\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.254691\n",
      "351  \t  426  \t  75\n",
      "Dev P:  0.214\n",
      "Dev R:  0.176\n",
      "Dev F1:  0.193\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.833489\n",
      "364  \t  421  \t  70\n",
      "Test P:  0.192\n",
      "Test R:  0.166\n",
      "Test F1:  0.178\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  17\n",
      "100%|| 63/63 [00:23<00:00,  2.70it/s]\n",
      "Training loss:  1.554947212574974\n",
      "Training time:  0:00:23.301446\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.276491\n",
      "337  \t  426  \t  74\n",
      "Dev P:  0.22\n",
      "Dev R:  0.174\n",
      "Dev F1:  0.194\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.842249\n",
      "334  \t  421  \t  68\n",
      "Test P:  0.204\n",
      "Test R:  0.162\n",
      "Test F1:  0.18\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  18\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  1.4765441658950986\n",
      "Training time:  0:00:23.510833\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.241693\n",
      "361  \t  426  \t  73\n",
      "Dev P:  0.202\n",
      "Dev R:  0.171\n",
      "Dev F1:  0.186\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.61it/s]\n",
      "Prediction time:  0:00:05.825164\n",
      "368  \t  421  \t  74\n",
      "Test P:  0.201\n",
      "Test R:  0.176\n",
      "Test F1:  0.188\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  19\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  1.4430564126325032\n",
      "Training time:  0:00:23.620624\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.279779\n",
      "377  \t  426  \t  86\n",
      "Dev P:  0.228\n",
      "Dev R:  0.202\n",
      "Dev F1:  0.214\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.840700\n",
      "380  \t  421  \t  66\n",
      "Test P:  0.174\n",
      "Test R:  0.157\n",
      "Test F1:  0.165\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:23<00:00,  2.70it/s]\n",
      "Training loss:  1.1316201696320185\n",
      "Training time:  0:00:23.323754\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.258776\n",
      "343  \t  426  \t  76\n",
      "Dev P:  0.222\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.198\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.829289\n",
      "362  \t  421  \t  61\n",
      "Test P:  0.169\n",
      "Test R:  0.145\n",
      "Test F1:  0.156\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  21\n",
      "100%|| 63/63 [00:23<00:00,  2.73it/s]\n",
      "Training loss:  1.1595351714936515\n",
      "Training time:  0:00:23.084260\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.246927\n",
      "364  \t  426  \t  79\n",
      "Dev P:  0.217\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.2\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.841300\n",
      "371  \t  421  \t  64\n",
      "Test P:  0.173\n",
      "Test R:  0.152\n",
      "Test F1:  0.162\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  22\n",
      "100%|| 63/63 [00:23<00:00,  2.69it/s]\n",
      "Training loss:  1.200881844475156\n",
      "Training time:  0:00:23.387445\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.269332\n",
      "346  \t  426  \t  70\n",
      "Dev P:  0.202\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.181\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.853681\n",
      "347  \t  421  \t  68\n",
      "Test P:  0.196\n",
      "Test R:  0.162\n",
      "Test F1:  0.177\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  23\n",
      "100%|| 63/63 [00:23<00:00,  2.72it/s]\n",
      "Training loss:  1.0927966800000932\n",
      "Training time:  0:00:23.134619\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.265481\n",
      "351  \t  426  \t  75\n",
      "Dev P:  0.214\n",
      "Dev R:  0.176\n",
      "Dev F1:  0.193\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.829517\n",
      "362  \t  421  \t  70\n",
      "Test P:  0.193\n",
      "Test R:  0.166\n",
      "Test F1:  0.179\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  24\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  1.0502475244658334\n",
      "Training time:  0:00:23.501801\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.37it/s]\n",
      "Prediction time:  0:00:06.236345\n",
      "328  \t  426  \t  72\n",
      "Dev P:  0.22\n",
      "Dev R:  0.169\n",
      "Dev F1:  0.191\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.825917\n",
      "331  \t  421  \t  67\n",
      "Test P:  0.202\n",
      "Test R:  0.159\n",
      "Test F1:  0.178\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  25\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  1.0716484501248313\n",
      "Training time:  0:00:23.467650\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.279287\n",
      "349  \t  426  \t  72\n",
      "Dev P:  0.206\n",
      "Dev R:  0.169\n",
      "Dev F1:  0.186\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.844243\n",
      "357  \t  421  \t  70\n",
      "Test P:  0.196\n",
      "Test R:  0.166\n",
      "Test F1:  0.18\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  26\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  0.9520069753366803\n",
      "Training time:  0:00:23.550874\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.267239\n",
      "346  \t  426  \t  74\n",
      "Dev P:  0.214\n",
      "Dev R:  0.174\n",
      "Dev F1:  0.192\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.841093\n",
      "349  \t  421  \t  67\n",
      "Test P:  0.192\n",
      "Test R:  0.159\n",
      "Test F1:  0.174\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  27\n",
      "100%|| 63/63 [00:23<00:00,  2.65it/s]\n",
      "Training loss:  0.8699595426756238\n",
      "Training time:  0:00:23.732045\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.38it/s]\n",
      "Prediction time:  0:00:06.213626\n",
      "340  \t  426  \t  71\n",
      "Dev P:  0.209\n",
      "Dev R:  0.167\n",
      "Dev F1:  0.185\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.61it/s]\n",
      "Prediction time:  0:00:05.809613\n",
      "353  \t  421  \t  72\n",
      "Test P:  0.204\n",
      "Test R:  0.171\n",
      "Test F1:  0.186\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  28\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  0.8980305355692667\n",
      "Training time:  0:00:23.526506\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.37it/s]\n",
      "Prediction time:  0:00:06.240590\n",
      "367  \t  426  \t  82\n",
      "Dev P:  0.223\n",
      "Dev R:  0.192\n",
      "Dev F1:  0.207\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.61it/s]\n",
      "Prediction time:  0:00:05.821622\n",
      "371  \t  421  \t  65\n",
      "Test P:  0.175\n",
      "Test R:  0.154\n",
      "Test F1:  0.164\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  29\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  0.8123094538847605\n",
      "Training time:  0:00:23.577818\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.265857\n",
      "379  \t  426  \t  83\n",
      "Dev P:  0.219\n",
      "Dev R:  0.195\n",
      "Dev F1:  0.206\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.849462\n",
      "384  \t  421  \t  67\n",
      "Test P:  0.174\n",
      "Test R:  0.159\n",
      "Test F1:  0.166\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  30\n",
      "100%|| 63/63 [00:23<00:00,  2.66it/s]\n",
      "Training loss:  0.8037955775147393\n",
      "Training time:  0:00:23.655475\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.274019\n",
      "378  \t  426  \t  76\n",
      "Dev P:  0.201\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.189\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.856466\n",
      "404  \t  421  \t  60\n",
      "Test P:  0.149\n",
      "Test R:  0.143\n",
      "Test F1:  0.145\n",
      "\n",
      "\n",
      "\n",
      "*******\n",
      "Best Epoch:  19\n",
      "Best Epoch Seed:  61\n",
      "Corresponding P:  0.174\n",
      "Corresponding R:  0.157\n",
      "Corresponding F1:  0.165\n",
      "\n",
      "\n",
      "\n",
      "Best Test Epoch:  18\n",
      "Corresponding P:  0.201\n",
      "Corresponding R:  0.176\n",
      "Corresponding F1:  0.188\n",
      "\n",
      "\n",
      "\n",
      "Test size: 322\n",
      "Re-checking the scores of entire Test data with the best saved model:\n",
      "Total sentences in the test set:  322\n",
      "GT Triple Count:  421  \tPRED Triple Count:  380  \tCORRECT Triple Count:  66\n",
      "Test P:  0.174\n",
      "Test R:  0.157\n",
      "Test F1:  0.165\n",
      "Now printing the scores for various subsets of Test Data with the best saved model:\n",
      "Total sentences with single triples:  243\n",
      "GT Triple Count:  243  \tPRED Triple Count:  264  \tCORRECT Triple Count:  45\n",
      "Test P:  0.17\n",
      "Test R:  0.185\n",
      "Test F1:  0.178\n",
      "Total sentences with multiple triples:  79\n",
      "GT Triple Count:  178  \tPRED Triple Count:  116  \tCORRECT Triple Count:  21\n",
      "Test P:  0.181\n",
      "Test R:  0.118\n",
      "Test F1:  0.143\n",
      "Total sentences triples with varying sentiments:  31\n",
      "GT Triple Count:  79  \tPRED Triple Count:  50  \tCORRECT Triple Count:  6\n",
      "Test P:  0.12\n",
      "Test R:  0.076\n",
      "Test F1:  0.093\n",
      "Total sentences with overlapping triples:  42\n",
      "GT Triple Count:  95  \tPRED Triple Count:  55  \tCORRECT Triple Count:  6\n",
      "Test P:  0.109\n",
      "Test R:  0.063\n",
      "Test F1:  0.08\n"
     ]
    }
   ],
   "source": [
    "!python3 PASTE_BERT.py --gpu_id 0 --src_folder mpqa/ --trg_folder mpqa/PASTE_BERT --bert_mode gen --gen_direct af --l2 y --use_dep_emb y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea28043f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/shivam/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/shivam/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/shivam/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "enc_hidden_size: 868\n",
      "dec_inp_size: 868\n",
      "dec_hidden_size: 868\n",
      "pointer_net_hidden_size: 300\n",
      "['PASTE_BERT.py', '--gpu_id', '0', '--src_folder', 'mpqa/', '--trg_folder', 'mpqa/PASTE_BERT', '--bert_mode', 'gen', '--gen_direct', 'af', '--l2', 'y', '--use_pos_tags', 'y', '--use_dep_emb', 'y']\n",
      "100  10  0.5\n",
      "BERT\n",
      "loading data......\n",
      "No. of sentences:  996\n",
      "No. of lines in Target file:  996\n",
      "No. of lines in POS file:  996\n",
      "No. of lines in DEP file:  996\n",
      "No. of sentences:  323\n",
      "No. of lines in Target file:  323\n",
      "No. of lines in POS file:  323\n",
      "No. of lines in DEP file:  323\n",
      "No. of sentences:  322\n",
      "No. of lines in Target file:  322\n",
      "No. of lines in POS file:  322\n",
      "No. of lines in DEP file:  322\n",
      "Training data size:  994\n",
      "Development data size:  323\n",
      "Test data size:  322\n",
      "Building POS TAG Vocab..\n",
      "Building DEP TAG Vocab..\n",
      "Training started......\n",
      "Batch Count:   63\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_attentions\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/shivam/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Parameters size:  131663959\n",
      "weight factor:  1\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "Epoch:  1\n",
      "  0%|                                                    | 0/63 [00:00<?, ?it/s]/home/shivam/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2251: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|| 63/63 [00:24<00:00,  2.58it/s]\n",
      "Training loss:  9.810933612641835\n",
      "Training time:  0:00:24.409088\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.440164\n",
      "323  \t  426  \t  45\n",
      "Dev P:  0.139\n",
      "Dev R:  0.106\n",
      "Dev F1:  0.12\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:05.996011\n",
      "322  \t  421  \t  41\n",
      "Test P:  0.127\n",
      "Test R:  0.097\n",
      "Test F1:  0.11\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  2\n",
      "100%|| 63/63 [00:24<00:00,  2.58it/s]\n",
      "Training loss:  7.106110474419972\n",
      "Training time:  0:00:24.395445\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.28it/s]\n",
      "Prediction time:  0:00:06.396995\n",
      "323  \t  426  \t  67\n",
      "Dev P:  0.207\n",
      "Dev R:  0.157\n",
      "Dev F1:  0.179\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.52it/s]\n",
      "Prediction time:  0:00:05.958773\n",
      "322  \t  421  \t  49\n",
      "Test P:  0.152\n",
      "Test R:  0.116\n",
      "Test F1:  0.132\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  3\n",
      "100%|| 63/63 [00:24<00:00,  2.60it/s]\n",
      "Training loss:  6.32486243096609\n",
      "Training time:  0:00:24.244685\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.444317\n",
      "323  \t  426  \t  60\n",
      "Dev P:  0.186\n",
      "Dev R:  0.141\n",
      "Dev F1:  0.16\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:06.006005\n",
      "322  \t  421  \t  43\n",
      "Test P:  0.134\n",
      "Test R:  0.102\n",
      "Test F1:  0.116\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  4\n",
      "100%|| 63/63 [00:23<00:00,  2.63it/s]\n",
      "Training loss:  5.746884293026394\n",
      "Training time:  0:00:23.964858\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.24it/s]\n",
      "Prediction time:  0:00:06.484372\n",
      "325  \t  426  \t  69\n",
      "Dev P:  0.212\n",
      "Dev R:  0.162\n",
      "Dev F1:  0.184\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.48it/s]\n",
      "Prediction time:  0:00:06.043022\n",
      "325  \t  421  \t  54\n",
      "Test P:  0.166\n",
      "Test R:  0.128\n",
      "Test F1:  0.145\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  5\n",
      "100%|| 63/63 [00:24<00:00,  2.61it/s]\n",
      "Training loss:  5.234000962878031\n",
      "Training time:  0:00:24.112516\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.27it/s]\n",
      "Prediction time:  0:00:06.418413\n",
      "352  \t  426  \t  69\n",
      "Dev P:  0.196\n",
      "Dev R:  0.162\n",
      "Dev F1:  0.177\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.51it/s]\n",
      "Prediction time:  0:00:05.979395\n",
      "362  \t  421  \t  65\n",
      "Test P:  0.18\n",
      "Test R:  0.154\n",
      "Test F1:  0.166\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  6\n",
      "100%|| 63/63 [00:24<00:00,  2.58it/s]\n",
      "Training loss:  4.678104926669408\n",
      "Training time:  0:00:24.383960\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.25it/s]\n",
      "Prediction time:  0:00:06.466890\n",
      "398  \t  426  \t  86\n",
      "Dev P:  0.216\n",
      "Dev R:  0.202\n",
      "Dev F1:  0.209\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.49it/s]\n",
      "Prediction time:  0:00:06.016569\n",
      "393  \t  421  \t  69\n",
      "Test P:  0.176\n",
      "Test R:  0.164\n",
      "Test F1:  0.17\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  7\n",
      "100%|| 63/63 [00:24<00:00,  2.56it/s]\n",
      "Training loss:  4.400205793834868\n",
      "Training time:  0:00:24.629453\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.24it/s]\n",
      "Prediction time:  0:00:06.488607\n",
      "335  \t  426  \t  77\n",
      "Dev P:  0.23\n",
      "Dev R:  0.181\n",
      "Dev F1:  0.202\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.48it/s]\n",
      "Prediction time:  0:00:06.042672\n",
      "339  \t  421  \t  58\n",
      "Test P:  0.171\n",
      "Test R:  0.138\n",
      "Test F1:  0.153\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  8\n",
      "100%|| 63/63 [00:24<00:00,  2.60it/s]\n",
      "Training loss:  3.926847544927446\n",
      "Training time:  0:00:24.273025\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.28it/s]\n",
      "Prediction time:  0:00:06.394765\n",
      "335  \t  426  \t  70\n",
      "Dev P:  0.209\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.184\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.52it/s]\n",
      "Prediction time:  0:00:05.971562\n",
      "335  \t  421  \t  57\n",
      "Test P:  0.17\n",
      "Test R:  0.135\n",
      "Test F1:  0.151\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  9\n",
      "100%|| 63/63 [00:24<00:00,  2.60it/s]\n",
      "Training loss:  3.4606348976256354\n",
      "Training time:  0:00:24.269605\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.435020\n",
      "327  \t  426  \t  70\n",
      "Dev P:  0.214\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.186\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:06.003433\n",
      "326  \t  421  \t  64\n",
      "Test P:  0.196\n",
      "Test R:  0.152\n",
      "Test F1:  0.171\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  10\n",
      "100%|| 63/63 [00:24<00:00,  2.59it/s]\n",
      "Training loss:  3.049605303340488\n",
      "Training time:  0:00:24.330129\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.25it/s]\n",
      "Prediction time:  0:00:06.458921\n",
      "348  \t  426  \t  78\n",
      "Dev P:  0.224\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.202\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.49it/s]\n",
      "Prediction time:  0:00:06.021449\n",
      "346  \t  421  \t  59\n",
      "Test P:  0.171\n",
      "Test R:  0.14\n",
      "Test F1:  0.154\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  11\n",
      "100%|| 63/63 [00:24<00:00,  2.60it/s]\n",
      "Training loss:  2.850707548478293\n",
      "Training time:  0:00:24.266721\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.444143\n",
      "351  \t  426  \t  74\n",
      "Dev P:  0.211\n",
      "Dev R:  0.174\n",
      "Dev F1:  0.19\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:05.997101\n",
      "351  \t  421  \t  65\n",
      "Test P:  0.185\n",
      "Test R:  0.154\n",
      "Test F1:  0.168\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  12\n",
      "100%|| 63/63 [00:24<00:00,  2.62it/s]\n",
      "Training loss:  2.5184899757778836\n",
      "Training time:  0:00:24.020943\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.28it/s]\n",
      "Prediction time:  0:00:06.411278\n",
      "327  \t  426  \t  67\n",
      "Dev P:  0.205\n",
      "Dev R:  0.157\n",
      "Dev F1:  0.178\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.52it/s]\n",
      "Prediction time:  0:00:05.973382\n",
      "333  \t  421  \t  65\n",
      "Test P:  0.195\n",
      "Test R:  0.154\n",
      "Test F1:  0.172\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  13\n",
      "100%|| 63/63 [00:24<00:00,  2.56it/s]\n",
      "Training loss:  2.3578299321825544\n",
      "Training time:  0:00:24.625435\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.440573\n",
      "331  \t  426  \t  71\n",
      "Dev P:  0.215\n",
      "Dev R:  0.167\n",
      "Dev F1:  0.188\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:06.002395\n",
      "335  \t  421  \t  57\n",
      "Test P:  0.17\n",
      "Test R:  0.135\n",
      "Test F1:  0.151\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  14\n",
      "100%|| 63/63 [00:24<00:00,  2.61it/s]\n",
      "Training loss:  2.128340514879378\n",
      "Training time:  0:00:24.181358\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.28it/s]\n",
      "Prediction time:  0:00:06.401084\n",
      "344  \t  426  \t  80\n",
      "Dev P:  0.233\n",
      "Dev R:  0.188\n",
      "Dev F1:  0.208\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.52it/s]\n",
      "Prediction time:  0:00:05.969523\n",
      "352  \t  421  \t  65\n",
      "Test P:  0.185\n",
      "Test R:  0.154\n",
      "Test F1:  0.168\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  15\n",
      "100%|| 63/63 [00:24<00:00,  2.57it/s]\n",
      "Training loss:  1.9520758768868824\n",
      "Training time:  0:00:24.543994\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.446127\n",
      "345  \t  426  \t  71\n",
      "Dev P:  0.206\n",
      "Dev R:  0.167\n",
      "Dev F1:  0.184\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:05.999579\n",
      "355  \t  421  \t  67\n",
      "Test P:  0.189\n",
      "Test R:  0.159\n",
      "Test F1:  0.173\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  16\n",
      "100%|| 63/63 [00:24<00:00,  2.56it/s]\n",
      "Training loss:  1.8543510550544375\n",
      "Training time:  0:00:24.588892\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.27it/s]\n",
      "Prediction time:  0:00:06.429209\n",
      "363  \t  426  \t  76\n",
      "Dev P:  0.209\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.193\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.51it/s]\n",
      "Prediction time:  0:00:05.977568\n",
      "375  \t  421  \t  70\n",
      "Test P:  0.187\n",
      "Test R:  0.166\n",
      "Test F1:  0.176\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  17\n",
      "100%|| 63/63 [00:24<00:00,  2.60it/s]\n",
      "Training loss:  1.6478689577844408\n",
      "Training time:  0:00:24.187614\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.25it/s]\n",
      "Prediction time:  0:00:06.453529\n",
      "329  \t  426  \t  70\n",
      "Dev P:  0.213\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.185\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.49it/s]\n",
      "Prediction time:  0:00:06.019340\n",
      "331  \t  421  \t  64\n",
      "Test P:  0.193\n",
      "Test R:  0.152\n",
      "Test F1:  0.17\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  18\n",
      "100%|| 63/63 [00:24<00:00,  2.56it/s]\n",
      "Training loss:  1.5761179706406971\n",
      "Training time:  0:00:24.563455\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.25it/s]\n",
      "Prediction time:  0:00:06.471174\n",
      "346  \t  426  \t  77\n",
      "Dev P:  0.223\n",
      "Dev R:  0.181\n",
      "Dev F1:  0.199\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.49it/s]\n",
      "Prediction time:  0:00:06.013821\n",
      "351  \t  421  \t  63\n",
      "Test P:  0.179\n",
      "Test R:  0.15\n",
      "Test F1:  0.163\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  19\n",
      "100%|| 63/63 [00:24<00:00,  2.56it/s]\n",
      "Training loss:  1.4053797144738456\n",
      "Training time:  0:00:24.580072\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.25it/s]\n",
      "Prediction time:  0:00:06.458625\n",
      "360  \t  426  \t  70\n",
      "Dev P:  0.194\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.178\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:06.005301\n",
      "361  \t  421  \t  59\n",
      "Test P:  0.163\n",
      "Test R:  0.14\n",
      "Test F1:  0.151\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:24<00:00,  2.60it/s]\n",
      "Training loss:  1.4239496295414273\n",
      "Training time:  0:00:24.216191\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.435388\n",
      "338  \t  426  \t  70\n",
      "Dev P:  0.207\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.183\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.51it/s]\n",
      "Prediction time:  0:00:05.990020\n",
      "336  \t  421  \t  62\n",
      "Test P:  0.185\n",
      "Test R:  0.147\n",
      "Test F1:  0.164\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  21\n",
      "100%|| 63/63 [00:24<00:00,  2.61it/s]\n",
      "Training loss:  1.290835990792229\n",
      "Training time:  0:00:24.102398\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.25it/s]\n",
      "Prediction time:  0:00:06.460771\n",
      "402  \t  426  \t  79\n",
      "Dev P:  0.197\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.191\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.49it/s]\n",
      "Prediction time:  0:00:06.023197\n",
      "406  \t  421  \t  69\n",
      "Test P:  0.17\n",
      "Test R:  0.164\n",
      "Test F1:  0.167\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  22\n",
      "100%|| 63/63 [00:24<00:00,  2.59it/s]\n",
      "Training loss:  1.2804955527895974\n",
      "Training time:  0:00:24.310529\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.27it/s]\n",
      "Prediction time:  0:00:06.424586\n",
      "348  \t  426  \t  72\n",
      "Dev P:  0.207\n",
      "Dev R:  0.169\n",
      "Dev F1:  0.186\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:05.992664\n",
      "350  \t  421  \t  63\n",
      "Test P:  0.18\n",
      "Test R:  0.15\n",
      "Test F1:  0.163\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  23\n",
      "100%|| 63/63 [00:24<00:00,  2.61it/s]\n",
      "Training loss:  1.090959710734231\n",
      "Training time:  0:00:24.139188\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.24it/s]\n",
      "Prediction time:  0:00:06.484538\n",
      "351  \t  426  \t  74\n",
      "Dev P:  0.211\n",
      "Dev R:  0.174\n",
      "Dev F1:  0.19\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.47it/s]\n",
      "Prediction time:  0:00:06.051779\n",
      "374  \t  421  \t  66\n",
      "Test P:  0.176\n",
      "Test R:  0.157\n",
      "Test F1:  0.166\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  24\n",
      "100%|| 63/63 [00:24<00:00,  2.57it/s]\n",
      "Training loss:  1.050135576535785\n",
      "Training time:  0:00:24.476628\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.27it/s]\n",
      "Prediction time:  0:00:06.419431\n",
      "366  \t  426  \t  73\n",
      "Dev P:  0.199\n",
      "Dev R:  0.171\n",
      "Dev F1:  0.184\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.51it/s]\n",
      "Prediction time:  0:00:05.991837\n",
      "383  \t  421  \t  61\n",
      "Test P:  0.159\n",
      "Test R:  0.145\n",
      "Test F1:  0.152\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  25\n",
      "100%|| 63/63 [00:24<00:00,  2.59it/s]\n",
      "Training loss:  1.085636023491148\n",
      "Training time:  0:00:24.312378\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.25it/s]\n",
      "Prediction time:  0:00:06.464261\n",
      "343  \t  426  \t  78\n",
      "Dev P:  0.227\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.203\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.49it/s]\n",
      "Prediction time:  0:00:06.021071\n",
      "342  \t  421  \t  61\n",
      "Test P:  0.178\n",
      "Test R:  0.145\n",
      "Test F1:  0.16\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  26\n",
      "100%|| 63/63 [00:24<00:00,  2.57it/s]\n",
      "Training loss:  0.9973353845259499\n",
      "Training time:  0:00:24.466847\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.27it/s]\n",
      "Prediction time:  0:00:06.421411\n",
      "347  \t  426  \t  77\n",
      "Dev P:  0.222\n",
      "Dev R:  0.181\n",
      "Dev F1:  0.199\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.51it/s]\n",
      "Prediction time:  0:00:05.987544\n",
      "364  \t  421  \t  69\n",
      "Test P:  0.19\n",
      "Test R:  0.164\n",
      "Test F1:  0.176\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  27\n",
      "100%|| 63/63 [00:24<00:00,  2.55it/s]\n",
      "Training loss:  1.0430497858259413\n",
      "Training time:  0:00:24.677394\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.24it/s]\n",
      "Prediction time:  0:00:06.473095\n",
      "356  \t  426  \t  76\n",
      "Dev P:  0.213\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.194\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.47it/s]\n",
      "Prediction time:  0:00:06.053094\n",
      "360  \t  421  \t  63\n",
      "Test P:  0.175\n",
      "Test R:  0.15\n",
      "Test F1:  0.161\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  28\n",
      "100%|| 63/63 [00:24<00:00,  2.58it/s]\n",
      "Training loss:  1.0260691271414832\n",
      "Training time:  0:00:24.443852\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.24it/s]\n",
      "Prediction time:  0:00:06.472863\n",
      "344  \t  426  \t  75\n",
      "Dev P:  0.218\n",
      "Dev R:  0.176\n",
      "Dev F1:  0.195\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.48it/s]\n",
      "Prediction time:  0:00:06.029944\n",
      "353  \t  421  \t  56\n",
      "Test P:  0.159\n",
      "Test R:  0.133\n",
      "Test F1:  0.145\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  29\n",
      "100%|| 63/63 [00:24<00:00,  2.62it/s]\n",
      "Training loss:  0.8928582521658095\n",
      "Training time:  0:00:24.084337\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.25it/s]\n",
      "Prediction time:  0:00:06.459548\n",
      "360  \t  426  \t  77\n",
      "Dev P:  0.214\n",
      "Dev R:  0.181\n",
      "Dev F1:  0.196\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.49it/s]\n",
      "Prediction time:  0:00:06.020384\n",
      "368  \t  421  \t  66\n",
      "Test P:  0.179\n",
      "Test R:  0.157\n",
      "Test F1:  0.167\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  30\n",
      "100%|| 63/63 [00:24<00:00,  2.57it/s]\n",
      "Training loss:  0.8677214980125427\n",
      "Training time:  0:00:24.500310\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.24it/s]\n",
      "Prediction time:  0:00:06.490180\n",
      "361  \t  426  \t  72\n",
      "Dev P:  0.199\n",
      "Dev R:  0.169\n",
      "Dev F1:  0.183\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.47it/s]\n",
      "Prediction time:  0:00:06.046457\n",
      "383  \t  421  \t  68\n",
      "Test P:  0.178\n",
      "Test R:  0.162\n",
      "Test F1:  0.169\n",
      "\n",
      "\n",
      "\n",
      "*******\n",
      "Best Epoch:  6\n",
      "Best Epoch Seed:  48\n",
      "Corresponding P:  0.176\n",
      "Corresponding R:  0.164\n",
      "Corresponding F1:  0.17\n",
      "\n",
      "\n",
      "\n",
      "Best Test Epoch:  16\n",
      "Corresponding P:  0.187\n",
      "Corresponding R:  0.166\n",
      "Corresponding F1:  0.176\n",
      "\n",
      "\n",
      "\n",
      "Test size: 322\n",
      "Re-checking the scores of entire Test data with the best saved model:\n",
      "Total sentences in the test set:  322\n",
      "GT Triple Count:  421  \tPRED Triple Count:  393  \tCORRECT Triple Count:  69\n",
      "Test P:  0.176\n",
      "Test R:  0.164\n",
      "Test F1:  0.17\n",
      "Now printing the scores for various subsets of Test Data with the best saved model:\n",
      "Total sentences with single triples:  243\n",
      "GT Triple Count:  243  \tPRED Triple Count:  277  \tCORRECT Triple Count:  47\n",
      "Test P:  0.17\n",
      "Test R:  0.193\n",
      "Test F1:  0.181\n",
      "Total sentences with multiple triples:  79\n",
      "GT Triple Count:  178  \tPRED Triple Count:  116  \tCORRECT Triple Count:  22\n",
      "Test P:  0.19\n",
      "Test R:  0.124\n",
      "Test F1:  0.15\n",
      "Total sentences triples with varying sentiments:  31\n",
      "GT Triple Count:  79  \tPRED Triple Count:  46  \tCORRECT Triple Count:  9\n",
      "Test P:  0.196\n",
      "Test R:  0.114\n",
      "Test F1:  0.144\n",
      "Total sentences with overlapping triples:  42\n",
      "GT Triple Count:  95  \tPRED Triple Count:  58  \tCORRECT Triple Count:  6\n",
      "Test P:  0.103\n",
      "Test R:  0.063\n",
      "Test F1:  0.078\n"
     ]
    }
   ],
   "source": [
    "!python3 PASTE_BERT.py --gpu_id 0 --src_folder mpqa/ --trg_folder mpqa/PASTE_BERT --bert_mode gen --gen_direct af --l2 y --use_pos_tags y --use_dep_emb y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dd01b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e1d5802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/shivam/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/shivam/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/shivam/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "enc_hidden_size: 768\n",
      "dec_inp_size: 768\n",
      "dec_hidden_size: 768\n",
      "pointer_net_hidden_size: 300\n",
      "['PASTE_BERT.py', '--gpu_id', '0', '--src_folder', 'mpqa/', '--trg_folder', 'mpqa/PASTE_BERT', '--bert_mode', 'gen', '--gen_direct', 'af', '--l2', 'y', '--wd', '1e-5']\n",
      "100  10  0.5\n",
      "BERT\n",
      "loading data......\n",
      "No. of sentences:  996\n",
      "No. of lines in Target file:  996\n",
      "No. of lines in POS file:  996\n",
      "No. of lines in DEP file:  996\n",
      "No. of sentences:  323\n",
      "No. of lines in Target file:  323\n",
      "No. of lines in POS file:  323\n",
      "No. of lines in DEP file:  323\n",
      "No. of sentences:  322\n",
      "No. of lines in Target file:  322\n",
      "No. of lines in POS file:  322\n",
      "No. of lines in DEP file:  322\n",
      "Training data size:  994\n",
      "Development data size:  323\n",
      "Test data size:  322\n",
      "Building POS TAG Vocab..\n",
      "Building DEP TAG Vocab..\n",
      "Training started......\n",
      "Batch Count:   63\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_attentions\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/shivam/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Parameters size:  127959659\n",
      "weight factor:  1\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 1e-05\n",
      ")\n",
      "Epoch:  1\n",
      "  0%|                                                    | 0/63 [00:00<?, ?it/s]/home/shivam/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2251: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|| 63/63 [00:22<00:00,  2.80it/s]\n",
      "Training loss:  9.894118044111464\n",
      "Training time:  0:00:22.523765\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.45it/s]\n",
      "Prediction time:  0:00:06.086437\n",
      "333  \t  426  \t  42\n",
      "Dev P:  0.126\n",
      "Dev R:  0.099\n",
      "Dev F1:  0.111\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.719157\n",
      "329  \t  421  \t  34\n",
      "Test P:  0.103\n",
      "Test R:  0.081\n",
      "Test F1:  0.091\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  2\n",
      "100%|| 63/63 [00:22<00:00,  2.80it/s]\n",
      "Training loss:  7.125623718140617\n",
      "Training time:  0:00:22.515915\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.42it/s]\n",
      "Prediction time:  0:00:06.147867\n",
      "323  \t  426  \t  58\n",
      "Dev P:  0.18\n",
      "Dev R:  0.136\n",
      "Dev F1:  0.155\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.64it/s]\n",
      "Prediction time:  0:00:05.764564\n",
      "322  \t  421  \t  46\n",
      "Test P:  0.143\n",
      "Test R:  0.109\n",
      "Test F1:  0.124\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  3\n",
      "100%|| 63/63 [00:22<00:00,  2.82it/s]\n",
      "Training loss:  6.246389850737557\n",
      "Training time:  0:00:22.325035\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.40it/s]\n",
      "Prediction time:  0:00:06.167888\n",
      "323  \t  426  \t  55\n",
      "Dev P:  0.17\n",
      "Dev R:  0.129\n",
      "Dev F1:  0.147\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.65it/s]\n",
      "Prediction time:  0:00:05.746898\n",
      "322  \t  421  \t  49\n",
      "Test P:  0.152\n",
      "Test R:  0.116\n",
      "Test F1:  0.132\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  4\n",
      "100%|| 63/63 [00:22<00:00,  2.81it/s]\n",
      "Training loss:  5.550777200668577\n",
      "Training time:  0:00:22.450844\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.125970\n",
      "326  \t  426  \t  65\n",
      "Dev P:  0.199\n",
      "Dev R:  0.153\n",
      "Dev F1:  0.173\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.66it/s]\n",
      "Prediction time:  0:00:05.732199\n",
      "327  \t  421  \t  49\n",
      "Test P:  0.15\n",
      "Test R:  0.116\n",
      "Test F1:  0.131\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  5\n",
      "100%|| 63/63 [00:22<00:00,  2.81it/s]\n",
      "Training loss:  4.988154551339528\n",
      "Training time:  0:00:22.437994\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.116823\n",
      "412  \t  426  \t  71\n",
      "Dev P:  0.172\n",
      "Dev R:  0.167\n",
      "Dev F1:  0.169\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.727753\n",
      "390  \t  421  \t  60\n",
      "Test P:  0.154\n",
      "Test R:  0.143\n",
      "Test F1:  0.148\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  6\n",
      "100%|| 63/63 [00:22<00:00,  2.75it/s]\n",
      "Training loss:  4.464142458779471\n",
      "Training time:  0:00:22.877485\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.41it/s]\n",
      "Prediction time:  0:00:06.157676\n",
      "395  \t  426  \t  82\n",
      "Dev P:  0.208\n",
      "Dev R:  0.192\n",
      "Dev F1:  0.2\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.65it/s]\n",
      "Prediction time:  0:00:05.760978\n",
      "392  \t  421  \t  62\n",
      "Test P:  0.158\n",
      "Test R:  0.147\n",
      "Test F1:  0.153\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  7\n",
      "100%|| 63/63 [00:23<00:00,  2.73it/s]\n",
      "Training loss:  3.978267722659641\n",
      "Training time:  0:00:23.102283\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.40it/s]\n",
      "Prediction time:  0:00:06.172403\n",
      "370  \t  426  \t  81\n",
      "Dev P:  0.219\n",
      "Dev R:  0.19\n",
      "Dev F1:  0.204\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.65it/s]\n",
      "Prediction time:  0:00:05.746569\n",
      "368  \t  421  \t  66\n",
      "Test P:  0.179\n",
      "Test R:  0.157\n",
      "Test F1:  0.167\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  8\n",
      "100%|| 63/63 [00:22<00:00,  2.78it/s]\n",
      "Training loss:  3.4236092359300643\n",
      "Training time:  0:00:22.693180\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.39it/s]\n",
      "Prediction time:  0:00:06.191758\n",
      "346  \t  426  \t  76\n",
      "Dev P:  0.22\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.197\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.62it/s]\n",
      "Prediction time:  0:00:05.801439\n",
      "356  \t  421  \t  63\n",
      "Test P:  0.177\n",
      "Test R:  0.15\n",
      "Test F1:  0.162\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  9\n",
      "100%|| 63/63 [00:22<00:00,  2.78it/s]\n",
      "Training loss:  3.066039165807149\n",
      "Training time:  0:00:22.674261\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.44it/s]\n",
      "Prediction time:  0:00:06.111855\n",
      "327  \t  426  \t  69\n",
      "Dev P:  0.211\n",
      "Dev R:  0.162\n",
      "Dev F1:  0.183\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.66it/s]\n",
      "Prediction time:  0:00:05.736369\n",
      "325  \t  421  \t  59\n",
      "Test P:  0.182\n",
      "Test R:  0.14\n",
      "Test F1:  0.158\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  10\n",
      "100%|| 63/63 [00:22<00:00,  2.80it/s]\n",
      "Training loss:  2.688340086785574\n",
      "Training time:  0:00:22.536318\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.42it/s]\n",
      "Prediction time:  0:00:06.138387\n",
      "347  \t  426  \t  70\n",
      "Dev P:  0.202\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.181\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.65it/s]\n",
      "Prediction time:  0:00:05.748359\n",
      "345  \t  421  \t  64\n",
      "Test P:  0.186\n",
      "Test R:  0.152\n",
      "Test F1:  0.167\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  11\n",
      "100%|| 63/63 [00:22<00:00,  2.82it/s]\n",
      "Training loss:  2.418038988397235\n",
      "Training time:  0:00:22.372784\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.42it/s]\n",
      "Prediction time:  0:00:06.144787\n",
      "359  \t  426  \t  81\n",
      "Dev P:  0.226\n",
      "Dev R:  0.19\n",
      "Dev F1:  0.206\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.66it/s]\n",
      "Prediction time:  0:00:05.742023\n",
      "354  \t  421  \t  61\n",
      "Test P:  0.172\n",
      "Test R:  0.145\n",
      "Test F1:  0.157\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  12\n",
      "100%|| 63/63 [00:22<00:00,  2.83it/s]\n",
      "Training loss:  2.2300992333699785\n",
      "Training time:  0:00:22.277032\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.44it/s]\n",
      "Prediction time:  0:00:06.099809\n",
      "359  \t  426  \t  74\n",
      "Dev P:  0.206\n",
      "Dev R:  0.174\n",
      "Dev F1:  0.189\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.68it/s]\n",
      "Prediction time:  0:00:05.710232\n",
      "380  \t  421  \t  62\n",
      "Test P:  0.163\n",
      "Test R:  0.147\n",
      "Test F1:  0.155\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  13\n",
      "100%|| 63/63 [00:22<00:00,  2.78it/s]\n",
      "Training loss:  2.0008118852736456\n",
      "Training time:  0:00:22.693756\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.44it/s]\n",
      "Prediction time:  0:00:06.104899\n",
      "334  \t  426  \t  67\n",
      "Dev P:  0.201\n",
      "Dev R:  0.157\n",
      "Dev F1:  0.176\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.719035\n",
      "340  \t  421  \t  60\n",
      "Test P:  0.176\n",
      "Test R:  0.143\n",
      "Test F1:  0.158\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  14\n",
      "100%|| 63/63 [00:22<00:00,  2.82it/s]\n",
      "Training loss:  1.7420501907666524\n",
      "Training time:  0:00:22.341513\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.131695\n",
      "339  \t  426  \t  63\n",
      "Dev P:  0.186\n",
      "Dev R:  0.148\n",
      "Dev F1:  0.165\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.66it/s]\n",
      "Prediction time:  0:00:05.741040\n",
      "338  \t  421  \t  60\n",
      "Test P:  0.178\n",
      "Test R:  0.143\n",
      "Test F1:  0.158\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  15\n",
      "100%|| 63/63 [00:22<00:00,  2.79it/s]\n",
      "Training loss:  1.6555267534558735\n",
      "Training time:  0:00:22.589409\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.44it/s]\n",
      "Prediction time:  0:00:06.113046\n",
      "362  \t  426  \t  69\n",
      "Dev P:  0.191\n",
      "Dev R:  0.162\n",
      "Dev F1:  0.175\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.66it/s]\n",
      "Prediction time:  0:00:05.732124\n",
      "364  \t  421  \t  59\n",
      "Test P:  0.162\n",
      "Test R:  0.14\n",
      "Test F1:  0.15\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  16\n",
      "100%|| 63/63 [00:22<00:00,  2.78it/s]\n",
      "Training loss:  1.6014903291823372\n",
      "Training time:  0:00:22.693499\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.121386\n",
      "350  \t  426  \t  64\n",
      "Dev P:  0.183\n",
      "Dev R:  0.15\n",
      "Dev F1:  0.165\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.66it/s]\n",
      "Prediction time:  0:00:05.735814\n",
      "365  \t  421  \t  66\n",
      "Test P:  0.181\n",
      "Test R:  0.157\n",
      "Test F1:  0.168\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  17\n",
      "100%|| 63/63 [00:22<00:00,  2.83it/s]\n",
      "Training loss:  1.5127546976483057\n",
      "Training time:  0:00:22.286021\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.41it/s]\n",
      "Prediction time:  0:00:06.162867\n",
      "326  \t  426  \t  61\n",
      "Dev P:  0.187\n",
      "Dev R:  0.143\n",
      "Dev F1:  0.162\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.63it/s]\n",
      "Prediction time:  0:00:05.783453\n",
      "331  \t  421  \t  52\n",
      "Test P:  0.157\n",
      "Test R:  0.124\n",
      "Test F1:  0.138\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  18\n",
      "100%|| 63/63 [00:22<00:00,  2.81it/s]\n",
      "Training loss:  1.2939970502777705\n",
      "Training time:  0:00:22.425086\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.44it/s]\n",
      "Prediction time:  0:00:06.099252\n",
      "332  \t  426  \t  64\n",
      "Dev P:  0.193\n",
      "Dev R:  0.15\n",
      "Dev F1:  0.169\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.66it/s]\n",
      "Prediction time:  0:00:05.731329\n",
      "340  \t  421  \t  65\n",
      "Test P:  0.191\n",
      "Test R:  0.154\n",
      "Test F1:  0.171\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  19\n",
      "100%|| 63/63 [00:22<00:00,  2.79it/s]\n",
      "Training loss:  1.2387181482617817\n",
      "Training time:  0:00:22.574147\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.126383\n",
      "340  \t  426  \t  63\n",
      "Dev P:  0.185\n",
      "Dev R:  0.148\n",
      "Dev F1:  0.164\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.66it/s]\n",
      "Prediction time:  0:00:05.741125\n",
      "351  \t  421  \t  67\n",
      "Test P:  0.191\n",
      "Test R:  0.159\n",
      "Test F1:  0.174\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:22<00:00,  2.83it/s]\n",
      "Training loss:  1.121153959679225\n",
      "Training time:  0:00:22.268354\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.42it/s]\n",
      "Prediction time:  0:00:06.148493\n",
      "339  \t  426  \t  70\n",
      "Dev P:  0.206\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.183\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.65it/s]\n",
      "Prediction time:  0:00:05.755937\n",
      "352  \t  421  \t  63\n",
      "Test P:  0.179\n",
      "Test R:  0.15\n",
      "Test F1:  0.163\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  21\n",
      "100%|| 63/63 [00:22<00:00,  2.84it/s]\n",
      "Training loss:  1.0701920257674322\n",
      "Training time:  0:00:22.199755\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.40it/s]\n",
      "Prediction time:  0:00:06.178267\n",
      "367  \t  426  \t  77\n",
      "Dev P:  0.21\n",
      "Dev R:  0.181\n",
      "Dev F1:  0.194\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.63it/s]\n",
      "Prediction time:  0:00:05.784018\n",
      "378  \t  421  \t  67\n",
      "Test P:  0.177\n",
      "Test R:  0.159\n",
      "Test F1:  0.168\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  22\n",
      "100%|| 63/63 [00:22<00:00,  2.81it/s]\n",
      "Training loss:  1.0720537684503055\n",
      "Training time:  0:00:22.447617\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.41it/s]\n",
      "Prediction time:  0:00:06.158103\n",
      "384  \t  426  \t  75\n",
      "Dev P:  0.195\n",
      "Dev R:  0.176\n",
      "Dev F1:  0.185\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.64it/s]\n",
      "Prediction time:  0:00:05.765845\n",
      "393  \t  421  \t  65\n",
      "Test P:  0.165\n",
      "Test R:  0.154\n",
      "Test F1:  0.16\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  23\n",
      "100%|| 63/63 [00:22<00:00,  2.84it/s]\n",
      "Training loss:  0.906164815974614\n",
      "Training time:  0:00:22.214668\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.42it/s]\n",
      "Prediction time:  0:00:06.139996\n",
      "342  \t  426  \t  72\n",
      "Dev P:  0.211\n",
      "Dev R:  0.169\n",
      "Dev F1:  0.187\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.64it/s]\n",
      "Prediction time:  0:00:05.772852\n",
      "351  \t  421  \t  66\n",
      "Test P:  0.188\n",
      "Test R:  0.157\n",
      "Test F1:  0.171\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  24\n",
      "100%|| 63/63 [00:22<00:00,  2.74it/s]\n",
      "Training loss:  0.8205237270347656\n",
      "Training time:  0:00:22.958511\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.42it/s]\n",
      "Prediction time:  0:00:06.136742\n",
      "348  \t  426  \t  69\n",
      "Dev P:  0.198\n",
      "Dev R:  0.162\n",
      "Dev F1:  0.178\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.64it/s]\n",
      "Prediction time:  0:00:05.764410\n",
      "354  \t  421  \t  62\n",
      "Test P:  0.175\n",
      "Test R:  0.147\n",
      "Test F1:  0.16\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  25\n",
      "100%|| 63/63 [00:22<00:00,  2.74it/s]\n",
      "Training loss:  0.9371064470873939\n",
      "Training time:  0:00:22.973229\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.40it/s]\n",
      "Prediction time:  0:00:06.168957\n",
      "357  \t  426  \t  69\n",
      "Dev P:  0.193\n",
      "Dev R:  0.162\n",
      "Dev F1:  0.176\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.63it/s]\n",
      "Prediction time:  0:00:05.784378\n",
      "361  \t  421  \t  71\n",
      "Test P:  0.197\n",
      "Test R:  0.169\n",
      "Test F1:  0.182\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  26\n",
      "100%|| 63/63 [00:22<00:00,  2.76it/s]\n",
      "Training loss:  0.7460643696406531\n",
      "Training time:  0:00:22.836143\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.41it/s]\n",
      "Prediction time:  0:00:06.156364\n",
      "350  \t  426  \t  75\n",
      "Dev P:  0.214\n",
      "Dev R:  0.176\n",
      "Dev F1:  0.193\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.65it/s]\n",
      "Prediction time:  0:00:05.753406\n",
      "357  \t  421  \t  73\n",
      "Test P:  0.204\n",
      "Test R:  0.173\n",
      "Test F1:  0.188\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  27\n",
      "100%|| 63/63 [00:22<00:00,  2.79it/s]\n",
      "Training loss:  0.8975794154500204\n",
      "Training time:  0:00:22.551003\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.40it/s]\n",
      "Prediction time:  0:00:06.172732\n",
      "353  \t  426  \t  75\n",
      "Dev P:  0.212\n",
      "Dev R:  0.176\n",
      "Dev F1:  0.193\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.63it/s]\n",
      "Prediction time:  0:00:05.790064\n",
      "355  \t  421  \t  62\n",
      "Test P:  0.175\n",
      "Test R:  0.147\n",
      "Test F1:  0.16\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  28\n",
      "100%|| 63/63 [00:22<00:00,  2.80it/s]\n",
      "Training loss:  0.8303428441286087\n",
      "Training time:  0:00:22.473929\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.41it/s]\n",
      "Prediction time:  0:00:06.154019\n",
      "344  \t  426  \t  70\n",
      "Dev P:  0.203\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.182\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.64it/s]\n",
      "Prediction time:  0:00:05.772294\n",
      "346  \t  421  \t  61\n",
      "Test P:  0.176\n",
      "Test R:  0.145\n",
      "Test F1:  0.159\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  29\n",
      "100%|| 63/63 [00:22<00:00,  2.83it/s]\n",
      "Training loss:  0.8048212160430257\n",
      "Training time:  0:00:22.259175\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.42it/s]\n",
      "Prediction time:  0:00:06.136694\n",
      "348  \t  426  \t  72\n",
      "Dev P:  0.207\n",
      "Dev R:  0.169\n",
      "Dev F1:  0.186\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.65it/s]\n",
      "Prediction time:  0:00:05.750211\n",
      "359  \t  421  \t  69\n",
      "Test P:  0.192\n",
      "Test R:  0.164\n",
      "Test F1:  0.177\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  30\n",
      "100%|| 63/63 [00:22<00:00,  2.80it/s]\n",
      "Training loss:  0.8278835536468596\n",
      "Training time:  0:00:22.473711\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.126850\n",
      "403  \t  426  \t  76\n",
      "Dev P:  0.189\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.183\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.66it/s]\n",
      "Prediction time:  0:00:05.742817\n",
      "413  \t  421  \t  64\n",
      "Test P:  0.155\n",
      "Test R:  0.152\n",
      "Test F1:  0.153\n",
      "\n",
      "\n",
      "\n",
      "*******\n",
      "Best Epoch:  11\n",
      "Best Epoch Seed:  53\n",
      "Corresponding P:  0.172\n",
      "Corresponding R:  0.145\n",
      "Corresponding F1:  0.157\n",
      "\n",
      "\n",
      "\n",
      "Best Test Epoch:  26\n",
      "Corresponding P:  0.204\n",
      "Corresponding R:  0.173\n",
      "Corresponding F1:  0.188\n",
      "\n",
      "\n",
      "\n",
      "Test size: 322\n",
      "Re-checking the scores of entire Test data with the best saved model:\n",
      "Total sentences in the test set:  322\n",
      "GT Triple Count:  421  \tPRED Triple Count:  354  \tCORRECT Triple Count:  61\n",
      "Test P:  0.172\n",
      "Test R:  0.145\n",
      "Test F1:  0.157\n",
      "Now printing the scores for various subsets of Test Data with the best saved model:\n",
      "Total sentences with single triples:  243\n",
      "GT Triple Count:  243  \tPRED Triple Count:  257  \tCORRECT Triple Count:  39\n",
      "Test P:  0.152\n",
      "Test R:  0.16\n",
      "Test F1:  0.156\n",
      "Total sentences with multiple triples:  79\n",
      "GT Triple Count:  178  \tPRED Triple Count:  97  \tCORRECT Triple Count:  22\n",
      "Test P:  0.227\n",
      "Test R:  0.124\n",
      "Test F1:  0.16\n",
      "Total sentences triples with varying sentiments:  31\n",
      "GT Triple Count:  79  \tPRED Triple Count:  40  \tCORRECT Triple Count:  8\n",
      "Test P:  0.2\n",
      "Test R:  0.101\n",
      "Test F1:  0.134\n",
      "Total sentences with overlapping triples:  42\n",
      "GT Triple Count:  95  \tPRED Triple Count:  48  \tCORRECT Triple Count:  8\n",
      "Test P:  0.167\n",
      "Test R:  0.084\n",
      "Test F1:  0.112\n"
     ]
    }
   ],
   "source": [
    "!python3 PASTE_BERT.py --gpu_id 0 --src_folder mpqa/ --trg_folder mpqa/PASTE_BERT --bert_mode gen --gen_direct af --l2 y --wd 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fd4b075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/shivam/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/shivam/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/shivam/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "enc_hidden_size: 818\n",
      "dec_inp_size: 818\n",
      "dec_hidden_size: 818\n",
      "pointer_net_hidden_size: 300\n",
      "['PASTE_BERT.py', '--gpu_id', '0', '--src_folder', 'mpqa/', '--trg_folder', 'mpqa/PASTE_BERT', '--bert_mode', 'gen', '--gen_direct', 'af', '--l2', 'y', '--wd', '1e-5', '--use_pos_tags', 'y']\n",
      "100  10  0.5\n",
      "BERT\n",
      "loading data......\n",
      "No. of sentences:  996\n",
      "No. of lines in Target file:  996\n",
      "No. of lines in POS file:  996\n",
      "No. of lines in DEP file:  996\n",
      "No. of sentences:  323\n",
      "No. of lines in Target file:  323\n",
      "No. of lines in POS file:  323\n",
      "No. of lines in DEP file:  323\n",
      "No. of sentences:  322\n",
      "No. of lines in Target file:  322\n",
      "No. of lines in POS file:  322\n",
      "No. of lines in DEP file:  322\n",
      "Training data size:  994\n",
      "Development data size:  323\n",
      "Test data size:  322\n",
      "Building POS TAG Vocab..\n",
      "Building DEP TAG Vocab..\n",
      "Training started......\n",
      "Batch Count:   63\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_attentions\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/shivam/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Parameters size:  129772009\n",
      "weight factor:  1\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 1e-05\n",
      ")\n",
      "Epoch:  1\n",
      "  0%|                                                    | 0/63 [00:00<?, ?it/s]/home/shivam/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2251: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|| 63/63 [00:23<00:00,  2.64it/s]\n",
      "Training loss:  9.866302573491657\n",
      "Training time:  0:00:23.852672\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.283400\n",
      "323  \t  426  \t  43\n",
      "Dev P:  0.133\n",
      "Dev R:  0.101\n",
      "Dev F1:  0.115\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.843523\n",
      "323  \t  421  \t  36\n",
      "Test P:  0.111\n",
      "Test R:  0.086\n",
      "Test F1:  0.097\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  2\n",
      "100%|| 63/63 [00:23<00:00,  2.66it/s]\n",
      "Training loss:  7.072116639879015\n",
      "Training time:  0:00:23.702953\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.319107\n",
      "323  \t  426  \t  59\n",
      "Dev P:  0.183\n",
      "Dev R:  0.138\n",
      "Dev F1:  0.158\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.55it/s]\n",
      "Prediction time:  0:00:05.916508\n",
      "322  \t  421  \t  49\n",
      "Test P:  0.152\n",
      "Test R:  0.116\n",
      "Test F1:  0.132\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  3\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  6.319297238001748\n",
      "Training time:  0:00:23.549087\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.271385\n",
      "323  \t  426  \t  64\n",
      "Dev P:  0.198\n",
      "Dev R:  0.15\n",
      "Dev F1:  0.171\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.854787\n",
      "322  \t  421  \t  48\n",
      "Test P:  0.149\n",
      "Test R:  0.114\n",
      "Test F1:  0.129\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  4\n",
      "100%|| 63/63 [00:23<00:00,  2.70it/s]\n",
      "Training loss:  5.764282442274547\n",
      "Training time:  0:00:23.309977\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.31it/s]\n",
      "Prediction time:  0:00:06.337901\n",
      "323  \t  426  \t  70\n",
      "Dev P:  0.217\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.187\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.56it/s]\n",
      "Prediction time:  0:00:05.900527\n",
      "322  \t  421  \t  54\n",
      "Test P:  0.168\n",
      "Test R:  0.128\n",
      "Test F1:  0.145\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  5\n",
      "100%|| 63/63 [00:23<00:00,  2.70it/s]\n",
      "Training loss:  5.136784334031362\n",
      "Training time:  0:00:23.337870\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.31it/s]\n",
      "Prediction time:  0:00:06.340883\n",
      "357  \t  426  \t  71\n",
      "Dev P:  0.199\n",
      "Dev R:  0.167\n",
      "Dev F1:  0.181\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.56it/s]\n",
      "Prediction time:  0:00:05.904346\n",
      "372  \t  421  \t  63\n",
      "Test P:  0.169\n",
      "Test R:  0.15\n",
      "Test F1:  0.159\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  6\n",
      "100%|| 63/63 [00:23<00:00,  2.66it/s]\n",
      "Training loss:  4.565007561729068\n",
      "Training time:  0:00:23.678965\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.308591\n",
      "408  \t  426  \t  80\n",
      "Dev P:  0.196\n",
      "Dev R:  0.188\n",
      "Dev F1:  0.192\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.882458\n",
      "389  \t  421  \t  59\n",
      "Test P:  0.152\n",
      "Test R:  0.14\n",
      "Test F1:  0.146\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  7\n",
      "100%|| 63/63 [00:23<00:00,  2.63it/s]\n",
      "Training loss:  4.214733059444125\n",
      "Training time:  0:00:23.939214\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.309811\n",
      "340  \t  426  \t  74\n",
      "Dev P:  0.218\n",
      "Dev R:  0.174\n",
      "Dev F1:  0.193\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.878792\n",
      "347  \t  421  \t  64\n",
      "Test P:  0.184\n",
      "Test R:  0.152\n",
      "Test F1:  0.167\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  8\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  3.678023618365091\n",
      "Training time:  0:00:23.515670\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.276903\n",
      "346  \t  426  \t  82\n",
      "Dev P:  0.237\n",
      "Dev R:  0.192\n",
      "Dev F1:  0.212\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.838991\n",
      "357  \t  421  \t  70\n",
      "Test P:  0.196\n",
      "Test R:  0.166\n",
      "Test F1:  0.18\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  9\n",
      "100%|| 63/63 [00:23<00:00,  2.69it/s]\n",
      "Training loss:  3.305371876746889\n",
      "Training time:  0:00:23.424241\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.329893\n",
      "353  \t  426  \t  75\n",
      "Dev P:  0.212\n",
      "Dev R:  0.176\n",
      "Dev F1:  0.193\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.888146\n",
      "357  \t  421  \t  53\n",
      "Test P:  0.148\n",
      "Test R:  0.126\n",
      "Test F1:  0.136\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  10\n",
      "100%|| 63/63 [00:23<00:00,  2.66it/s]\n",
      "Training loss:  2.9614011900765553\n",
      "Training time:  0:00:23.689323\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.31it/s]\n",
      "Prediction time:  0:00:06.336868\n",
      "362  \t  426  \t  86\n",
      "Dev P:  0.238\n",
      "Dev R:  0.202\n",
      "Dev F1:  0.218\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.54it/s]\n",
      "Prediction time:  0:00:05.927801\n",
      "357  \t  421  \t  63\n",
      "Test P:  0.176\n",
      "Test R:  0.15\n",
      "Test F1:  0.162\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  11\n",
      "100%|| 63/63 [00:23<00:00,  2.66it/s]\n",
      "Training loss:  2.5543909668922424\n",
      "Training time:  0:00:23.677902\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.31it/s]\n",
      "Prediction time:  0:00:06.343472\n",
      "357  \t  426  \t  75\n",
      "Dev P:  0.21\n",
      "Dev R:  0.176\n",
      "Dev F1:  0.192\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.56it/s]\n",
      "Prediction time:  0:00:05.906505\n",
      "360  \t  421  \t  73\n",
      "Test P:  0.203\n",
      "Test R:  0.173\n",
      "Test F1:  0.187\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  12\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  2.4391413378337075\n",
      "Training time:  0:00:23.581855\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.31it/s]\n",
      "Prediction time:  0:00:06.351942\n",
      "347  \t  426  \t  76\n",
      "Dev P:  0.219\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.197\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.55it/s]\n",
      "Prediction time:  0:00:05.922702\n",
      "351  \t  421  \t  64\n",
      "Test P:  0.182\n",
      "Test R:  0.152\n",
      "Test F1:  0.166\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  13\n",
      "100%|| 63/63 [00:23<00:00,  2.64it/s]\n",
      "Training loss:  2.18617514201573\n",
      "Training time:  0:00:23.878585\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.325520\n",
      "334  \t  426  \t  73\n",
      "Dev P:  0.219\n",
      "Dev R:  0.171\n",
      "Dev F1:  0.192\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.56it/s]\n",
      "Prediction time:  0:00:05.900202\n",
      "341  \t  421  \t  55\n",
      "Test P:  0.161\n",
      "Test R:  0.131\n",
      "Test F1:  0.144\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  14\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  2.0301547901970998\n",
      "Training time:  0:00:23.470381\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.31it/s]\n",
      "Prediction time:  0:00:06.344411\n",
      "333  \t  426  \t  77\n",
      "Dev P:  0.231\n",
      "Dev R:  0.181\n",
      "Dev F1:  0.203\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.56it/s]\n",
      "Prediction time:  0:00:05.903338\n",
      "333  \t  421  \t  61\n",
      "Test P:  0.183\n",
      "Test R:  0.145\n",
      "Test F1:  0.162\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  15\n",
      "100%|| 63/63 [00:23<00:00,  2.65it/s]\n",
      "Training loss:  1.8100290402533517\n",
      "Training time:  0:00:23.818385\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.31it/s]\n",
      "Prediction time:  0:00:06.335351\n",
      "347  \t  426  \t  85\n",
      "Dev P:  0.245\n",
      "Dev R:  0.2\n",
      "Dev F1:  0.22\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.56it/s]\n",
      "Prediction time:  0:00:05.898890\n",
      "351  \t  421  \t  70\n",
      "Test P:  0.199\n",
      "Test R:  0.166\n",
      "Test F1:  0.181\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  16\n",
      "100%|| 63/63 [00:24<00:00,  2.62it/s]\n",
      "Training loss:  1.75206553652173\n",
      "Training time:  0:00:24.079263\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.31it/s]\n",
      "Prediction time:  0:00:06.348806\n",
      "338  \t  426  \t  83\n",
      "Dev P:  0.246\n",
      "Dev R:  0.195\n",
      "Dev F1:  0.217\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.54it/s]\n",
      "Prediction time:  0:00:05.934577\n",
      "348  \t  421  \t  65\n",
      "Test P:  0.187\n",
      "Test R:  0.154\n",
      "Test F1:  0.169\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  17\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  1.580800855916644\n",
      "Training time:  0:00:23.591265\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.328443\n",
      "355  \t  426  \t  90\n",
      "Dev P:  0.254\n",
      "Dev R:  0.211\n",
      "Dev F1:  0.23\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.56it/s]\n",
      "Prediction time:  0:00:05.896153\n",
      "357  \t  421  \t  61\n",
      "Test P:  0.171\n",
      "Test R:  0.145\n",
      "Test F1:  0.157\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  18\n",
      "100%|| 63/63 [00:23<00:00,  2.64it/s]\n",
      "Training loss:  1.4299479732437739\n",
      "Training time:  0:00:23.856428\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.333323\n",
      "378  \t  426  \t  88\n",
      "Dev P:  0.233\n",
      "Dev R:  0.207\n",
      "Dev F1:  0.219\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.56it/s]\n",
      "Prediction time:  0:00:05.905017\n",
      "372  \t  421  \t  65\n",
      "Test P:  0.175\n",
      "Test R:  0.154\n",
      "Test F1:  0.164\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  19\n",
      "100%|| 63/63 [00:23<00:00,  2.63it/s]\n",
      "Training loss:  1.3435971116026242\n",
      "Training time:  0:00:23.964986\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.332459\n",
      "339  \t  426  \t  81\n",
      "Dev P:  0.239\n",
      "Dev R:  0.19\n",
      "Dev F1:  0.212\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.56it/s]\n",
      "Prediction time:  0:00:05.903482\n",
      "345  \t  421  \t  62\n",
      "Test P:  0.18\n",
      "Test R:  0.147\n",
      "Test F1:  0.162\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  1.291679234731765\n",
      "Training time:  0:00:23.552581\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.30it/s]\n",
      "Prediction time:  0:00:06.363501\n",
      "356  \t  426  \t  85\n",
      "Dev P:  0.239\n",
      "Dev R:  0.2\n",
      "Dev F1:  0.217\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.53it/s]\n",
      "Prediction time:  0:00:05.945239\n",
      "363  \t  421  \t  58\n",
      "Test P:  0.16\n",
      "Test R:  0.138\n",
      "Test F1:  0.148\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  21\n",
      "100%|| 63/63 [00:23<00:00,  2.70it/s]\n",
      "Training loss:  1.1999237840137784\n",
      "Training time:  0:00:23.337794\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.325025\n",
      "371  \t  426  \t  85\n",
      "Dev P:  0.229\n",
      "Dev R:  0.2\n",
      "Dev F1:  0.213\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.882745\n",
      "383  \t  421  \t  69\n",
      "Test P:  0.18\n",
      "Test R:  0.164\n",
      "Test F1:  0.172\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  22\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  1.1427752697278584\n",
      "Training time:  0:00:23.528472\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.306447\n",
      "340  \t  426  \t  70\n",
      "Dev P:  0.206\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.183\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.863302\n",
      "340  \t  421  \t  64\n",
      "Test P:  0.188\n",
      "Test R:  0.152\n",
      "Test F1:  0.168\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  23\n",
      "100%|| 63/63 [00:23<00:00,  2.70it/s]\n",
      "Training loss:  1.1178934063230241\n",
      "Training time:  0:00:23.342883\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.286558\n",
      "349  \t  426  \t  80\n",
      "Dev P:  0.229\n",
      "Dev R:  0.188\n",
      "Dev F1:  0.206\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.875931\n",
      "364  \t  421  \t  58\n",
      "Test P:  0.159\n",
      "Test R:  0.138\n",
      "Test F1:  0.148\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  24\n",
      "100%|| 63/63 [00:23<00:00,  2.65it/s]\n",
      "Training loss:  0.9581888005847022\n",
      "Training time:  0:00:23.810924\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.31it/s]\n",
      "Prediction time:  0:00:06.337415\n",
      "363  \t  426  \t  74\n",
      "Dev P:  0.204\n",
      "Dev R:  0.174\n",
      "Dev F1:  0.188\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.56it/s]\n",
      "Prediction time:  0:00:05.900280\n",
      "380  \t  421  \t  63\n",
      "Test P:  0.166\n",
      "Test R:  0.15\n",
      "Test F1:  0.157\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  25\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  1.0053207458011688\n",
      "Training time:  0:00:23.607268\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.333603\n",
      "376  \t  426  \t  86\n",
      "Dev P:  0.229\n",
      "Dev R:  0.202\n",
      "Dev F1:  0.214\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.56it/s]\n",
      "Prediction time:  0:00:05.901208\n",
      "381  \t  421  \t  62\n",
      "Test P:  0.163\n",
      "Test R:  0.147\n",
      "Test F1:  0.155\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  26\n",
      "100%|| 63/63 [00:23<00:00,  2.66it/s]\n",
      "Training loss:  0.8434326222964695\n",
      "Training time:  0:00:23.724429\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.291178\n",
      "346  \t  426  \t  84\n",
      "Dev P:  0.243\n",
      "Dev R:  0.197\n",
      "Dev F1:  0.218\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.847475\n",
      "344  \t  421  \t  62\n",
      "Test P:  0.18\n",
      "Test R:  0.147\n",
      "Test F1:  0.162\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  27\n",
      "100%|| 63/63 [00:23<00:00,  2.63it/s]\n",
      "Training loss:  0.882684441312911\n",
      "Training time:  0:00:23.938548\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.288634\n",
      "338  \t  426  \t  76\n",
      "Dev P:  0.225\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.199\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.850811\n",
      "347  \t  421  \t  58\n",
      "Test P:  0.167\n",
      "Test R:  0.138\n",
      "Test F1:  0.151\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  28\n",
      "100%|| 63/63 [00:23<00:00,  2.65it/s]\n",
      "Training loss:  0.9290102162058391\n",
      "Training time:  0:00:23.737798\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.312450\n",
      "367  \t  426  \t  76\n",
      "Dev P:  0.207\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.192\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.869897\n",
      "369  \t  421  \t  63\n",
      "Test P:  0.171\n",
      "Test R:  0.15\n",
      "Test F1:  0.159\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  29\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  0.8300470447256452\n",
      "Training time:  0:00:23.536686\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.31it/s]\n",
      "Prediction time:  0:00:06.352780\n",
      "363  \t  426  \t  79\n",
      "Dev P:  0.218\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.2\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.56it/s]\n",
      "Prediction time:  0:00:05.895645\n",
      "375  \t  421  \t  58\n",
      "Test P:  0.155\n",
      "Test R:  0.138\n",
      "Test F1:  0.146\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  30\n",
      "100%|| 63/63 [00:23<00:00,  2.66it/s]\n",
      "Training loss:  0.7545228716399934\n",
      "Training time:  0:00:23.729018\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.314440\n",
      "341  \t  426  \t  73\n",
      "Dev P:  0.214\n",
      "Dev R:  0.171\n",
      "Dev F1:  0.19\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.886365\n",
      "345  \t  421  \t  55\n",
      "Test P:  0.159\n",
      "Test R:  0.131\n",
      "Test F1:  0.144\n",
      "\n",
      "\n",
      "\n",
      "*******\n",
      "Best Epoch:  17\n",
      "Best Epoch Seed:  59\n",
      "Corresponding P:  0.171\n",
      "Corresponding R:  0.145\n",
      "Corresponding F1:  0.157\n",
      "\n",
      "\n",
      "\n",
      "Best Test Epoch:  11\n",
      "Corresponding P:  0.203\n",
      "Corresponding R:  0.173\n",
      "Corresponding F1:  0.187\n",
      "\n",
      "\n",
      "\n",
      "Test size: 322\n",
      "Re-checking the scores of entire Test data with the best saved model:\n",
      "Total sentences in the test set:  322\n",
      "GT Triple Count:  421  \tPRED Triple Count:  357  \tCORRECT Triple Count:  61\n",
      "Test P:  0.171\n",
      "Test R:  0.145\n",
      "Test F1:  0.157\n",
      "Now printing the scores for various subsets of Test Data with the best saved model:\n",
      "Total sentences with single triples:  243\n",
      "GT Triple Count:  243  \tPRED Triple Count:  259  \tCORRECT Triple Count:  44\n",
      "Test P:  0.17\n",
      "Test R:  0.181\n",
      "Test F1:  0.175\n",
      "Total sentences with multiple triples:  79\n",
      "GT Triple Count:  178  \tPRED Triple Count:  98  \tCORRECT Triple Count:  17\n",
      "Test P:  0.173\n",
      "Test R:  0.096\n",
      "Test F1:  0.123\n",
      "Total sentences triples with varying sentiments:  31\n",
      "GT Triple Count:  79  \tPRED Triple Count:  38  \tCORRECT Triple Count:  4\n",
      "Test P:  0.105\n",
      "Test R:  0.051\n",
      "Test F1:  0.068\n",
      "Total sentences with overlapping triples:  42\n",
      "GT Triple Count:  95  \tPRED Triple Count:  46  \tCORRECT Triple Count:  5\n",
      "Test P:  0.109\n",
      "Test R:  0.053\n",
      "Test F1:  0.071\n"
     ]
    }
   ],
   "source": [
    "!python3 PASTE_BERT.py --gpu_id 0 --src_folder mpqa/ --trg_folder mpqa/PASTE_BERT --bert_mode gen --gen_direct af --l2 y --wd 1e-5 --use_pos_tags y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1acb459d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/shivam/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/shivam/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/shivam/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "enc_hidden_size: 818\n",
      "dec_inp_size: 818\n",
      "dec_hidden_size: 818\n",
      "pointer_net_hidden_size: 300\n",
      "['PASTE_BERT.py', '--gpu_id', '0', '--src_folder', 'mpqa/', '--trg_folder', 'mpqa/PASTE_BERT', '--bert_mode', 'gen', '--gen_direct', 'af', '--l2', 'y', '--wd', '1e-5', '--use_dep_emb', 'y']\n",
      "100  10  0.5\n",
      "BERT\n",
      "loading data......\n",
      "No. of sentences:  996\n",
      "No. of lines in Target file:  996\n",
      "No. of lines in POS file:  996\n",
      "No. of lines in DEP file:  996\n",
      "No. of sentences:  323\n",
      "No. of lines in Target file:  323\n",
      "No. of lines in POS file:  323\n",
      "No. of lines in DEP file:  323\n",
      "No. of sentences:  322\n",
      "No. of lines in Target file:  322\n",
      "No. of lines in POS file:  322\n",
      "No. of lines in DEP file:  322\n",
      "Training data size:  994\n",
      "Development data size:  323\n",
      "Test data size:  322\n",
      "Building POS TAG Vocab..\n",
      "Building DEP TAG Vocab..\n",
      "Training started......\n",
      "Batch Count:   63\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_attentions\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/shivam/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Parameters size:  129771609\n",
      "weight factor:  1\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 1e-05\n",
      ")\n",
      "Epoch:  1\n",
      "  0%|                                                    | 0/63 [00:00<?, ?it/s]/home/shivam/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2251: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  9.915301731654576\n",
      "Training time:  0:00:23.492436\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.266794\n",
      "330  \t  426  \t  48\n",
      "Dev P:  0.145\n",
      "Dev R:  0.113\n",
      "Dev F1:  0.127\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.837243\n",
      "326  \t  421  \t  42\n",
      "Test P:  0.129\n",
      "Test R:  0.1\n",
      "Test F1:  0.112\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  2\n",
      "100%|| 63/63 [00:23<00:00,  2.65it/s]\n",
      "Training loss:  7.1290800836351185\n",
      "Training time:  0:00:23.759710\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.300671\n",
      "323  \t  426  \t  61\n",
      "Dev P:  0.189\n",
      "Dev R:  0.143\n",
      "Dev F1:  0.163\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.56it/s]\n",
      "Prediction time:  0:00:05.900517\n",
      "322  \t  421  \t  48\n",
      "Test P:  0.149\n",
      "Test R:  0.114\n",
      "Test F1:  0.129\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  3\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  6.340829046945723\n",
      "Training time:  0:00:23.603864\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.297226\n",
      "323  \t  426  \t  62\n",
      "Dev P:  0.192\n",
      "Dev R:  0.146\n",
      "Dev F1:  0.166\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.869386\n",
      "322  \t  421  \t  54\n",
      "Test P:  0.168\n",
      "Test R:  0.128\n",
      "Test F1:  0.145\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  4\n",
      "100%|| 63/63 [00:23<00:00,  2.71it/s]\n",
      "Training loss:  5.7266664580693325\n",
      "Training time:  0:00:23.221270\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.293131\n",
      "327  \t  426  \t  72\n",
      "Dev P:  0.22\n",
      "Dev R:  0.169\n",
      "Dev F1:  0.191\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.857471\n",
      "324  \t  421  \t  51\n",
      "Test P:  0.157\n",
      "Test R:  0.121\n",
      "Test F1:  0.137\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  5\n",
      "100%|| 63/63 [00:23<00:00,  2.69it/s]\n",
      "Training loss:  5.156519272970775\n",
      "Training time:  0:00:23.400230\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.301353\n",
      "391  \t  426  \t  69\n",
      "Dev P:  0.176\n",
      "Dev R:  0.162\n",
      "Dev F1:  0.169\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.873848\n",
      "390  \t  421  \t  69\n",
      "Test P:  0.177\n",
      "Test R:  0.164\n",
      "Test F1:  0.17\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  6\n",
      "100%|| 63/63 [00:23<00:00,  2.65it/s]\n",
      "Training loss:  4.638708773113432\n",
      "Training time:  0:00:23.788418\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.314256\n",
      "387  \t  426  \t  77\n",
      "Dev P:  0.199\n",
      "Dev R:  0.181\n",
      "Dev F1:  0.189\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.870914\n",
      "390  \t  421  \t  67\n",
      "Test P:  0.172\n",
      "Test R:  0.159\n",
      "Test F1:  0.165\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  7\n",
      "100%|| 63/63 [00:23<00:00,  2.64it/s]\n",
      "Training loss:  4.295515120975555\n",
      "Training time:  0:00:23.860903\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.316618\n",
      "329  \t  426  \t  70\n",
      "Dev P:  0.213\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.185\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.887369\n",
      "329  \t  421  \t  64\n",
      "Test P:  0.195\n",
      "Test R:  0.152\n",
      "Test F1:  0.171\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  8\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  3.703297319866362\n",
      "Training time:  0:00:23.629841\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.31it/s]\n",
      "Prediction time:  0:00:06.339429\n",
      "335  \t  426  \t  76\n",
      "Dev P:  0.227\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.2\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.56it/s]\n",
      "Prediction time:  0:00:05.902901\n",
      "339  \t  421  \t  68\n",
      "Test P:  0.201\n",
      "Test R:  0.162\n",
      "Test F1:  0.179\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  9\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  3.123131373571971\n",
      "Training time:  0:00:23.600310\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.314235\n",
      "335  \t  426  \t  69\n",
      "Dev P:  0.206\n",
      "Dev R:  0.162\n",
      "Dev F1:  0.181\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.873554\n",
      "337  \t  421  \t  68\n",
      "Test P:  0.202\n",
      "Test R:  0.162\n",
      "Test F1:  0.179\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  10\n",
      "100%|| 63/63 [00:23<00:00,  2.64it/s]\n",
      "Training loss:  2.893119847963727\n",
      "Training time:  0:00:23.819021\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.320933\n",
      "385  \t  426  \t  81\n",
      "Dev P:  0.21\n",
      "Dev R:  0.19\n",
      "Dev F1:  0.2\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.56it/s]\n",
      "Prediction time:  0:00:05.891345\n",
      "380  \t  421  \t  68\n",
      "Test P:  0.179\n",
      "Test R:  0.162\n",
      "Test F1:  0.17\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  11\n",
      "100%|| 63/63 [00:23<00:00,  2.66it/s]\n",
      "Training loss:  2.610441947267169\n",
      "Training time:  0:00:23.676437\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.322497\n",
      "366  \t  426  \t  81\n",
      "Dev P:  0.221\n",
      "Dev R:  0.19\n",
      "Dev F1:  0.205\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.879250\n",
      "371  \t  421  \t  72\n",
      "Test P:  0.194\n",
      "Test R:  0.171\n",
      "Test F1:  0.182\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  12\n",
      "100%|| 63/63 [00:23<00:00,  2.69it/s]\n",
      "Training loss:  2.290916024692475\n",
      "Training time:  0:00:23.453744\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.315279\n",
      "335  \t  426  \t  69\n",
      "Dev P:  0.206\n",
      "Dev R:  0.162\n",
      "Dev F1:  0.181\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.868038\n",
      "344  \t  421  \t  58\n",
      "Test P:  0.169\n",
      "Test R:  0.138\n",
      "Test F1:  0.152\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  13\n",
      "100%|| 63/63 [00:23<00:00,  2.64it/s]\n",
      "Training loss:  2.2123547470758833\n",
      "Training time:  0:00:23.883781\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.326973\n",
      "370  \t  426  \t  81\n",
      "Dev P:  0.219\n",
      "Dev R:  0.19\n",
      "Dev F1:  0.204\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.885879\n",
      "391  \t  421  \t  65\n",
      "Test P:  0.166\n",
      "Test R:  0.154\n",
      "Test F1:  0.16\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  14\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  1.9368162656587267\n",
      "Training time:  0:00:23.545417\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.303429\n",
      "338  \t  426  \t  80\n",
      "Dev P:  0.237\n",
      "Dev R:  0.188\n",
      "Dev F1:  0.209\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.859598\n",
      "337  \t  421  \t  60\n",
      "Test P:  0.178\n",
      "Test R:  0.143\n",
      "Test F1:  0.158\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  15\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  1.744461004696195\n",
      "Training time:  0:00:23.602835\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.330329\n",
      "357  \t  426  \t  77\n",
      "Dev P:  0.216\n",
      "Dev R:  0.181\n",
      "Dev F1:  0.197\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.879388\n",
      "364  \t  421  \t  70\n",
      "Test P:  0.192\n",
      "Test R:  0.166\n",
      "Test F1:  0.178\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  16\n",
      "100%|| 63/63 [00:23<00:00,  2.63it/s]\n",
      "Training loss:  1.6218205926910279\n",
      "Training time:  0:00:23.947042\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.30it/s]\n",
      "Prediction time:  0:00:06.370955\n",
      "353  \t  426  \t  69\n",
      "Dev P:  0.195\n",
      "Dev R:  0.162\n",
      "Dev F1:  0.177\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.55it/s]\n",
      "Prediction time:  0:00:05.914467\n",
      "364  \t  421  \t  71\n",
      "Test P:  0.195\n",
      "Test R:  0.169\n",
      "Test F1:  0.181\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  17\n",
      "100%|| 63/63 [00:23<00:00,  2.69it/s]\n",
      "Training loss:  1.4986463491878812\n",
      "Training time:  0:00:23.410668\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.291883\n",
      "368  \t  426  \t  71\n",
      "Dev P:  0.193\n",
      "Dev R:  0.167\n",
      "Dev F1:  0.179\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.859436\n",
      "375  \t  421  \t  71\n",
      "Test P:  0.189\n",
      "Test R:  0.169\n",
      "Test F1:  0.178\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  18\n",
      "100%|| 63/63 [00:23<00:00,  2.64it/s]\n",
      "Training loss:  1.521619681328062\n",
      "Training time:  0:00:23.846631\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.303639\n",
      "357  \t  426  \t  77\n",
      "Dev P:  0.216\n",
      "Dev R:  0.181\n",
      "Dev F1:  0.197\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.876175\n",
      "364  \t  421  \t  64\n",
      "Test P:  0.176\n",
      "Test R:  0.152\n",
      "Test F1:  0.163\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  19\n",
      "100%|| 63/63 [00:23<00:00,  2.64it/s]\n",
      "Training loss:  1.3430263061845114\n",
      "Training time:  0:00:23.868004\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.314716\n",
      "378  \t  426  \t  77\n",
      "Dev P:  0.204\n",
      "Dev R:  0.181\n",
      "Dev F1:  0.192\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.887533\n",
      "383  \t  421  \t  72\n",
      "Test P:  0.188\n",
      "Test R:  0.171\n",
      "Test F1:  0.179\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  1.1604093422019293\n",
      "Training time:  0:00:23.619199\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.286476\n",
      "372  \t  426  \t  84\n",
      "Dev P:  0.226\n",
      "Dev R:  0.197\n",
      "Dev F1:  0.211\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.878088\n",
      "376  \t  421  \t  65\n",
      "Test P:  0.173\n",
      "Test R:  0.154\n",
      "Test F1:  0.163\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  21\n",
      "100%|| 63/63 [00:23<00:00,  2.69it/s]\n",
      "Training loss:  1.141196658686986\n",
      "Training time:  0:00:23.433533\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.294231\n",
      "354  \t  426  \t  80\n",
      "Dev P:  0.226\n",
      "Dev R:  0.188\n",
      "Dev F1:  0.205\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.850322\n",
      "358  \t  421  \t  73\n",
      "Test P:  0.204\n",
      "Test R:  0.173\n",
      "Test F1:  0.187\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  22\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  1.043017221821679\n",
      "Training time:  0:00:23.497047\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.316224\n",
      "337  \t  426  \t  75\n",
      "Dev P:  0.223\n",
      "Dev R:  0.176\n",
      "Dev F1:  0.197\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.876773\n",
      "340  \t  421  \t  60\n",
      "Test P:  0.176\n",
      "Test R:  0.143\n",
      "Test F1:  0.158\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  23\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  1.0209640983551267\n",
      "Training time:  0:00:23.508691\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.285083\n",
      "349  \t  426  \t  78\n",
      "Dev P:  0.223\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.201\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.847138\n",
      "357  \t  421  \t  68\n",
      "Test P:  0.19\n",
      "Test R:  0.162\n",
      "Test F1:  0.175\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  24\n",
      "100%|| 63/63 [00:23<00:00,  2.64it/s]\n",
      "Training loss:  0.9971271275527893\n",
      "Training time:  0:00:23.869916\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.330112\n",
      "349  \t  426  \t  80\n",
      "Dev P:  0.229\n",
      "Dev R:  0.188\n",
      "Dev F1:  0.206\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.56it/s]\n",
      "Prediction time:  0:00:05.904656\n",
      "355  \t  421  \t  65\n",
      "Test P:  0.183\n",
      "Test R:  0.154\n",
      "Test F1:  0.168\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  25\n",
      "100%|| 63/63 [00:23<00:00,  2.66it/s]\n",
      "Training loss:  0.9818286545692928\n",
      "Training time:  0:00:23.668682\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.297319\n",
      "339  \t  426  \t  67\n",
      "Dev P:  0.198\n",
      "Dev R:  0.157\n",
      "Dev F1:  0.175\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.846179\n",
      "347  \t  421  \t  70\n",
      "Test P:  0.202\n",
      "Test R:  0.166\n",
      "Test F1:  0.182\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  26\n",
      "100%|| 63/63 [00:23<00:00,  2.65it/s]\n",
      "Training loss:  0.9172102681228093\n",
      "Training time:  0:00:23.769866\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.309108\n",
      "385  \t  426  \t  84\n",
      "Dev P:  0.218\n",
      "Dev R:  0.197\n",
      "Dev F1:  0.207\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.862853\n",
      "400  \t  421  \t  69\n",
      "Test P:  0.172\n",
      "Test R:  0.164\n",
      "Test F1:  0.168\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  27\n",
      "100%|| 63/63 [00:23<00:00,  2.63it/s]\n",
      "Training loss:  0.8541885931340475\n",
      "Training time:  0:00:23.985388\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.327861\n",
      "359  \t  426  \t  79\n",
      "Dev P:  0.22\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.201\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.56it/s]\n",
      "Prediction time:  0:00:05.895390\n",
      "360  \t  421  \t  70\n",
      "Test P:  0.194\n",
      "Test R:  0.166\n",
      "Test F1:  0.179\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  28\n",
      "100%|| 63/63 [00:23<00:00,  2.66it/s]\n",
      "Training loss:  0.8482416395157103\n",
      "Training time:  0:00:23.723571\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.30it/s]\n",
      "Prediction time:  0:00:06.363824\n",
      "375  \t  426  \t  76\n",
      "Dev P:  0.203\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.19\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.55it/s]\n",
      "Prediction time:  0:00:05.921190\n",
      "380  \t  421  \t  68\n",
      "Test P:  0.179\n",
      "Test R:  0.162\n",
      "Test F1:  0.17\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  29\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  0.7407869628024479\n",
      "Training time:  0:00:23.628029\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.331553\n",
      "356  \t  426  \t  71\n",
      "Dev P:  0.199\n",
      "Dev R:  0.167\n",
      "Dev F1:  0.182\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.56it/s]\n",
      "Prediction time:  0:00:05.898788\n",
      "375  \t  421  \t  69\n",
      "Test P:  0.184\n",
      "Test R:  0.164\n",
      "Test F1:  0.173\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  30\n",
      "100%|| 63/63 [00:23<00:00,  2.65it/s]\n",
      "Training loss:  0.7974679985689739\n",
      "Training time:  0:00:23.765409\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.289995\n",
      "352  \t  426  \t  80\n",
      "Dev P:  0.227\n",
      "Dev R:  0.188\n",
      "Dev F1:  0.206\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.844825\n",
      "357  \t  421  \t  68\n",
      "Test P:  0.19\n",
      "Test R:  0.162\n",
      "Test F1:  0.175\n",
      "\n",
      "\n",
      "\n",
      "*******\n",
      "Best Epoch:  20\n",
      "Best Epoch Seed:  62\n",
      "Corresponding P:  0.173\n",
      "Corresponding R:  0.154\n",
      "Corresponding F1:  0.163\n",
      "\n",
      "\n",
      "\n",
      "Best Test Epoch:  21\n",
      "Corresponding P:  0.204\n",
      "Corresponding R:  0.173\n",
      "Corresponding F1:  0.187\n",
      "\n",
      "\n",
      "\n",
      "Test size: 322\n",
      "Re-checking the scores of entire Test data with the best saved model:\n",
      "Total sentences in the test set:  322\n",
      "GT Triple Count:  421  \tPRED Triple Count:  376  \tCORRECT Triple Count:  65\n",
      "Test P:  0.173\n",
      "Test R:  0.154\n",
      "Test F1:  0.163\n",
      "Now printing the scores for various subsets of Test Data with the best saved model:\n",
      "Total sentences with single triples:  243\n",
      "GT Triple Count:  243  \tPRED Triple Count:  265  \tCORRECT Triple Count:  44\n",
      "Test P:  0.166\n",
      "Test R:  0.181\n",
      "Test F1:  0.173\n",
      "Total sentences with multiple triples:  79\n",
      "GT Triple Count:  178  \tPRED Triple Count:  111  \tCORRECT Triple Count:  21\n",
      "Test P:  0.189\n",
      "Test R:  0.118\n",
      "Test F1:  0.145\n",
      "Total sentences triples with varying sentiments:  31\n",
      "GT Triple Count:  79  \tPRED Triple Count:  42  \tCORRECT Triple Count:  7\n",
      "Test P:  0.167\n",
      "Test R:  0.089\n",
      "Test F1:  0.116\n",
      "Total sentences with overlapping triples:  42\n",
      "GT Triple Count:  95  \tPRED Triple Count:  55  \tCORRECT Triple Count:  8\n",
      "Test P:  0.145\n",
      "Test R:  0.084\n",
      "Test F1:  0.107\n"
     ]
    }
   ],
   "source": [
    "!python3 PASTE_BERT.py --gpu_id 0 --src_folder mpqa/ --trg_folder mpqa/PASTE_BERT --bert_mode gen --gen_direct af --l2 y --wd 1e-5 --use_dep_emb y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e75c6a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/shivam/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/shivam/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/shivam/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "enc_hidden_size: 868\n",
      "dec_inp_size: 868\n",
      "dec_hidden_size: 868\n",
      "pointer_net_hidden_size: 300\n",
      "['PASTE_BERT.py', '--gpu_id', '0', '--src_folder', 'mpqa/', '--trg_folder', 'mpqa/PASTE_BERT', '--bert_mode', 'gen', '--gen_direct', 'af', '--l2', 'y', '--wd', '1e-5', '--use_pos_tags', 'y', '--use_dep_emb', 'y']\n",
      "100  10  0.5\n",
      "BERT\n",
      "loading data......\n",
      "No. of sentences:  996\n",
      "No. of lines in Target file:  996\n",
      "No. of lines in POS file:  996\n",
      "No. of lines in DEP file:  996\n",
      "No. of sentences:  323\n",
      "No. of lines in Target file:  323\n",
      "No. of lines in POS file:  323\n",
      "No. of lines in DEP file:  323\n",
      "No. of sentences:  322\n",
      "No. of lines in Target file:  322\n",
      "No. of lines in POS file:  322\n",
      "No. of lines in DEP file:  322\n",
      "Training data size:  994\n",
      "Development data size:  323\n",
      "Test data size:  322\n",
      "Building POS TAG Vocab..\n",
      "Building DEP TAG Vocab..\n",
      "Training started......\n",
      "Batch Count:   63\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_attentions\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/shivam/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Parameters size:  131663959\n",
      "weight factor:  1\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 1e-05\n",
      ")\n",
      "Epoch:  1\n",
      "  0%|                                                    | 0/63 [00:00<?, ?it/s]/home/shivam/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2251: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|| 63/63 [00:24<00:00,  2.59it/s]\n",
      "Training loss:  9.820820566207644\n",
      "Training time:  0:00:24.351288\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.432346\n",
      "323  \t  426  \t  48\n",
      "Dev P:  0.149\n",
      "Dev R:  0.113\n",
      "Dev F1:  0.128\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.52it/s]\n",
      "Prediction time:  0:00:05.961798\n",
      "322  \t  421  \t  37\n",
      "Test P:  0.115\n",
      "Test R:  0.088\n",
      "Test F1:  0.1\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  2\n",
      "100%|| 63/63 [00:24<00:00,  2.59it/s]\n",
      "Training loss:  7.103938178410606\n",
      "Training time:  0:00:24.291934\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.27it/s]\n",
      "Prediction time:  0:00:06.423333\n",
      "323  \t  426  \t  61\n",
      "Dev P:  0.189\n",
      "Dev R:  0.143\n",
      "Dev F1:  0.163\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.52it/s]\n",
      "Prediction time:  0:00:05.973150\n",
      "322  \t  421  \t  49\n",
      "Test P:  0.152\n",
      "Test R:  0.116\n",
      "Test F1:  0.132\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  3\n",
      "100%|| 63/63 [00:24<00:00,  2.61it/s]\n",
      "Training loss:  6.35773369622609\n",
      "Training time:  0:00:24.147088\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.441389\n",
      "323  \t  426  \t  60\n",
      "Dev P:  0.186\n",
      "Dev R:  0.141\n",
      "Dev F1:  0.16\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:05.993466\n",
      "322  \t  421  \t  48\n",
      "Test P:  0.149\n",
      "Test R:  0.114\n",
      "Test F1:  0.129\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  4\n",
      "100%|| 63/63 [00:23<00:00,  2.63it/s]\n",
      "Training loss:  5.741573591080923\n",
      "Training time:  0:00:23.986215\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.27it/s]\n",
      "Prediction time:  0:00:06.413726\n",
      "324  \t  426  \t  71\n",
      "Dev P:  0.219\n",
      "Dev R:  0.167\n",
      "Dev F1:  0.189\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.51it/s]\n",
      "Prediction time:  0:00:05.987389\n",
      "324  \t  421  \t  56\n",
      "Test P:  0.173\n",
      "Test R:  0.133\n",
      "Test F1:  0.15\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  5\n",
      "100%|| 63/63 [00:24<00:00,  2.61it/s]\n",
      "Training loss:  5.181676126661754\n",
      "Training time:  0:00:24.150651\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.29it/s]\n",
      "Prediction time:  0:00:06.390707\n",
      "355  \t  426  \t  70\n",
      "Dev P:  0.197\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.179\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.53it/s]\n",
      "Prediction time:  0:00:05.957081\n",
      "364  \t  421  \t  64\n",
      "Test P:  0.176\n",
      "Test R:  0.152\n",
      "Test F1:  0.163\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  6\n",
      "100%|| 63/63 [00:24<00:00,  2.58it/s]\n",
      "Training loss:  4.667383315071227\n",
      "Training time:  0:00:24.379230\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.448748\n",
      "343  \t  426  \t  76\n",
      "Dev P:  0.222\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.198\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:06.007226\n",
      "345  \t  421  \t  66\n",
      "Test P:  0.191\n",
      "Test R:  0.157\n",
      "Test F1:  0.172\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  7\n",
      "100%|| 63/63 [00:24<00:00,  2.57it/s]\n",
      "Training loss:  4.369352874301729\n",
      "Training time:  0:00:24.538289\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.446609\n",
      "357  \t  426  \t  84\n",
      "Dev P:  0.235\n",
      "Dev R:  0.197\n",
      "Dev F1:  0.215\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:05.998620\n",
      "376  \t  421  \t  62\n",
      "Test P:  0.165\n",
      "Test R:  0.147\n",
      "Test F1:  0.156\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  8\n",
      "100%|| 63/63 [00:24<00:00,  2.61it/s]\n",
      "Training loss:  3.856764554977417\n",
      "Training time:  0:00:24.155446\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.27it/s]\n",
      "Prediction time:  0:00:06.431539\n",
      "333  \t  426  \t  75\n",
      "Dev P:  0.225\n",
      "Dev R:  0.176\n",
      "Dev F1:  0.198\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:05.995936\n",
      "335  \t  421  \t  58\n",
      "Test P:  0.173\n",
      "Test R:  0.138\n",
      "Test F1:  0.153\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  9\n",
      "100%|| 63/63 [00:24<00:00,  2.60it/s]\n",
      "Training loss:  3.3483946247706338\n",
      "Training time:  0:00:24.215334\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.27it/s]\n",
      "Prediction time:  0:00:06.425405\n",
      "323  \t  426  \t  64\n",
      "Dev P:  0.198\n",
      "Dev R:  0.15\n",
      "Dev F1:  0.171\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.51it/s]\n",
      "Prediction time:  0:00:05.989538\n",
      "330  \t  421  \t  68\n",
      "Test P:  0.206\n",
      "Test R:  0.162\n",
      "Test F1:  0.181\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  10\n",
      "100%|| 63/63 [00:24<00:00,  2.59it/s]\n",
      "Training loss:  3.047307156381153\n",
      "Training time:  0:00:24.316995\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.27it/s]\n",
      "Prediction time:  0:00:06.427502\n",
      "366  \t  426  \t  87\n",
      "Dev P:  0.238\n",
      "Dev R:  0.204\n",
      "Dev F1:  0.22\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.51it/s]\n",
      "Prediction time:  0:00:05.987544\n",
      "374  \t  421  \t  69\n",
      "Test P:  0.184\n",
      "Test R:  0.164\n",
      "Test F1:  0.174\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  11\n",
      "100%|| 63/63 [00:24<00:00,  2.61it/s]\n",
      "Training loss:  2.8444905408791135\n",
      "Training time:  0:00:24.162737\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.27it/s]\n",
      "Prediction time:  0:00:06.425124\n",
      "381  \t  426  \t  79\n",
      "Dev P:  0.207\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.196\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:05.996855\n",
      "387  \t  421  \t  67\n",
      "Test P:  0.173\n",
      "Test R:  0.159\n",
      "Test F1:  0.166\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  12\n",
      "100%|| 63/63 [00:24<00:00,  2.62it/s]\n",
      "Training loss:  2.496394384474981\n",
      "Training time:  0:00:24.006611\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.27it/s]\n",
      "Prediction time:  0:00:06.423868\n",
      "336  \t  426  \t  75\n",
      "Dev P:  0.223\n",
      "Dev R:  0.176\n",
      "Dev F1:  0.197\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:05.998815\n",
      "342  \t  421  \t  66\n",
      "Test P:  0.193\n",
      "Test R:  0.157\n",
      "Test F1:  0.173\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  13\n",
      "100%|| 63/63 [00:24<00:00,  2.53it/s]\n",
      "Training loss:  2.3950846251987277\n",
      "Training time:  0:00:24.878316\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.27it/s]\n",
      "Prediction time:  0:00:06.432171\n",
      "334  \t  426  \t  75\n",
      "Dev P:  0.225\n",
      "Dev R:  0.176\n",
      "Dev F1:  0.197\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.51it/s]\n",
      "Prediction time:  0:00:05.990293\n",
      "341  \t  421  \t  60\n",
      "Test P:  0.176\n",
      "Test R:  0.143\n",
      "Test F1:  0.157\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  14\n",
      "100%|| 63/63 [00:24<00:00,  2.60it/s]\n",
      "Training loss:  2.061742483623444\n",
      "Training time:  0:00:24.251243\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.25it/s]\n",
      "Prediction time:  0:00:06.457157\n",
      "329  \t  426  \t  81\n",
      "Dev P:  0.246\n",
      "Dev R:  0.19\n",
      "Dev F1:  0.215\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.49it/s]\n",
      "Prediction time:  0:00:06.013596\n",
      "336  \t  421  \t  64\n",
      "Test P:  0.19\n",
      "Test R:  0.152\n",
      "Test F1:  0.169\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  15\n",
      "100%|| 63/63 [00:24<00:00,  2.59it/s]\n",
      "Training loss:  1.9723186578069414\n",
      "Training time:  0:00:24.357833\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.432943\n",
      "354  \t  426  \t  81\n",
      "Dev P:  0.229\n",
      "Dev R:  0.19\n",
      "Dev F1:  0.208\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:05.992066\n",
      "362  \t  421  \t  59\n",
      "Test P:  0.163\n",
      "Test R:  0.14\n",
      "Test F1:  0.151\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  16\n",
      "100%|| 63/63 [00:24<00:00,  2.57it/s]\n",
      "Training loss:  1.7394970579752846\n",
      "Training time:  0:00:24.537561\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.27it/s]\n",
      "Prediction time:  0:00:06.428452\n",
      "359  \t  426  \t  76\n",
      "Dev P:  0.212\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.194\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:05.996508\n",
      "373  \t  421  \t  68\n",
      "Test P:  0.182\n",
      "Test R:  0.162\n",
      "Test F1:  0.171\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  17\n",
      "100%|| 63/63 [00:24<00:00,  2.60it/s]\n",
      "Training loss:  1.682527400198437\n",
      "Training time:  0:00:24.223471\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.25it/s]\n",
      "Prediction time:  0:00:06.466213\n",
      "339  \t  426  \t  78\n",
      "Dev P:  0.23\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.204\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.49it/s]\n",
      "Prediction time:  0:00:06.020187\n",
      "344  \t  421  \t  64\n",
      "Test P:  0.186\n",
      "Test R:  0.152\n",
      "Test F1:  0.167\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  18\n",
      "100%|| 63/63 [00:24<00:00,  2.59it/s]\n",
      "Training loss:  1.5833170063911923\n",
      "Training time:  0:00:24.306920\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.433719\n",
      "352  \t  426  \t  72\n",
      "Dev P:  0.205\n",
      "Dev R:  0.169\n",
      "Dev F1:  0.185\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:06.001450\n",
      "363  \t  421  \t  65\n",
      "Test P:  0.179\n",
      "Test R:  0.154\n",
      "Test F1:  0.166\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  19\n",
      "100%|| 63/63 [00:24<00:00,  2.58it/s]\n",
      "Training loss:  1.4649425044892326\n",
      "Training time:  0:00:24.462493\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.451073\n",
      "356  \t  426  \t  81\n",
      "Dev P:  0.228\n",
      "Dev R:  0.19\n",
      "Dev F1:  0.207\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.49it/s]\n",
      "Prediction time:  0:00:06.015379\n",
      "364  \t  421  \t  61\n",
      "Test P:  0.168\n",
      "Test R:  0.145\n",
      "Test F1:  0.155\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:24<00:00,  2.62it/s]\n",
      "Training loss:  1.3117490969006977\n",
      "Training time:  0:00:24.064775\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.437096\n",
      "361  \t  426  \t  78\n",
      "Dev P:  0.216\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.198\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:05.997478\n",
      "375  \t  421  \t  71\n",
      "Test P:  0.189\n",
      "Test R:  0.169\n",
      "Test F1:  0.178\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  21\n",
      "100%|| 63/63 [00:24<00:00,  2.62it/s]\n",
      "Training loss:  1.2241604829591417\n",
      "Training time:  0:00:24.061902\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.28it/s]\n",
      "Prediction time:  0:00:06.408931\n",
      "418  \t  426  \t  79\n",
      "Dev P:  0.189\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.187\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.52it/s]\n",
      "Prediction time:  0:00:05.968509\n",
      "433  \t  421  \t  72\n",
      "Test P:  0.166\n",
      "Test R:  0.171\n",
      "Test F1:  0.169\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  22\n",
      "100%|| 63/63 [00:24<00:00,  2.60it/s]\n",
      "Training loss:  1.149522927072313\n",
      "Training time:  0:00:24.271804\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.25it/s]\n",
      "Prediction time:  0:00:06.452619\n",
      "358  \t  426  \t  87\n",
      "Dev P:  0.243\n",
      "Dev R:  0.204\n",
      "Dev F1:  0.222\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:06.004249\n",
      "366  \t  421  \t  64\n",
      "Test P:  0.175\n",
      "Test R:  0.152\n",
      "Test F1:  0.163\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  23\n",
      "100%|| 63/63 [00:24<00:00,  2.59it/s]\n",
      "Training loss:  1.0955777352764493\n",
      "Training time:  0:00:24.361189\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.24it/s]\n",
      "Prediction time:  0:00:06.474107\n",
      "384  \t  426  \t  85\n",
      "Dev P:  0.221\n",
      "Dev R:  0.2\n",
      "Dev F1:  0.21\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.48it/s]\n",
      "Prediction time:  0:00:06.039715\n",
      "409  \t  421  \t  66\n",
      "Test P:  0.161\n",
      "Test R:  0.157\n",
      "Test F1:  0.159\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  24\n",
      "100%|| 63/63 [00:24<00:00,  2.56it/s]\n",
      "Training loss:  1.0823640217856756\n",
      "Training time:  0:00:24.593337\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.445855\n",
      "355  \t  426  \t  74\n",
      "Dev P:  0.208\n",
      "Dev R:  0.174\n",
      "Dev F1:  0.19\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.48it/s]\n",
      "Prediction time:  0:00:06.028738\n",
      "363  \t  421  \t  60\n",
      "Test P:  0.165\n",
      "Test R:  0.143\n",
      "Test F1:  0.153\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  25\n",
      "100%|| 63/63 [00:24<00:00,  2.56it/s]\n",
      "Training loss:  1.0186350591598996\n",
      "Training time:  0:00:24.615929\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.27it/s]\n",
      "Prediction time:  0:00:06.424547\n",
      "355  \t  426  \t  81\n",
      "Dev P:  0.228\n",
      "Dev R:  0.19\n",
      "Dev F1:  0.207\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:05.992991\n",
      "372  \t  421  \t  67\n",
      "Test P:  0.18\n",
      "Test R:  0.159\n",
      "Test F1:  0.169\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  26\n",
      "100%|| 63/63 [00:24<00:00,  2.58it/s]\n",
      "Training loss:  0.9054664884294782\n",
      "Training time:  0:00:24.385867\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.27it/s]\n",
      "Prediction time:  0:00:06.420890\n",
      "338  \t  426  \t  73\n",
      "Dev P:  0.216\n",
      "Dev R:  0.171\n",
      "Dev F1:  0.191\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.51it/s]\n",
      "Prediction time:  0:00:05.983172\n",
      "351  \t  421  \t  60\n",
      "Test P:  0.171\n",
      "Test R:  0.143\n",
      "Test F1:  0.155\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  27\n",
      "100%|| 63/63 [00:24<00:00,  2.53it/s]\n",
      "Training loss:  0.9103729694135605\n",
      "Training time:  0:00:24.948716\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.25it/s]\n",
      "Prediction time:  0:00:06.469918\n",
      "359  \t  426  \t  81\n",
      "Dev P:  0.226\n",
      "Dev R:  0.19\n",
      "Dev F1:  0.206\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.49it/s]\n",
      "Prediction time:  0:00:06.014044\n",
      "374  \t  421  \t  61\n",
      "Test P:  0.163\n",
      "Test R:  0.145\n",
      "Test F1:  0.153\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  28\n",
      "100%|| 63/63 [00:24<00:00,  2.58it/s]\n",
      "Training loss:  0.8825733335245223\n",
      "Training time:  0:00:24.442622\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.24it/s]\n",
      "Prediction time:  0:00:06.487572\n",
      "353  \t  426  \t  71\n",
      "Dev P:  0.201\n",
      "Dev R:  0.167\n",
      "Dev F1:  0.182\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:06.005438\n",
      "366  \t  421  \t  58\n",
      "Test P:  0.158\n",
      "Test R:  0.138\n",
      "Test F1:  0.147\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  29\n",
      "100%|| 63/63 [00:24<00:00,  2.60it/s]\n",
      "Training loss:  0.8950242059571403\n",
      "Training time:  0:00:24.255408\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.25it/s]\n",
      "Prediction time:  0:00:06.460331\n",
      "337  \t  426  \t  79\n",
      "Dev P:  0.234\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.207\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:06.001978\n",
      "348  \t  421  \t  67\n",
      "Test P:  0.193\n",
      "Test R:  0.159\n",
      "Test F1:  0.174\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  30\n",
      "100%|| 63/63 [00:24<00:00,  2.57it/s]\n",
      "Training loss:  0.8743401969236041\n",
      "Training time:  0:00:24.510502\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.432284\n",
      "367  \t  426  \t  84\n",
      "Dev P:  0.229\n",
      "Dev R:  0.197\n",
      "Dev F1:  0.212\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:06.001702\n",
      "378  \t  421  \t  66\n",
      "Test P:  0.175\n",
      "Test R:  0.157\n",
      "Test F1:  0.165\n",
      "\n",
      "\n",
      "\n",
      "*******\n",
      "Best Epoch:  22\n",
      "Best Epoch Seed:  64\n",
      "Corresponding P:  0.175\n",
      "Corresponding R:  0.152\n",
      "Corresponding F1:  0.163\n",
      "\n",
      "\n",
      "\n",
      "Best Test Epoch:  9\n",
      "Corresponding P:  0.206\n",
      "Corresponding R:  0.162\n",
      "Corresponding F1:  0.181\n",
      "\n",
      "\n",
      "\n",
      "Test size: 322\n",
      "Re-checking the scores of entire Test data with the best saved model:\n",
      "Total sentences in the test set:  322\n",
      "GT Triple Count:  421  \tPRED Triple Count:  366  \tCORRECT Triple Count:  64\n",
      "Test P:  0.175\n",
      "Test R:  0.152\n",
      "Test F1:  0.163\n",
      "Now printing the scores for various subsets of Test Data with the best saved model:\n",
      "Total sentences with single triples:  243\n",
      "GT Triple Count:  243  \tPRED Triple Count:  264  \tCORRECT Triple Count:  41\n",
      "Test P:  0.155\n",
      "Test R:  0.169\n",
      "Test F1:  0.162\n",
      "Total sentences with multiple triples:  79\n",
      "GT Triple Count:  178  \tPRED Triple Count:  102  \tCORRECT Triple Count:  23\n",
      "Test P:  0.225\n",
      "Test R:  0.129\n",
      "Test F1:  0.164\n",
      "Total sentences triples with varying sentiments:  31\n",
      "GT Triple Count:  79  \tPRED Triple Count:  42  \tCORRECT Triple Count:  8\n",
      "Test P:  0.19\n",
      "Test R:  0.101\n",
      "Test F1:  0.132\n",
      "Total sentences with overlapping triples:  42\n",
      "GT Triple Count:  95  \tPRED Triple Count:  50  \tCORRECT Triple Count:  8\n",
      "Test P:  0.16\n",
      "Test R:  0.084\n",
      "Test F1:  0.11\n"
     ]
    }
   ],
   "source": [
    "!python3 PASTE_BERT.py --gpu_id 0 --src_folder mpqa/ --trg_folder mpqa/PASTE_BERT --bert_mode gen --gen_direct af --l2 y --wd 1e-5 --use_pos_tags y --use_dep_emb y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239ff613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0161ff7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/shivam/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/shivam/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/shivam/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "enc_hidden_size: 768\n",
      "dec_inp_size: 768\n",
      "dec_hidden_size: 768\n",
      "pointer_net_hidden_size: 300\n",
      "['PASTE_BERT.py', '--gpu_id', '0', '--src_folder', 'mpqa/', '--trg_folder', 'mpqa/PASTE_BERT', '--bert_mode', 'gen', '--gen_direct', 'of', '--l2', 'y']\n",
      "100  10  0.5\n",
      "BERT\n",
      "loading data......\n",
      "No. of sentences:  996\n",
      "No. of lines in Target file:  996\n",
      "No. of lines in POS file:  996\n",
      "No. of lines in DEP file:  996\n",
      "No. of sentences:  323\n",
      "No. of lines in Target file:  323\n",
      "No. of lines in POS file:  323\n",
      "No. of lines in DEP file:  323\n",
      "No. of sentences:  322\n",
      "No. of lines in Target file:  322\n",
      "No. of lines in POS file:  322\n",
      "No. of lines in DEP file:  322\n",
      "Training data size:  994\n",
      "Development data size:  323\n",
      "Test data size:  322\n",
      "Building POS TAG Vocab..\n",
      "Building DEP TAG Vocab..\n",
      "Training started......\n",
      "Batch Count:   63\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_attentions\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/shivam/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Parameters size:  127959659\n",
      "weight factor:  1\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "Epoch:  1\n",
      "  0%|                                                    | 0/63 [00:00<?, ?it/s]/home/shivam/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2251: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  9.826152173299638\n",
      "Training time:  0:00:23.586831\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.49it/s]\n",
      "Prediction time:  0:00:06.023322\n",
      "323  \t  426  \t  50\n",
      "Dev P:  0.155\n",
      "Dev R:  0.117\n",
      "Dev F1:  0.134\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.71it/s]\n",
      "Prediction time:  0:00:05.657779\n",
      "322  \t  421  \t  36\n",
      "Test P:  0.112\n",
      "Test R:  0.086\n",
      "Test F1:  0.097\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  2\n",
      "100%|| 63/63 [00:22<00:00,  2.84it/s]\n",
      "Training loss:  7.082873541211325\n",
      "Training time:  0:00:22.214889\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.47it/s]\n",
      "Prediction time:  0:00:06.047788\n",
      "323  \t  426  \t  63\n",
      "Dev P:  0.195\n",
      "Dev R:  0.148\n",
      "Dev F1:  0.168\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.71it/s]\n",
      "Prediction time:  0:00:05.661811\n",
      "322  \t  421  \t  48\n",
      "Test P:  0.149\n",
      "Test R:  0.114\n",
      "Test F1:  0.129\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  3\n",
      "100%|| 63/63 [00:22<00:00,  2.84it/s]\n",
      "Training loss:  6.333271787280128\n",
      "Training time:  0:00:22.217772\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.46it/s]\n",
      "Prediction time:  0:00:06.069118\n",
      "323  \t  426  \t  60\n",
      "Dev P:  0.186\n",
      "Dev R:  0.141\n",
      "Dev F1:  0.16\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.69it/s]\n",
      "Prediction time:  0:00:05.694112\n",
      "322  \t  421  \t  44\n",
      "Test P:  0.137\n",
      "Test R:  0.105\n",
      "Test F1:  0.118\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  4\n",
      "100%|| 63/63 [00:22<00:00,  2.86it/s]\n",
      "Training loss:  5.664405512431311\n",
      "Training time:  0:00:22.049078\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.116961\n",
      "326  \t  426  \t  65\n",
      "Dev P:  0.199\n",
      "Dev R:  0.153\n",
      "Dev F1:  0.173\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.722006\n",
      "323  \t  421  \t  57\n",
      "Test P:  0.176\n",
      "Test R:  0.135\n",
      "Test F1:  0.153\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  5\n",
      "100%|| 63/63 [00:21<00:00,  2.88it/s]\n",
      "Training loss:  5.027279017463563\n",
      "Training time:  0:00:21.884724\n",
      "\n",
      "Dev Results\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:06<00:00,  3.46it/s]\n",
      "Prediction time:  0:00:06.077863\n",
      "386  \t  426  \t  70\n",
      "Dev P:  0.181\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.172\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.68it/s]\n",
      "Prediction time:  0:00:05.705337\n",
      "386  \t  421  \t  63\n",
      "Test P:  0.163\n",
      "Test R:  0.15\n",
      "Test F1:  0.156\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  6\n",
      "100%|| 63/63 [00:22<00:00,  2.85it/s]\n",
      "Training loss:  4.503093363746764\n",
      "Training time:  0:00:22.123469\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.46it/s]\n",
      "Prediction time:  0:00:06.069119\n",
      "385  \t  426  \t  70\n",
      "Dev P:  0.182\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.173\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.69it/s]\n",
      "Prediction time:  0:00:05.695993\n",
      "388  \t  421  \t  64\n",
      "Test P:  0.165\n",
      "Test R:  0.152\n",
      "Test F1:  0.158\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  7\n",
      "100%|| 63/63 [00:22<00:00,  2.82it/s]\n",
      "Training loss:  4.081463590500847\n",
      "Training time:  0:00:22.341888\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.45it/s]\n",
      "Prediction time:  0:00:06.094889\n",
      "337  \t  426  \t  65\n",
      "Dev P:  0.193\n",
      "Dev R:  0.153\n",
      "Dev F1:  0.17\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.69it/s]\n",
      "Prediction time:  0:00:05.696304\n",
      "331  \t  421  \t  52\n",
      "Test P:  0.157\n",
      "Test R:  0.124\n",
      "Test F1:  0.138\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  8\n",
      "100%|| 63/63 [00:22<00:00,  2.84it/s]\n",
      "Training loss:  3.4063034019772966\n",
      "Training time:  0:00:22.199696\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.45it/s]\n",
      "Prediction time:  0:00:06.088888\n",
      "341  \t  426  \t  74\n",
      "Dev P:  0.217\n",
      "Dev R:  0.174\n",
      "Dev F1:  0.193\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.69it/s]\n",
      "Prediction time:  0:00:05.697602\n",
      "336  \t  421  \t  62\n",
      "Test P:  0.185\n",
      "Test R:  0.147\n",
      "Test F1:  0.164\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  9\n",
      "100%|| 63/63 [00:21<00:00,  2.87it/s]\n",
      "Training loss:  2.981738009150066\n",
      "Training time:  0:00:21.984426\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.47it/s]\n",
      "Prediction time:  0:00:06.059320\n",
      "334  \t  426  \t  61\n",
      "Dev P:  0.183\n",
      "Dev R:  0.143\n",
      "Dev F1:  0.161\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.70it/s]\n",
      "Prediction time:  0:00:05.678290\n",
      "334  \t  421  \t  61\n",
      "Test P:  0.183\n",
      "Test R:  0.145\n",
      "Test F1:  0.162\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  10\n",
      "100%|| 63/63 [00:22<00:00,  2.83it/s]\n",
      "Training loss:  2.7415632709624274\n",
      "Training time:  0:00:22.284697\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.46it/s]\n",
      "Prediction time:  0:00:06.077669\n",
      "366  \t  426  \t  68\n",
      "Dev P:  0.186\n",
      "Dev R:  0.16\n",
      "Dev F1:  0.172\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.68it/s]\n",
      "Prediction time:  0:00:05.714697\n",
      "367  \t  421  \t  68\n",
      "Test P:  0.185\n",
      "Test R:  0.162\n",
      "Test F1:  0.173\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  11\n",
      "100%|| 63/63 [00:22<00:00,  2.84it/s]\n",
      "Training loss:  2.418891938905867\n",
      "Training time:  0:00:22.219535\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.45it/s]\n",
      "Prediction time:  0:00:06.090564\n",
      "373  \t  426  \t  70\n",
      "Dev P:  0.188\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.175\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.68it/s]\n",
      "Prediction time:  0:00:05.706268\n",
      "379  \t  421  \t  72\n",
      "Test P:  0.19\n",
      "Test R:  0.171\n",
      "Test F1:  0.18\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  12\n",
      "100%|| 63/63 [00:22<00:00,  2.84it/s]\n",
      "Training loss:  2.1711661304746355\n",
      "Training time:  0:00:22.176590\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.44it/s]\n",
      "Prediction time:  0:00:06.103169\n",
      "345  \t  426  \t  70\n",
      "Dev P:  0.203\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.182\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.719972\n",
      "346  \t  421  \t  66\n",
      "Test P:  0.191\n",
      "Test R:  0.157\n",
      "Test F1:  0.172\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  13\n",
      "100%|| 63/63 [00:22<00:00,  2.79it/s]\n",
      "Training loss:  1.9927137144028195\n",
      "Training time:  0:00:22.576639\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.123903\n",
      "333  \t  426  \t  67\n",
      "Dev P:  0.201\n",
      "Dev R:  0.157\n",
      "Dev F1:  0.177\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.66it/s]\n",
      "Prediction time:  0:00:05.743884\n",
      "348  \t  421  \t  64\n",
      "Test P:  0.184\n",
      "Test R:  0.152\n",
      "Test F1:  0.166\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  14\n",
      "100%|| 63/63 [00:22<00:00,  2.85it/s]\n",
      "Training loss:  1.8312890359333582\n",
      "Training time:  0:00:22.120461\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.45it/s]\n",
      "Prediction time:  0:00:06.092336\n",
      "369  \t  426  \t  70\n",
      "Dev P:  0.19\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.176\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.68it/s]\n",
      "Prediction time:  0:00:05.714781\n",
      "380  \t  421  \t  65\n",
      "Test P:  0.171\n",
      "Test R:  0.154\n",
      "Test F1:  0.162\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  15\n",
      "100%|| 63/63 [00:22<00:00,  2.81it/s]\n",
      "Training loss:  1.5769130440931471\n",
      "Training time:  0:00:22.451368\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.45it/s]\n",
      "Prediction time:  0:00:06.084773\n",
      "343  \t  426  \t  61\n",
      "Dev P:  0.178\n",
      "Dev R:  0.143\n",
      "Dev F1:  0.159\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.70it/s]\n",
      "Prediction time:  0:00:05.683244\n",
      "358  \t  421  \t  70\n",
      "Test P:  0.196\n",
      "Test R:  0.166\n",
      "Test F1:  0.18\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  16\n",
      "100%|| 63/63 [00:22<00:00,  2.80it/s]\n",
      "Training loss:  1.5875211660824124\n",
      "Training time:  0:00:22.489714\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.45it/s]\n",
      "Prediction time:  0:00:06.092160\n",
      "390  \t  426  \t  74\n",
      "Dev P:  0.19\n",
      "Dev R:  0.174\n",
      "Dev F1:  0.181\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.69it/s]\n",
      "Prediction time:  0:00:05.697431\n",
      "385  \t  421  \t  69\n",
      "Test P:  0.179\n",
      "Test R:  0.164\n",
      "Test F1:  0.171\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  17\n",
      "100%|| 63/63 [00:22<00:00,  2.85it/s]\n",
      "Training loss:  1.4658766057756212\n",
      "Training time:  0:00:22.071779\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.44it/s]\n",
      "Prediction time:  0:00:06.099835\n",
      "333  \t  426  \t  69\n",
      "Dev P:  0.207\n",
      "Dev R:  0.162\n",
      "Dev F1:  0.182\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.68it/s]\n",
      "Prediction time:  0:00:05.714309\n",
      "334  \t  421  \t  60\n",
      "Test P:  0.18\n",
      "Test R:  0.143\n",
      "Test F1:  0.159\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  18\n",
      "100%|| 63/63 [00:22<00:00,  2.81it/s]\n",
      "Training loss:  1.2107017399772766\n",
      "Training time:  0:00:22.405480\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.114255\n",
      "370  \t  426  \t  73\n",
      "Dev P:  0.197\n",
      "Dev R:  0.171\n",
      "Dev F1:  0.183\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.727694\n",
      "378  \t  421  \t  68\n",
      "Test P:  0.18\n",
      "Test R:  0.162\n",
      "Test F1:  0.17\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  19\n",
      "100%|| 63/63 [00:22<00:00,  2.79it/s]\n",
      "Training loss:  1.1475828531242551\n",
      "Training time:  0:00:22.602921\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.118480\n",
      "356  \t  426  \t  71\n",
      "Dev P:  0.199\n",
      "Dev R:  0.167\n",
      "Dev F1:  0.182\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.717425\n",
      "362  \t  421  \t  64\n",
      "Test P:  0.177\n",
      "Test R:  0.152\n",
      "Test F1:  0.163\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  20\n",
      "100%|| 63/63 [00:22<00:00,  2.83it/s]\n",
      "Training loss:  1.088713404678163\n",
      "Training time:  0:00:22.232205\n",
      "\n",
      "Dev Results\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [00:06<00:00,  3.45it/s]\n",
      "Prediction time:  0:00:06.080459\n",
      "332  \t  426  \t  71\n",
      "Dev P:  0.214\n",
      "Dev R:  0.167\n",
      "Dev F1:  0.187\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.68it/s]\n",
      "Prediction time:  0:00:05.713002\n",
      "337  \t  421  \t  58\n",
      "Test P:  0.172\n",
      "Test R:  0.138\n",
      "Test F1:  0.153\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  21\n",
      "100%|| 63/63 [00:22<00:00,  2.86it/s]\n",
      "Training loss:  1.166069755005458\n",
      "Training time:  0:00:22.024538\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.44it/s]\n",
      "Prediction time:  0:00:06.101241\n",
      "356  \t  426  \t  75\n",
      "Dev P:  0.211\n",
      "Dev R:  0.176\n",
      "Dev F1:  0.192\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.720883\n",
      "364  \t  421  \t  61\n",
      "Test P:  0.168\n",
      "Test R:  0.145\n",
      "Test F1:  0.155\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  22\n",
      "100%|| 63/63 [00:22<00:00,  2.83it/s]\n",
      "Training loss:  1.0237212155073407\n",
      "Training time:  0:00:22.261466\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.121993\n",
      "338  \t  426  \t  70\n",
      "Dev P:  0.207\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.183\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.724261\n",
      "348  \t  421  \t  69\n",
      "Test P:  0.198\n",
      "Test R:  0.164\n",
      "Test F1:  0.179\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  23\n",
      "100%|| 63/63 [00:22<00:00,  2.86it/s]\n",
      "Training loss:  0.9772117762338548\n",
      "Training time:  0:00:22.018243\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.44it/s]\n",
      "Prediction time:  0:00:06.103230\n",
      "352  \t  426  \t  77\n",
      "Dev P:  0.219\n",
      "Dev R:  0.181\n",
      "Dev F1:  0.198\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.722919\n",
      "359  \t  421  \t  61\n",
      "Test P:  0.17\n",
      "Test R:  0.145\n",
      "Test F1:  0.156\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  24\n",
      "100%|| 63/63 [00:22<00:00,  2.80it/s]\n",
      "Training loss:  0.9759674360827794\n",
      "Training time:  0:00:22.497661\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.44it/s]\n",
      "Prediction time:  0:00:06.097059\n",
      "346  \t  426  \t  69\n",
      "Dev P:  0.199\n",
      "Dev R:  0.162\n",
      "Dev F1:  0.179\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.68it/s]\n",
      "Prediction time:  0:00:05.702659\n",
      "356  \t  421  \t  66\n",
      "Test P:  0.185\n",
      "Test R:  0.157\n",
      "Test F1:  0.17\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  25\n",
      "100%|| 63/63 [00:22<00:00,  2.83it/s]\n",
      "Training loss:  0.9065075351132287\n",
      "Training time:  0:00:22.261076\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.123010\n",
      "393  \t  426  \t  73\n",
      "Dev P:  0.186\n",
      "Dev R:  0.171\n",
      "Dev F1:  0.178\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.727655\n",
      "394  \t  421  \t  72\n",
      "Test P:  0.183\n",
      "Test R:  0.171\n",
      "Test F1:  0.177\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  26\n",
      "100%|| 63/63 [00:22<00:00,  2.80it/s]\n",
      "Training loss:  0.8796631266909932\n",
      "Training time:  0:00:22.498903\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.121893\n",
      "349  \t  426  \t  68\n",
      "Dev P:  0.195\n",
      "Dev R:  0.16\n",
      "Dev F1:  0.175\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.726079\n",
      "360  \t  421  \t  63\n",
      "Test P:  0.175\n",
      "Test R:  0.15\n",
      "Test F1:  0.161\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  27\n",
      "100%|| 63/63 [00:22<00:00,  2.79it/s]\n",
      "Training loss:  0.880273251306443\n",
      "Training time:  0:00:22.592694\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.40it/s]\n",
      "Prediction time:  0:00:06.174737\n",
      "350  \t  426  \t  70\n",
      "Dev P:  0.2\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.18\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.64it/s]\n",
      "Prediction time:  0:00:05.764482\n",
      "351  \t  421  \t  68\n",
      "Test P:  0.194\n",
      "Test R:  0.162\n",
      "Test F1:  0.176\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  28\n",
      "100%|| 63/63 [00:22<00:00,  2.82it/s]\n",
      "Training loss:  0.8244251270615865\n",
      "Training time:  0:00:22.321650\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.44it/s]\n",
      "Prediction time:  0:00:06.102241\n",
      "338  \t  426  \t  73\n",
      "Dev P:  0.216\n",
      "Dev R:  0.171\n",
      "Dev F1:  0.191\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.721377\n",
      "345  \t  421  \t  67\n",
      "Test P:  0.194\n",
      "Test R:  0.159\n",
      "Test F1:  0.175\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  29\n",
      "100%|| 63/63 [00:22<00:00,  2.84it/s]\n",
      "Training loss:  0.7047088657106672\n",
      "Training time:  0:00:22.172822\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.44it/s]\n",
      "Prediction time:  0:00:06.106491\n",
      "397  \t  426  \t  78\n",
      "Dev P:  0.196\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.19\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.727109\n",
      "425  \t  421  \t  71\n",
      "Test P:  0.167\n",
      "Test R:  0.169\n",
      "Test F1:  0.168\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  30\n",
      "100%|| 63/63 [00:22<00:00,  2.84it/s]\n",
      "Training loss:  0.8104248680765667\n",
      "Training time:  0:00:22.190237\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.123677\n",
      "381  \t  426  \t  77\n",
      "Dev P:  0.202\n",
      "Dev R:  0.181\n",
      "Dev F1:  0.191\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.68it/s]\n",
      "Prediction time:  0:00:05.712374\n",
      "391  \t  421  \t  70\n",
      "Test P:  0.179\n",
      "Test R:  0.166\n",
      "Test F1:  0.172\n",
      "\n",
      "\n",
      "\n",
      "*******\n",
      "Best Epoch:  23\n",
      "Best Epoch Seed:  65\n",
      "Corresponding P:  0.17\n",
      "Corresponding R:  0.145\n",
      "Corresponding F1:  0.156\n",
      "\n",
      "\n",
      "\n",
      "Best Test Epoch:  11\n",
      "Corresponding P:  0.19\n",
      "Corresponding R:  0.171\n",
      "Corresponding F1:  0.18\n",
      "\n",
      "\n",
      "\n",
      "Test size: 322\n",
      "Re-checking the scores of entire Test data with the best saved model:\n",
      "Total sentences in the test set:  322\n",
      "GT Triple Count:  421  \tPRED Triple Count:  359  \tCORRECT Triple Count:  61\n",
      "Test P:  0.17\n",
      "Test R:  0.145\n",
      "Test F1:  0.156\n",
      "Now printing the scores for various subsets of Test Data with the best saved model:\n",
      "Total sentences with single triples:  243\n",
      "GT Triple Count:  243  \tPRED Triple Count:  260  \tCORRECT Triple Count:  40\n",
      "Test P:  0.154\n",
      "Test R:  0.165\n",
      "Test F1:  0.159\n",
      "Total sentences with multiple triples:  79\n",
      "GT Triple Count:  178  \tPRED Triple Count:  99  \tCORRECT Triple Count:  21\n",
      "Test P:  0.212\n",
      "Test R:  0.118\n",
      "Test F1:  0.152\n",
      "Total sentences triples with varying sentiments:  31\n",
      "GT Triple Count:  79  \tPRED Triple Count:  38  \tCORRECT Triple Count:  8\n",
      "Test P:  0.211\n",
      "Test R:  0.101\n",
      "Test F1:  0.137\n",
      "Total sentences with overlapping triples:  42\n",
      "GT Triple Count:  95  \tPRED Triple Count:  48  \tCORRECT Triple Count:  6\n",
      "Test P:  0.125\n",
      "Test R:  0.063\n",
      "Test F1:  0.084\n"
     ]
    }
   ],
   "source": [
    "!python3 PASTE_BERT.py --gpu_id 0 --src_folder mpqa/ --trg_folder mpqa/PASTE_BERT --bert_mode gen --gen_direct of --l2 y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c3c38bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/shivam/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/shivam/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/shivam/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "enc_hidden_size: 818\n",
      "dec_inp_size: 818\n",
      "dec_hidden_size: 818\n",
      "pointer_net_hidden_size: 300\n",
      "['PASTE_BERT.py', '--gpu_id', '0', '--src_folder', 'mpqa/', '--trg_folder', 'mpqa/PASTE_BERT', '--bert_mode', 'gen', '--gen_direct', 'of', '--l2', 'y', '--use_pos_tags', 'y']\n",
      "100  10  0.5\n",
      "BERT\n",
      "loading data......\n",
      "No. of sentences:  996\n",
      "No. of lines in Target file:  996\n",
      "No. of lines in POS file:  996\n",
      "No. of lines in DEP file:  996\n",
      "No. of sentences:  323\n",
      "No. of lines in Target file:  323\n",
      "No. of lines in POS file:  323\n",
      "No. of lines in DEP file:  323\n",
      "No. of sentences:  322\n",
      "No. of lines in Target file:  322\n",
      "No. of lines in POS file:  322\n",
      "No. of lines in DEP file:  322\n",
      "Training data size:  994\n",
      "Development data size:  323\n",
      "Test data size:  322\n",
      "Building POS TAG Vocab..\n",
      "Building DEP TAG Vocab..\n",
      "Training started......\n",
      "Batch Count:   63\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_attentions\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/shivam/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Parameters size:  129772009\n",
      "weight factor:  1\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "Epoch:  1\n",
      "  0%|                                                    | 0/63 [00:00<?, ?it/s]/home/shivam/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2251: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|| 63/63 [00:23<00:00,  2.65it/s]\n",
      "Training loss:  9.826460126846555\n",
      "Training time:  0:00:23.758333\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.271695\n",
      "323  \t  426  \t  49\n",
      "Dev P:  0.152\n",
      "Dev R:  0.115\n",
      "Dev F1:  0.131\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.861508\n",
      "322  \t  421  \t  41\n",
      "Test P:  0.127\n",
      "Test R:  0.097\n",
      "Test F1:  0.11\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  2\n",
      "100%|| 63/63 [00:23<00:00,  2.66it/s]\n",
      "Training loss:  7.092136890169174\n",
      "Training time:  0:00:23.712727\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.307939\n",
      "323  \t  426  \t  61\n",
      "Dev P:  0.189\n",
      "Dev R:  0.143\n",
      "Dev F1:  0.163\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.56it/s]\n",
      "Prediction time:  0:00:05.893342\n",
      "322  \t  421  \t  51\n",
      "Test P:  0.158\n",
      "Test R:  0.121\n",
      "Test F1:  0.137\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  3\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  6.319648954603407\n",
      "Training time:  0:00:23.537719\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.316908\n",
      "323  \t  426  \t  59\n",
      "Dev P:  0.183\n",
      "Dev R:  0.138\n",
      "Dev F1:  0.158\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.56it/s]\n",
      "Prediction time:  0:00:05.905545\n",
      "322  \t  421  \t  50\n",
      "Test P:  0.155\n",
      "Test R:  0.119\n",
      "Test F1:  0.135\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  4\n",
      "100%|| 63/63 [00:23<00:00,  2.72it/s]\n",
      "Training loss:  5.702154719640339\n",
      "Training time:  0:00:23.153929\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.294352\n",
      "326  \t  426  \t  70\n",
      "Dev P:  0.215\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.186\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.865433\n",
      "322  \t  421  \t  52\n",
      "Test P:  0.161\n",
      "Test R:  0.124\n",
      "Test F1:  0.14\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:23<00:00,  2.71it/s]\n",
      "Training loss:  5.1869831842089456\n",
      "Training time:  0:00:23.260754\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.293520\n",
      "380  \t  426  \t  77\n",
      "Dev P:  0.203\n",
      "Dev R:  0.181\n",
      "Dev F1:  0.191\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.879051\n",
      "380  \t  421  \t  61\n",
      "Test P:  0.161\n",
      "Test R:  0.145\n",
      "Test F1:  0.152\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  6\n",
      "100%|| 63/63 [00:23<00:00,  2.69it/s]\n",
      "Training loss:  4.520787530475193\n",
      "Training time:  0:00:23.415698\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.310952\n",
      "412  \t  426  \t  86\n",
      "Dev P:  0.209\n",
      "Dev R:  0.202\n",
      "Dev F1:  0.205\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.889095\n",
      "396  \t  421  \t  71\n",
      "Test P:  0.179\n",
      "Test R:  0.169\n",
      "Test F1:  0.174\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  7\n",
      "100%|| 63/63 [00:23<00:00,  2.66it/s]\n",
      "Training loss:  4.164715634451972\n",
      "Training time:  0:00:23.689122\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.293495\n",
      "388  \t  426  \t  83\n",
      "Dev P:  0.214\n",
      "Dev R:  0.195\n",
      "Dev F1:  0.204\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.854361\n",
      "379  \t  421  \t  71\n",
      "Test P:  0.187\n",
      "Test R:  0.169\n",
      "Test F1:  0.177\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  8\n",
      "100%|| 63/63 [00:23<00:00,  2.70it/s]\n",
      "Training loss:  3.6009158463705155\n",
      "Training time:  0:00:23.349189\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.284026\n",
      "332  \t  426  \t  83\n",
      "Dev P:  0.25\n",
      "Dev R:  0.195\n",
      "Dev F1:  0.219\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.885483\n",
      "325  \t  421  \t  61\n",
      "Test P:  0.188\n",
      "Test R:  0.145\n",
      "Test F1:  0.164\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  9\n",
      "100%|| 63/63 [00:23<00:00,  2.69it/s]\n",
      "Training loss:  3.364230880661616\n",
      "Training time:  0:00:23.395729\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.245718\n",
      "334  \t  426  \t  77\n",
      "Dev P:  0.231\n",
      "Dev R:  0.181\n",
      "Dev F1:  0.203\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.841384\n",
      "337  \t  421  \t  61\n",
      "Test P:  0.181\n",
      "Test R:  0.145\n",
      "Test F1:  0.161\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  10\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  2.8282988885092357\n",
      "Training time:  0:00:23.578407\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.296071\n",
      "355  \t  426  \t  78\n",
      "Dev P:  0.22\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.2\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.884872\n",
      "355  \t  421  \t  65\n",
      "Test P:  0.183\n",
      "Test R:  0.154\n",
      "Test F1:  0.168\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  11\n",
      "100%|| 63/63 [00:23<00:00,  2.69it/s]\n",
      "Training loss:  2.52339700290135\n",
      "Training time:  0:00:23.453107\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.289904\n",
      "407  \t  426  \t  86\n",
      "Dev P:  0.211\n",
      "Dev R:  0.202\n",
      "Dev F1:  0.206\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.890027\n",
      "412  \t  421  \t  71\n",
      "Test P:  0.172\n",
      "Test R:  0.169\n",
      "Test F1:  0.17\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  12\n",
      "100%|| 63/63 [00:23<00:00,  2.70it/s]\n",
      "Training loss:  2.4177439420942277\n",
      "Training time:  0:00:23.346513\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.299016\n",
      "339  \t  426  \t  73\n",
      "Dev P:  0.215\n",
      "Dev R:  0.171\n",
      "Dev F1:  0.191\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.880265\n",
      "337  \t  421  \t  65\n",
      "Test P:  0.193\n",
      "Test R:  0.154\n",
      "Test F1:  0.172\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  13\n",
      "100%|| 63/63 [00:24<00:00,  2.61it/s]\n",
      "Training loss:  2.214895553059048\n",
      "Training time:  0:00:24.111379\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.329612\n",
      "350  \t  426  \t  79\n",
      "Dev P:  0.226\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.204\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.55it/s]\n",
      "Prediction time:  0:00:05.917277\n",
      "354  \t  421  \t  62\n",
      "Test P:  0.175\n",
      "Test R:  0.147\n",
      "Test F1:  0.16\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  14\n",
      "100%|| 63/63 [00:24<00:00,  2.62it/s]\n",
      "Training loss:  2.0823639801570346\n",
      "Training time:  0:00:24.019477\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.285895\n",
      "338  \t  426  \t  77\n",
      "Dev P:  0.228\n",
      "Dev R:  0.181\n",
      "Dev F1:  0.202\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.888503\n",
      "340  \t  421  \t  60\n",
      "Test P:  0.176\n",
      "Test R:  0.143\n",
      "Test F1:  0.158\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  15\n",
      "100%|| 63/63 [00:24<00:00,  2.60it/s]\n",
      "Training loss:  1.7921432237776498\n",
      "Training time:  0:00:24.190161\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.326340\n",
      "373  \t  426  \t  74\n",
      "Dev P:  0.198\n",
      "Dev R:  0.174\n",
      "Dev F1:  0.185\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.56it/s]\n",
      "Prediction time:  0:00:05.897960\n",
      "370  \t  421  \t  69\n",
      "Test P:  0.186\n",
      "Test R:  0.164\n",
      "Test F1:  0.174\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  16\n",
      "100%|| 63/63 [00:23<00:00,  2.63it/s]\n",
      "Training loss:  1.693760565349034\n",
      "Training time:  0:00:23.973387\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.31it/s]\n",
      "Prediction time:  0:00:06.337254\n",
      "353  \t  426  \t  79\n",
      "Dev P:  0.224\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.203\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.55it/s]\n",
      "Prediction time:  0:00:05.907925\n",
      "356  \t  421  \t  68\n",
      "Test P:  0.191\n",
      "Test R:  0.162\n",
      "Test F1:  0.175\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  17\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  1.626223381549593\n",
      "Training time:  0:00:23.521211\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.31it/s]\n",
      "Prediction time:  0:00:06.340459\n",
      "350  \t  426  \t  81\n",
      "Dev P:  0.231\n",
      "Dev R:  0.19\n",
      "Dev F1:  0.209\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.55it/s]\n",
      "Prediction time:  0:00:05.914823\n",
      "353  \t  421  \t  62\n",
      "Test P:  0.176\n",
      "Test R:  0.147\n",
      "Test F1:  0.16\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  18\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  1.4476151613015977\n",
      "Training time:  0:00:23.625714\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.294564\n",
      "349  \t  426  \t  82\n",
      "Dev P:  0.235\n",
      "Dev R:  0.192\n",
      "Dev F1:  0.212\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.861769\n",
      "353  \t  421  \t  60\n",
      "Test P:  0.17\n",
      "Test R:  0.143\n",
      "Test F1:  0.155\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  19\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  1.4060402147117115\n",
      "Training time:  0:00:23.623705\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.289421\n",
      "346  \t  426  \t  81\n",
      "Dev P:  0.234\n",
      "Dev R:  0.19\n",
      "Dev F1:  0.21\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.859699\n",
      "346  \t  421  \t  58\n",
      "Test P:  0.168\n",
      "Test R:  0.138\n",
      "Test F1:  0.151\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:23<00:00,  2.69it/s]\n",
      "Training loss:  1.2543205590475173\n",
      "Training time:  0:00:23.409939\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.292287\n",
      "330  \t  426  \t  78\n",
      "Dev P:  0.236\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.206\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.872969\n",
      "329  \t  421  \t  60\n",
      "Test P:  0.182\n",
      "Test R:  0.143\n",
      "Test F1:  0.16\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  21\n",
      "100%|| 63/63 [00:23<00:00,  2.70it/s]\n",
      "Training loss:  1.2922847876473078\n",
      "Training time:  0:00:23.303506\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.326969\n",
      "358  \t  426  \t  82\n",
      "Dev P:  0.229\n",
      "Dev R:  0.192\n",
      "Dev F1:  0.209\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.55it/s]\n",
      "Prediction time:  0:00:05.910802\n",
      "369  \t  421  \t  61\n",
      "Test P:  0.165\n",
      "Test R:  0.145\n",
      "Test F1:  0.154\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  22\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  1.1847178235886588\n",
      "Training time:  0:00:23.529844\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.308859\n",
      "348  \t  426  \t  83\n",
      "Dev P:  0.239\n",
      "Dev R:  0.195\n",
      "Dev F1:  0.214\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.56it/s]\n",
      "Prediction time:  0:00:05.905594\n",
      "354  \t  421  \t  70\n",
      "Test P:  0.198\n",
      "Test R:  0.166\n",
      "Test F1:  0.181\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  23\n",
      "100%|| 63/63 [00:23<00:00,  2.70it/s]\n",
      "Training loss:  1.0911639214508118\n",
      "Training time:  0:00:23.340432\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.307162\n",
      "356  \t  426  \t  84\n",
      "Dev P:  0.236\n",
      "Dev R:  0.197\n",
      "Dev F1:  0.215\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.872958\n",
      "360  \t  421  \t  66\n",
      "Test P:  0.183\n",
      "Test R:  0.157\n",
      "Test F1:  0.169\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  24\n",
      "100%|| 63/63 [00:23<00:00,  2.66it/s]\n",
      "Training loss:  1.0720767293657576\n",
      "Training time:  0:00:23.684207\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.37it/s]\n",
      "Prediction time:  0:00:06.235421\n",
      "339  \t  426  \t  81\n",
      "Dev P:  0.239\n",
      "Dev R:  0.19\n",
      "Dev F1:  0.212\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.61it/s]\n",
      "Prediction time:  0:00:05.819241\n",
      "339  \t  421  \t  59\n",
      "Test P:  0.174\n",
      "Test R:  0.14\n",
      "Test F1:  0.155\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  25\n",
      "100%|| 63/63 [00:23<00:00,  2.70it/s]\n",
      "Training loss:  1.0262180112657093\n",
      "Training time:  0:00:23.367880\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.300836\n",
      "386  \t  426  \t  89\n",
      "Dev P:  0.231\n",
      "Dev R:  0.209\n",
      "Dev F1:  0.219\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.889699\n",
      "391  \t  421  \t  70\n",
      "Test P:  0.179\n",
      "Test R:  0.166\n",
      "Test F1:  0.172\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  26\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  1.0132712182544528\n",
      "Training time:  0:00:23.626199\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.327602\n",
      "382  \t  426  \t  83\n",
      "Dev P:  0.217\n",
      "Dev R:  0.195\n",
      "Dev F1:  0.205\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.56it/s]\n",
      "Prediction time:  0:00:05.902775\n",
      "387  \t  421  \t  69\n",
      "Test P:  0.178\n",
      "Test R:  0.164\n",
      "Test F1:  0.171\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  27\n",
      "100%|| 63/63 [00:23<00:00,  2.66it/s]\n",
      "Training loss:  0.8915982542056886\n",
      "Training time:  0:00:23.647767\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.261635\n",
      "350  \t  426  \t  76\n",
      "Dev P:  0.217\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.196\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.838068\n",
      "353  \t  421  \t  62\n",
      "Test P:  0.176\n",
      "Test R:  0.147\n",
      "Test F1:  0.16\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  28\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  0.8713361980423094\n",
      "Training time:  0:00:23.553511\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.265206\n",
      "351  \t  426  \t  73\n",
      "Dev P:  0.208\n",
      "Dev R:  0.171\n",
      "Dev F1:  0.188\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.854135\n",
      "349  \t  421  \t  61\n",
      "Test P:  0.175\n",
      "Test R:  0.145\n",
      "Test F1:  0.158\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  29\n",
      "100%|| 63/63 [00:23<00:00,  2.70it/s]\n",
      "Training loss:  0.8223150514421009\n",
      "Training time:  0:00:23.311151\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.327614\n",
      "391  \t  426  \t  84\n",
      "Dev P:  0.215\n",
      "Dev R:  0.197\n",
      "Dev F1:  0.206\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.125158\n",
      "385  \t  421  \t  68\n",
      "Test P:  0.177\n",
      "Test R:  0.162\n",
      "Test F1:  0.169\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  30\n",
      "100%|| 63/63 [00:26<00:00,  2.41it/s]\n",
      "Training loss:  0.7552109218779064\n",
      "Training time:  0:00:26.192712\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.30it/s]\n",
      "Prediction time:  0:00:06.369198\n",
      "393  \t  426  \t  85\n",
      "Dev P:  0.216\n",
      "Dev R:  0.2\n",
      "Dev F1:  0.208\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.52it/s]\n",
      "Prediction time:  0:00:05.963968\n",
      "398  \t  421  \t  69\n",
      "Test P:  0.173\n",
      "Test R:  0.164\n",
      "Test F1:  0.168\n",
      "\n",
      "\n",
      "\n",
      "*******\n",
      "Best Epoch:  25\n",
      "Best Epoch Seed:  67\n",
      "Corresponding P:  0.179\n",
      "Corresponding R:  0.166\n",
      "Corresponding F1:  0.172\n",
      "\n",
      "\n",
      "\n",
      "Best Test Epoch:  22\n",
      "Corresponding P:  0.198\n",
      "Corresponding R:  0.166\n",
      "Corresponding F1:  0.181\n",
      "\n",
      "\n",
      "\n",
      "Test size: 322\n",
      "Re-checking the scores of entire Test data with the best saved model:\n",
      "Total sentences in the test set:  322\n",
      "GT Triple Count:  421  \tPRED Triple Count:  391  \tCORRECT Triple Count:  70\n",
      "Test P:  0.179\n",
      "Test R:  0.166\n",
      "Test F1:  0.172\n",
      "Now printing the scores for various subsets of Test Data with the best saved model:\n",
      "Total sentences with single triples:  243\n",
      "GT Triple Count:  243  \tPRED Triple Count:  282  \tCORRECT Triple Count:  48\n",
      "Test P:  0.17\n",
      "Test R:  0.198\n",
      "Test F1:  0.183\n",
      "Total sentences with multiple triples:  79\n",
      "GT Triple Count:  178  \tPRED Triple Count:  109  \tCORRECT Triple Count:  22\n",
      "Test P:  0.202\n",
      "Test R:  0.124\n",
      "Test F1:  0.153\n",
      "Total sentences triples with varying sentiments:  31\n",
      "GT Triple Count:  79  \tPRED Triple Count:  47  \tCORRECT Triple Count:  6\n",
      "Test P:  0.128\n",
      "Test R:  0.076\n",
      "Test F1:  0.095\n",
      "Total sentences with overlapping triples:  42\n",
      "GT Triple Count:  95  \tPRED Triple Count:  53  \tCORRECT Triple Count:  7\n",
      "Test P:  0.132\n",
      "Test R:  0.074\n",
      "Test F1:  0.095\n"
     ]
    }
   ],
   "source": [
    "!python3 PASTE_BERT.py --gpu_id 0 --src_folder mpqa/ --trg_folder mpqa/PASTE_BERT --bert_mode gen --gen_direct of --l2 y --use_pos_tags y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5381a734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/shivam/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/shivam/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/shivam/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "enc_hidden_size: 818\n",
      "dec_inp_size: 818\n",
      "dec_hidden_size: 818\n",
      "pointer_net_hidden_size: 300\n",
      "['PASTE_BERT.py', '--gpu_id', '0', '--src_folder', 'mpqa/', '--trg_folder', 'mpqa/PASTE_BERT', '--bert_mode', 'gen', '--gen_direct', 'of', '--l2', 'y', '--use_dep_emb', 'y']\n",
      "100  10  0.5\n",
      "BERT\n",
      "loading data......\n",
      "No. of sentences:  996\n",
      "No. of lines in Target file:  996\n",
      "No. of lines in POS file:  996\n",
      "No. of lines in DEP file:  996\n",
      "No. of sentences:  323\n",
      "No. of lines in Target file:  323\n",
      "No. of lines in POS file:  323\n",
      "No. of lines in DEP file:  323\n",
      "No. of sentences:  322\n",
      "No. of lines in Target file:  322\n",
      "No. of lines in POS file:  322\n",
      "No. of lines in DEP file:  322\n",
      "Training data size:  994\n",
      "Development data size:  323\n",
      "Test data size:  322\n",
      "Building POS TAG Vocab..\n",
      "Building DEP TAG Vocab..\n",
      "Training started......\n",
      "Batch Count:   63\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_attentions\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/shivam/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Parameters size:  129771609\n",
      "weight factor:  1\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "Epoch:  1\n",
      "  0%|                                                    | 0/63 [00:00<?, ?it/s]/home/shivam/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2251: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|| 63/63 [00:25<00:00,  2.48it/s]\n",
      "Training loss:  9.754393093169682\n",
      "Training time:  0:00:25.397946\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.21it/s]\n",
      "Prediction time:  0:00:06.537128\n",
      "323  \t  426  \t  53\n",
      "Dev P:  0.164\n",
      "Dev R:  0.124\n",
      "Dev F1:  0.142\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.48it/s]\n",
      "Prediction time:  0:00:06.028132\n",
      "322  \t  421  \t  41\n",
      "Test P:  0.127\n",
      "Test R:  0.097\n",
      "Test F1:  0.11\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  2\n",
      "100%|| 63/63 [00:24<00:00,  2.61it/s]\n",
      "Training loss:  7.021175369383797\n",
      "Training time:  0:00:24.127285\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.280625\n",
      "323  \t  426  \t  61\n",
      "Dev P:  0.189\n",
      "Dev R:  0.143\n",
      "Dev F1:  0.163\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.852841\n",
      "322  \t  421  \t  46\n",
      "Test P:  0.143\n",
      "Test R:  0.109\n",
      "Test F1:  0.124\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  3\n",
      "100%|| 63/63 [00:26<00:00,  2.36it/s]\n",
      "Training loss:  6.357563631875174\n",
      "Training time:  0:00:26.696429\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.30it/s]\n",
      "Prediction time:  0:00:06.361355\n",
      "323  \t  426  \t  66\n",
      "Dev P:  0.204\n",
      "Dev R:  0.155\n",
      "Dev F1:  0.176\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.53it/s]\n",
      "Prediction time:  0:00:05.946286\n",
      "322  \t  421  \t  53\n",
      "Test P:  0.165\n",
      "Test R:  0.126\n",
      "Test F1:  0.143\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  4\n",
      "100%|| 63/63 [00:24<00:00,  2.57it/s]\n",
      "Training loss:  5.627429965942625\n",
      "Training time:  0:00:24.558475\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.304096\n",
      "323  \t  426  \t  65\n",
      "Dev P:  0.201\n",
      "Dev R:  0.153\n",
      "Dev F1:  0.174\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.864441\n",
      "323  \t  421  \t  56\n",
      "Test P:  0.173\n",
      "Test R:  0.133\n",
      "Test F1:  0.151\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:23<00:00,  2.65it/s]\n",
      "Training loss:  5.100454027690585\n",
      "Training time:  0:00:23.749655\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.326420\n",
      "369  \t  426  \t  70\n",
      "Dev P:  0.19\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.176\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.56it/s]\n",
      "Prediction time:  0:00:05.895873\n",
      "353  \t  421  \t  65\n",
      "Test P:  0.184\n",
      "Test R:  0.154\n",
      "Test F1:  0.168\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  6\n",
      "100%|| 63/63 [00:24<00:00,  2.60it/s]\n",
      "Training loss:  4.579486347380138\n",
      "Training time:  0:00:24.193983\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.30it/s]\n",
      "Prediction time:  0:00:06.355547\n",
      "405  \t  426  \t  83\n",
      "Dev P:  0.205\n",
      "Dev R:  0.195\n",
      "Dev F1:  0.2\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.55it/s]\n",
      "Prediction time:  0:00:05.921382\n",
      "383  \t  421  \t  68\n",
      "Test P:  0.178\n",
      "Test R:  0.162\n",
      "Test F1:  0.169\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  7\n",
      "100%|| 63/63 [00:23<00:00,  2.63it/s]\n",
      "Training loss:  4.122226786991907\n",
      "Training time:  0:00:23.977716\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.333799\n",
      "350  \t  426  \t  78\n",
      "Dev P:  0.223\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.201\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.54it/s]\n",
      "Prediction time:  0:00:05.927665\n",
      "357  \t  421  \t  67\n",
      "Test P:  0.188\n",
      "Test R:  0.159\n",
      "Test F1:  0.172\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  8\n",
      "100%|| 63/63 [00:24<00:00,  2.60it/s]\n",
      "Training loss:  3.6433196162420605\n",
      "Training time:  0:00:24.226879\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.31it/s]\n",
      "Prediction time:  0:00:06.353509\n",
      "343  \t  426  \t  84\n",
      "Dev P:  0.245\n",
      "Dev R:  0.197\n",
      "Dev F1:  0.218\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.55it/s]\n",
      "Prediction time:  0:00:05.916039\n",
      "347  \t  421  \t  63\n",
      "Test P:  0.182\n",
      "Test R:  0.15\n",
      "Test F1:  0.164\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  9\n",
      "100%|| 63/63 [00:23<00:00,  2.65it/s]\n",
      "Training loss:  3.283971249111115\n",
      "Training time:  0:00:23.785775\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.28it/s]\n",
      "Prediction time:  0:00:06.398768\n",
      "333  \t  426  \t  78\n",
      "Dev P:  0.234\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.206\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.52it/s]\n",
      "Prediction time:  0:00:05.972903\n",
      "330  \t  421  \t  63\n",
      "Test P:  0.191\n",
      "Test R:  0.15\n",
      "Test F1:  0.168\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  10\n",
      "100%|| 63/63 [00:24<00:00,  2.60it/s]\n",
      "Training loss:  2.836219923836844\n",
      "Training time:  0:00:24.264933\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.28it/s]\n",
      "Prediction time:  0:00:06.397123\n",
      "380  \t  426  \t  82\n",
      "Dev P:  0.216\n",
      "Dev R:  0.192\n",
      "Dev F1:  0.203\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.51it/s]\n",
      "Prediction time:  0:00:05.982448\n",
      "380  \t  421  \t  67\n",
      "Test P:  0.176\n",
      "Test R:  0.159\n",
      "Test F1:  0.167\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  11\n",
      "100%|| 63/63 [00:24<00:00,  2.58it/s]\n",
      "Training loss:  2.5148781121723234\n",
      "Training time:  0:00:24.379760\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.29it/s]\n",
      "Prediction time:  0:00:06.390211\n",
      "367  \t  426  \t  77\n",
      "Dev P:  0.21\n",
      "Dev R:  0.181\n",
      "Dev F1:  0.194\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.54it/s]\n",
      "Prediction time:  0:00:05.933050\n",
      "376  \t  421  \t  73\n",
      "Test P:  0.194\n",
      "Test R:  0.173\n",
      "Test F1:  0.183\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  12\n",
      "100%|| 63/63 [00:23<00:00,  2.64it/s]\n",
      "Training loss:  2.28956733620356\n",
      "Training time:  0:00:23.881825\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.28it/s]\n",
      "Prediction time:  0:00:06.395602\n",
      "331  \t  426  \t  70\n",
      "Dev P:  0.211\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.185\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.53it/s]\n",
      "Prediction time:  0:00:05.954468\n",
      "326  \t  421  \t  53\n",
      "Test P:  0.163\n",
      "Test R:  0.126\n",
      "Test F1:  0.142\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  13\n",
      "100%|| 63/63 [00:24<00:00,  2.57it/s]\n",
      "Training loss:  2.264603124724494\n",
      "Training time:  0:00:24.476851\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.30it/s]\n",
      "Prediction time:  0:00:06.366652\n",
      "353  \t  426  \t  78\n",
      "Dev P:  0.221\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.2\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.54it/s]\n",
      "Prediction time:  0:00:05.925331\n",
      "353  \t  421  \t  69\n",
      "Test P:  0.195\n",
      "Test R:  0.164\n",
      "Test F1:  0.178\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  14\n",
      "100%|| 63/63 [00:24<00:00,  2.58it/s]\n",
      "Training loss:  1.9952926645203242\n",
      "Training time:  0:00:24.459379\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.310470\n",
      "347  \t  426  \t  79\n",
      "Dev P:  0.228\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.204\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.53it/s]\n",
      "Prediction time:  0:00:05.941644\n",
      "336  \t  421  \t  66\n",
      "Test P:  0.196\n",
      "Test R:  0.157\n",
      "Test F1:  0.174\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  15\n",
      "100%|| 63/63 [00:24<00:00,  2.58it/s]\n",
      "Training loss:  1.7924654379723564\n",
      "Training time:  0:00:24.387366\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.30it/s]\n",
      "Prediction time:  0:00:06.358106\n",
      "368  \t  426  \t  79\n",
      "Dev P:  0.215\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.199\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.55it/s]\n",
      "Prediction time:  0:00:05.908949\n",
      "364  \t  421  \t  64\n",
      "Test P:  0.176\n",
      "Test R:  0.152\n",
      "Test F1:  0.163\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  16\n",
      "100%|| 63/63 [00:23<00:00,  2.64it/s]\n",
      "Training loss:  1.7022885405828083\n",
      "Training time:  0:00:23.905282\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.315639\n",
      "379  \t  426  \t  80\n",
      "Dev P:  0.211\n",
      "Dev R:  0.188\n",
      "Dev F1:  0.199\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.890825\n",
      "379  \t  421  \t  75\n",
      "Test P:  0.198\n",
      "Test R:  0.178\n",
      "Test F1:  0.187\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  17\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  1.5283581463117448\n",
      "Training time:  0:00:23.524723\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.324003\n",
      "347  \t  426  \t  79\n",
      "Dev P:  0.228\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.204\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.56it/s]\n",
      "Prediction time:  0:00:05.906378\n",
      "347  \t  421  \t  72\n",
      "Test P:  0.207\n",
      "Test R:  0.171\n",
      "Test F1:  0.187\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  18\n",
      "100%|| 63/63 [00:23<00:00,  2.66it/s]\n",
      "Training loss:  1.4393567736186679\n",
      "Training time:  0:00:23.680090\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.302515\n",
      "343  \t  426  \t  72\n",
      "Dev P:  0.21\n",
      "Dev R:  0.169\n",
      "Dev F1:  0.187\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.870740\n",
      "334  \t  421  \t  62\n",
      "Test P:  0.186\n",
      "Test R:  0.147\n",
      "Test F1:  0.164\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  19\n",
      "100%|| 63/63 [00:23<00:00,  2.65it/s]\n",
      "Training loss:  1.387962017030943\n",
      "Training time:  0:00:23.747807\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.293859\n",
      "366  \t  426  \t  83\n",
      "Dev P:  0.227\n",
      "Dev R:  0.195\n",
      "Dev F1:  0.21\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.855541\n",
      "380  \t  421  \t  65\n",
      "Test P:  0.171\n",
      "Test R:  0.154\n",
      "Test F1:  0.162\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  1.319458255692134\n",
      "Training time:  0:00:23.474157\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.326808\n",
      "341  \t  426  \t  77\n",
      "Dev P:  0.226\n",
      "Dev R:  0.181\n",
      "Dev F1:  0.201\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.882695\n",
      "342  \t  421  \t  60\n",
      "Test P:  0.175\n",
      "Test R:  0.143\n",
      "Test F1:  0.157\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  21\n",
      "100%|| 63/63 [00:23<00:00,  2.73it/s]\n",
      "Training loss:  1.1991518584508745\n",
      "Training time:  0:00:23.077895\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.304702\n",
      "368  \t  426  \t  82\n",
      "Dev P:  0.223\n",
      "Dev R:  0.192\n",
      "Dev F1:  0.207\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.872350\n",
      "375  \t  421  \t  66\n",
      "Test P:  0.176\n",
      "Test R:  0.157\n",
      "Test F1:  0.166\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  22\n",
      "100%|| 63/63 [00:23<00:00,  2.69it/s]\n",
      "Training loss:  1.2104952675955636\n",
      "Training time:  0:00:23.433981\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.318110\n",
      "351  \t  426  \t  83\n",
      "Dev P:  0.236\n",
      "Dev R:  0.195\n",
      "Dev F1:  0.214\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.883187\n",
      "341  \t  421  \t  58\n",
      "Test P:  0.17\n",
      "Test R:  0.138\n",
      "Test F1:  0.152\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  23\n",
      "100%|| 63/63 [00:23<00:00,  2.70it/s]\n",
      "Training loss:  1.0469749669233959\n",
      "Training time:  0:00:23.369655\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.325153\n",
      "363  \t  426  \t  83\n",
      "Dev P:  0.229\n",
      "Dev R:  0.195\n",
      "Dev F1:  0.21\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.55it/s]\n",
      "Prediction time:  0:00:05.909374\n",
      "362  \t  421  \t  63\n",
      "Test P:  0.174\n",
      "Test R:  0.15\n",
      "Test F1:  0.161\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  24\n",
      "100%|| 63/63 [00:23<00:00,  2.66it/s]\n",
      "Training loss:  0.9491534176326933\n",
      "Training time:  0:00:23.710729\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.311883\n",
      "355  \t  426  \t  82\n",
      "Dev P:  0.231\n",
      "Dev R:  0.192\n",
      "Dev F1:  0.21\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.56it/s]\n",
      "Prediction time:  0:00:05.895620\n",
      "345  \t  421  \t  62\n",
      "Test P:  0.18\n",
      "Test R:  0.147\n",
      "Test F1:  0.162\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  25\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  0.8989373738803561\n",
      "Training time:  0:00:23.477744\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.305667\n",
      "360  \t  426  \t  83\n",
      "Dev P:  0.231\n",
      "Dev R:  0.195\n",
      "Dev F1:  0.211\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.884563\n",
      "360  \t  421  \t  67\n",
      "Test P:  0.186\n",
      "Test R:  0.159\n",
      "Test F1:  0.172\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  26\n",
      "100%|| 63/63 [00:23<00:00,  2.66it/s]\n",
      "Training loss:  0.8564471358817721\n",
      "Training time:  0:00:23.705887\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.276865\n",
      "356  \t  426  \t  79\n",
      "Dev P:  0.222\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.202\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.858363\n",
      "348  \t  421  \t  60\n",
      "Test P:  0.172\n",
      "Test R:  0.143\n",
      "Test F1:  0.156\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  27\n",
      "100%|| 63/63 [00:23<00:00,  2.64it/s]\n",
      "Training loss:  0.9051721843462142\n",
      "Training time:  0:00:23.837122\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.245400\n",
      "349  \t  426  \t  72\n",
      "Dev P:  0.206\n",
      "Dev R:  0.169\n",
      "Dev F1:  0.186\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.62it/s]\n",
      "Prediction time:  0:00:05.803841\n",
      "343  \t  421  \t  66\n",
      "Test P:  0.192\n",
      "Test R:  0.157\n",
      "Test F1:  0.173\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  28\n",
      "100%|| 63/63 [00:23<00:00,  2.66it/s]\n",
      "Training loss:  0.8849359095569641\n",
      "Training time:  0:00:23.696587\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.271750\n",
      "373  \t  426  \t  82\n",
      "Dev P:  0.22\n",
      "Dev R:  0.192\n",
      "Dev F1:  0.205\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.844528\n",
      "364  \t  421  \t  65\n",
      "Test P:  0.179\n",
      "Test R:  0.154\n",
      "Test F1:  0.166\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  29\n",
      "100%|| 63/63 [00:23<00:00,  2.69it/s]\n",
      "Training loss:  0.8738376044091725\n",
      "Training time:  0:00:23.448488\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.298842\n",
      "373  \t  426  \t  90\n",
      "Dev P:  0.241\n",
      "Dev R:  0.211\n",
      "Dev F1:  0.225\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.871695\n",
      "377  \t  421  \t  72\n",
      "Test P:  0.191\n",
      "Test R:  0.171\n",
      "Test F1:  0.18\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  30\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  0.934541592522273\n",
      "Training time:  0:00:23.518822\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.309428\n",
      "360  \t  426  \t  78\n",
      "Dev P:  0.217\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.198\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.883756\n",
      "363  \t  421  \t  64\n",
      "Test P:  0.176\n",
      "Test R:  0.152\n",
      "Test F1:  0.163\n",
      "\n",
      "\n",
      "\n",
      "*******\n",
      "Best Epoch:  29\n",
      "Best Epoch Seed:  71\n",
      "Corresponding P:  0.191\n",
      "Corresponding R:  0.171\n",
      "Corresponding F1:  0.18\n",
      "\n",
      "\n",
      "\n",
      "Best Test Epoch:  17\n",
      "Corresponding P:  0.207\n",
      "Corresponding R:  0.171\n",
      "Corresponding F1:  0.187\n",
      "\n",
      "\n",
      "\n",
      "Test size: 322\n",
      "Re-checking the scores of entire Test data with the best saved model:\n",
      "Total sentences in the test set:  322\n",
      "GT Triple Count:  421  \tPRED Triple Count:  377  \tCORRECT Triple Count:  72\n",
      "Test P:  0.191\n",
      "Test R:  0.171\n",
      "Test F1:  0.18\n",
      "Now printing the scores for various subsets of Test Data with the best saved model:\n",
      "Total sentences with single triples:  243\n",
      "GT Triple Count:  243  \tPRED Triple Count:  265  \tCORRECT Triple Count:  45\n",
      "Test P:  0.17\n",
      "Test R:  0.185\n",
      "Test F1:  0.177\n",
      "Total sentences with multiple triples:  79\n",
      "GT Triple Count:  178  \tPRED Triple Count:  112  \tCORRECT Triple Count:  27\n",
      "Test P:  0.241\n",
      "Test R:  0.152\n",
      "Test F1:  0.186\n",
      "Total sentences triples with varying sentiments:  31\n",
      "GT Triple Count:  79  \tPRED Triple Count:  45  \tCORRECT Triple Count:  9\n",
      "Test P:  0.2\n",
      "Test R:  0.114\n",
      "Test F1:  0.145\n",
      "Total sentences with overlapping triples:  42\n",
      "GT Triple Count:  95  \tPRED Triple Count:  55  \tCORRECT Triple Count:  9\n",
      "Test P:  0.164\n",
      "Test R:  0.095\n",
      "Test F1:  0.12\n"
     ]
    }
   ],
   "source": [
    "!python3 PASTE_BERT.py --gpu_id 0 --src_folder mpqa/ --trg_folder mpqa/PASTE_BERT --bert_mode gen --gen_direct of --l2 y --use_dep_emb y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "509bebf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/shivam/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/shivam/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/shivam/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "enc_hidden_size: 868\n",
      "dec_inp_size: 868\n",
      "dec_hidden_size: 868\n",
      "pointer_net_hidden_size: 300\n",
      "['PASTE_BERT.py', '--gpu_id', '0', '--src_folder', 'mpqa/', '--trg_folder', 'mpqa/PASTE_BERT', '--bert_mode', 'gen', '--gen_direct', 'of', '--l2', 'y', '--use_pos_tags', 'y', '--use_dep_emb', 'y']\n",
      "100  10  0.5\n",
      "BERT\n",
      "loading data......\n",
      "No. of sentences:  996\n",
      "No. of lines in Target file:  996\n",
      "No. of lines in POS file:  996\n",
      "No. of lines in DEP file:  996\n",
      "No. of sentences:  323\n",
      "No. of lines in Target file:  323\n",
      "No. of lines in POS file:  323\n",
      "No. of lines in DEP file:  323\n",
      "No. of sentences:  322\n",
      "No. of lines in Target file:  322\n",
      "No. of lines in POS file:  322\n",
      "No. of lines in DEP file:  322\n",
      "Training data size:  994\n",
      "Development data size:  323\n",
      "Test data size:  322\n",
      "Building POS TAG Vocab..\n",
      "Building DEP TAG Vocab..\n",
      "Training started......\n",
      "Batch Count:   63\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_attentions\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/shivam/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Parameters size:  131663959\n",
      "weight factor:  1\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "Epoch:  1\n",
      "  0%|                                                    | 0/63 [00:00<?, ?it/s]/home/shivam/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2251: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|| 63/63 [00:24<00:00,  2.61it/s]\n",
      "Training loss:  9.773003025660438\n",
      "Training time:  0:00:24.166595\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.30it/s]\n",
      "Prediction time:  0:00:06.365059\n",
      "323  \t  426  \t  55\n",
      "Dev P:  0.17\n",
      "Dev R:  0.129\n",
      "Dev F1:  0.147\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.55it/s]\n",
      "Prediction time:  0:00:05.919849\n",
      "322  \t  421  \t  39\n",
      "Test P:  0.121\n",
      "Test R:  0.093\n",
      "Test F1:  0.105\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  2\n",
      "100%|| 63/63 [00:30<00:00,  2.09it/s]\n",
      "Training loss:  7.103829777429974\n",
      "Training time:  0:00:30.075088\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.05it/s]\n",
      "Prediction time:  0:00:06.883490\n",
      "323  \t  426  \t  62\n",
      "Dev P:  0.192\n",
      "Dev R:  0.146\n",
      "Dev F1:  0.166\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.295428\n",
      "322  \t  421  \t  48\n",
      "Test P:  0.149\n",
      "Test R:  0.114\n",
      "Test F1:  0.129\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  3\n",
      "100%|| 63/63 [00:26<00:00,  2.38it/s]\n",
      "Training loss:  6.3881382866511265\n",
      "Training time:  0:00:26.473469\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.24it/s]\n",
      "Prediction time:  0:00:06.484826\n",
      "323  \t  426  \t  61\n",
      "Dev P:  0.189\n",
      "Dev R:  0.143\n",
      "Dev F1:  0.163\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.46it/s]\n",
      "Prediction time:  0:00:06.066655\n",
      "322  \t  421  \t  49\n",
      "Test P:  0.152\n",
      "Test R:  0.116\n",
      "Test F1:  0.132\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  4\n",
      "100%|| 63/63 [00:25<00:00,  2.45it/s]\n",
      "Training loss:  5.816822025511\n",
      "Training time:  0:00:25.716399\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.27it/s]\n",
      "Prediction time:  0:00:06.419775\n",
      "323  \t  426  \t  67\n",
      "Dev P:  0.207\n",
      "Dev R:  0.157\n",
      "Dev F1:  0.179\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.52it/s]\n",
      "Prediction time:  0:00:05.965635\n",
      "322  \t  421  \t  54\n",
      "Test P:  0.168\n",
      "Test R:  0.128\n",
      "Test F1:  0.145\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:24<00:00,  2.62it/s]\n",
      "Training loss:  5.374251940893749\n",
      "Training time:  0:00:24.047401\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.31it/s]\n",
      "Prediction time:  0:00:06.337943\n",
      "358  \t  426  \t  74\n",
      "Dev P:  0.207\n",
      "Dev R:  0.174\n",
      "Dev F1:  0.189\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.54it/s]\n",
      "Prediction time:  0:00:05.926187\n",
      "359  \t  421  \t  65\n",
      "Test P:  0.181\n",
      "Test R:  0.154\n",
      "Test F1:  0.167\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  6\n",
      "100%|| 63/63 [00:24<00:00,  2.59it/s]\n",
      "Training loss:  4.69393115195017\n",
      "Training time:  0:00:24.329765\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.27it/s]\n",
      "Prediction time:  0:00:06.423958\n",
      "385  \t  426  \t  83\n",
      "Dev P:  0.216\n",
      "Dev R:  0.195\n",
      "Dev F1:  0.205\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.51it/s]\n",
      "Prediction time:  0:00:05.980614\n",
      "385  \t  421  \t  65\n",
      "Test P:  0.169\n",
      "Test R:  0.154\n",
      "Test F1:  0.161\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  7\n",
      "100%|| 63/63 [00:26<00:00,  2.42it/s]\n",
      "Training loss:  4.432314884094965\n",
      "Training time:  0:00:26.083671\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.24it/s]\n",
      "Prediction time:  0:00:06.491721\n",
      "352  \t  426  \t  82\n",
      "Dev P:  0.233\n",
      "Dev R:  0.192\n",
      "Dev F1:  0.211\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.46it/s]\n",
      "Prediction time:  0:00:06.065134\n",
      "359  \t  421  \t  61\n",
      "Test P:  0.17\n",
      "Test R:  0.145\n",
      "Test F1:  0.156\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  8\n",
      "100%|| 63/63 [00:26<00:00,  2.35it/s]\n",
      "Training loss:  3.8715617694551985\n",
      "Training time:  0:00:26.771681\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.23it/s]\n",
      "Prediction time:  0:00:06.504106\n",
      "332  \t  426  \t  74\n",
      "Dev P:  0.223\n",
      "Dev R:  0.174\n",
      "Dev F1:  0.195\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.47it/s]\n",
      "Prediction time:  0:00:06.055560\n",
      "331  \t  421  \t  56\n",
      "Test P:  0.169\n",
      "Test R:  0.133\n",
      "Test F1:  0.149\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  9\n",
      "100%|| 63/63 [00:26<00:00,  2.36it/s]\n",
      "Training loss:  3.460872182770381\n",
      "Training time:  0:00:26.651277\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.23it/s]\n",
      "Prediction time:  0:00:06.511485\n",
      "329  \t  426  \t  79\n",
      "Dev P:  0.24\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.209\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.46it/s]\n",
      "Prediction time:  0:00:06.071539\n",
      "327  \t  421  \t  58\n",
      "Test P:  0.177\n",
      "Test R:  0.138\n",
      "Test F1:  0.155\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  10\n",
      "100%|| 63/63 [00:26<00:00,  2.38it/s]\n",
      "Training loss:  3.114867936997187\n",
      "Training time:  0:00:26.522294\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.23it/s]\n",
      "Prediction time:  0:00:06.494541\n",
      "367  \t  426  \t  72\n",
      "Dev P:  0.196\n",
      "Dev R:  0.169\n",
      "Dev F1:  0.182\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.47it/s]\n",
      "Prediction time:  0:00:06.058762\n",
      "371  \t  421  \t  68\n",
      "Test P:  0.183\n",
      "Test R:  0.162\n",
      "Test F1:  0.172\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  11\n",
      "100%|| 63/63 [00:26<00:00,  2.39it/s]\n",
      "Training loss:  2.7887996132411654\n",
      "Training time:  0:00:26.398481\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.23it/s]\n",
      "Prediction time:  0:00:06.498140\n",
      "371  \t  426  \t  78\n",
      "Dev P:  0.21\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.196\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.45it/s]\n",
      "Prediction time:  0:00:06.085542\n",
      "373  \t  421  \t  68\n",
      "Test P:  0.182\n",
      "Test R:  0.162\n",
      "Test F1:  0.171\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  12\n",
      "100%|| 63/63 [00:26<00:00,  2.36it/s]\n",
      "Training loss:  2.4927254063742503\n",
      "Training time:  0:00:26.676502\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.12it/s]\n",
      "Prediction time:  0:00:06.741797\n",
      "344  \t  426  \t  71\n",
      "Dev P:  0.206\n",
      "Dev R:  0.167\n",
      "Dev F1:  0.184\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.28it/s]\n",
      "Prediction time:  0:00:06.407200\n",
      "339  \t  421  \t  66\n",
      "Test P:  0.195\n",
      "Test R:  0.157\n",
      "Test F1:  0.174\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  13\n",
      "100%|| 63/63 [00:33<00:00,  1.90it/s]\n",
      "Training loss:  2.408874138953194\n",
      "Training time:  0:00:33.195237\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.442838\n",
      "337  \t  426  \t  72\n",
      "Dev P:  0.214\n",
      "Dev R:  0.169\n",
      "Dev F1:  0.189\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.53it/s]\n",
      "Prediction time:  0:00:05.946320\n",
      "347  \t  421  \t  68\n",
      "Test P:  0.196\n",
      "Test R:  0.162\n",
      "Test F1:  0.177\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  14\n",
      "100%|| 63/63 [00:26<00:00,  2.42it/s]\n",
      "Training loss:  2.091911209954156\n",
      "Training time:  0:00:26.045335\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.22it/s]\n",
      "Prediction time:  0:00:06.513345\n",
      "339  \t  426  \t  76\n",
      "Dev P:  0.224\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.199\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.46it/s]\n",
      "Prediction time:  0:00:06.067838\n",
      "335  \t  421  \t  65\n",
      "Test P:  0.194\n",
      "Test R:  0.154\n",
      "Test F1:  0.172\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  15\n",
      "100%|| 63/63 [00:26<00:00,  2.36it/s]\n",
      "Training loss:  1.9607748162178766\n",
      "Training time:  0:00:26.672258\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.24it/s]\n",
      "Prediction time:  0:00:06.484631\n",
      "351  \t  426  \t  82\n",
      "Dev P:  0.234\n",
      "Dev R:  0.192\n",
      "Dev F1:  0.211\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.47it/s]\n",
      "Prediction time:  0:00:06.055294\n",
      "360  \t  421  \t  70\n",
      "Test P:  0.194\n",
      "Test R:  0.166\n",
      "Test F1:  0.179\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  16\n",
      "100%|| 63/63 [00:28<00:00,  2.24it/s]\n",
      "Training loss:  1.7996153519267128\n",
      "Training time:  0:00:28.184578\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.07it/s]\n",
      "Prediction time:  0:00:06.838877\n",
      "412  \t  426  \t  87\n",
      "Dev P:  0.211\n",
      "Dev R:  0.204\n",
      "Dev F1:  0.208\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.40it/s]\n",
      "Prediction time:  0:00:06.169787\n",
      "414  \t  421  \t  71\n",
      "Test P:  0.171\n",
      "Test R:  0.169\n",
      "Test F1:  0.17\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  17\n",
      "100%|| 63/63 [00:28<00:00,  2.24it/s]\n",
      "Training loss:  1.609154084372142\n",
      "Training time:  0:00:28.066097\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.23it/s]\n",
      "Prediction time:  0:00:06.506455\n",
      "352  \t  426  \t  81\n",
      "Dev P:  0.23\n",
      "Dev R:  0.19\n",
      "Dev F1:  0.208\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.45it/s]\n",
      "Prediction time:  0:00:06.082505\n",
      "355  \t  421  \t  72\n",
      "Test P:  0.203\n",
      "Test R:  0.171\n",
      "Test F1:  0.186\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  18\n",
      "100%|| 63/63 [00:25<00:00,  2.50it/s]\n",
      "Training loss:  1.5163534113339014\n",
      "Training time:  0:00:25.153292\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.28it/s]\n",
      "Prediction time:  0:00:06.411089\n",
      "346  \t  426  \t  77\n",
      "Dev P:  0.223\n",
      "Dev R:  0.181\n",
      "Dev F1:  0.199\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.52it/s]\n",
      "Prediction time:  0:00:05.963834\n",
      "349  \t  421  \t  72\n",
      "Test P:  0.206\n",
      "Test R:  0.171\n",
      "Test F1:  0.187\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  19\n",
      "100%|| 63/63 [00:24<00:00,  2.59it/s]\n",
      "Training loss:  1.4513035972440054\n",
      "Training time:  0:00:24.341318\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.28it/s]\n",
      "Prediction time:  0:00:06.401498\n",
      "346  \t  426  \t  78\n",
      "Dev P:  0.225\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.202\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.53it/s]\n",
      "Prediction time:  0:00:05.954155\n",
      "351  \t  421  \t  67\n",
      "Test P:  0.191\n",
      "Test R:  0.159\n",
      "Test F1:  0.174\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:24<00:00,  2.53it/s]\n",
      "Training loss:  1.3622538882588584\n",
      "Training time:  0:00:24.882297\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.23it/s]\n",
      "Prediction time:  0:00:06.510866\n",
      "333  \t  426  \t  78\n",
      "Dev P:  0.234\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.206\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.46it/s]\n",
      "Prediction time:  0:00:06.064281\n",
      "333  \t  421  \t  63\n",
      "Test P:  0.189\n",
      "Test R:  0.15\n",
      "Test F1:  0.167\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  21\n",
      "100%|| 63/63 [00:27<00:00,  2.25it/s]\n",
      "Training loss:  1.2668987995102292\n",
      "Training time:  0:00:27.964313\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.23it/s]\n",
      "Prediction time:  0:00:06.509329\n",
      "375  \t  426  \t  80\n",
      "Dev P:  0.213\n",
      "Dev R:  0.188\n",
      "Dev F1:  0.2\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.45it/s]\n",
      "Prediction time:  0:00:06.093684\n",
      "386  \t  421  \t  70\n",
      "Test P:  0.181\n",
      "Test R:  0.166\n",
      "Test F1:  0.173\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  22\n",
      "100%|| 63/63 [00:30<00:00,  2.10it/s]\n",
      "Training loss:  1.2702431837244639\n",
      "Training time:  0:00:30.022999\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.24it/s]\n",
      "Prediction time:  0:00:06.485512\n",
      "352  \t  426  \t  76\n",
      "Dev P:  0.216\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.195\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.48it/s]\n",
      "Prediction time:  0:00:06.038017\n",
      "357  \t  421  \t  69\n",
      "Test P:  0.193\n",
      "Test R:  0.164\n",
      "Test F1:  0.177\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  23\n",
      "100%|| 63/63 [00:26<00:00,  2.38it/s]\n",
      "Training loss:  1.110599061799428\n",
      "Training time:  0:00:26.464258\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.23it/s]\n",
      "Prediction time:  0:00:06.492744\n",
      "377  \t  426  \t  81\n",
      "Dev P:  0.215\n",
      "Dev R:  0.19\n",
      "Dev F1:  0.202\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.46it/s]\n",
      "Prediction time:  0:00:06.075966\n",
      "385  \t  421  \t  72\n",
      "Test P:  0.187\n",
      "Test R:  0.171\n",
      "Test F1:  0.179\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  24\n",
      "100%|| 63/63 [00:25<00:00,  2.48it/s]\n",
      "Training loss:  1.0007678644051627\n",
      "Training time:  0:00:25.365634\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.28it/s]\n",
      "Prediction time:  0:00:06.398382\n",
      "357  \t  426  \t  78\n",
      "Dev P:  0.218\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.199\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.53it/s]\n",
      "Prediction time:  0:00:05.947211\n",
      "356  \t  421  \t  74\n",
      "Test P:  0.208\n",
      "Test R:  0.176\n",
      "Test F1:  0.19\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  25\n",
      "100%|| 63/63 [00:24<00:00,  2.61it/s]\n",
      "Training loss:  1.020612497178335\n",
      "Training time:  0:00:24.130211\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.28it/s]\n",
      "Prediction time:  0:00:06.396047\n",
      "379  \t  426  \t  87\n",
      "Dev P:  0.23\n",
      "Dev R:  0.204\n",
      "Dev F1:  0.216\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.53it/s]\n",
      "Prediction time:  0:00:05.957622\n",
      "382  \t  421  \t  79\n",
      "Test P:  0.207\n",
      "Test R:  0.188\n",
      "Test F1:  0.197\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  26\n",
      "100%|| 63/63 [00:24<00:00,  2.60it/s]\n",
      "Training loss:  0.9045795670577458\n",
      "Training time:  0:00:24.263983\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.31it/s]\n",
      "Prediction time:  0:00:06.346660\n",
      "364  \t  426  \t  81\n",
      "Dev P:  0.223\n",
      "Dev R:  0.19\n",
      "Dev F1:  0.205\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.55it/s]\n",
      "Prediction time:  0:00:05.916472\n",
      "361  \t  421  \t  72\n",
      "Test P:  0.199\n",
      "Test R:  0.171\n",
      "Test F1:  0.184\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  27\n",
      "100%|| 63/63 [00:24<00:00,  2.57it/s]\n",
      "Training loss:  0.9274852952313801\n",
      "Training time:  0:00:24.478079\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.30it/s]\n",
      "Prediction time:  0:00:06.357879\n",
      "363  \t  426  \t  80\n",
      "Dev P:  0.22\n",
      "Dev R:  0.188\n",
      "Dev F1:  0.203\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.54it/s]\n",
      "Prediction time:  0:00:05.925713\n",
      "367  \t  421  \t  83\n",
      "Test P:  0.226\n",
      "Test R:  0.197\n",
      "Test F1:  0.211\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  28\n",
      "100%|| 63/63 [00:24<00:00,  2.61it/s]\n",
      "Training loss:  0.9447629555823311\n",
      "Training time:  0:00:24.153024\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.30it/s]\n",
      "Prediction time:  0:00:06.369041\n",
      "360  \t  426  \t  69\n",
      "Dev P:  0.192\n",
      "Dev R:  0.162\n",
      "Dev F1:  0.176\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.54it/s]\n",
      "Prediction time:  0:00:05.939723\n",
      "358  \t  421  \t  70\n",
      "Test P:  0.196\n",
      "Test R:  0.166\n",
      "Test F1:  0.18\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  29\n",
      "100%|| 63/63 [00:23<00:00,  2.63it/s]\n",
      "Training loss:  0.9102151909517864\n",
      "Training time:  0:00:23.940712\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.30it/s]\n",
      "Prediction time:  0:00:06.355884\n",
      "384  \t  426  \t  79\n",
      "Dev P:  0.206\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.195\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.55it/s]\n",
      "Prediction time:  0:00:05.921102\n",
      "389  \t  421  \t  66\n",
      "Test P:  0.17\n",
      "Test R:  0.157\n",
      "Test F1:  0.163\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  30\n",
      "100%|| 63/63 [00:24<00:00,  2.61it/s]\n",
      "Training loss:  0.8706523667252253\n",
      "Training time:  0:00:24.149290\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.27it/s]\n",
      "Prediction time:  0:00:06.414973\n",
      "352  \t  426  \t  73\n",
      "Dev P:  0.207\n",
      "Dev R:  0.171\n",
      "Dev F1:  0.188\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.51it/s]\n",
      "Prediction time:  0:00:05.976016\n",
      "349  \t  421  \t  76\n",
      "Test P:  0.218\n",
      "Test R:  0.181\n",
      "Test F1:  0.197\n",
      "\n",
      "\n",
      "\n",
      "*******\n",
      "Best Epoch:  25\n",
      "Best Epoch Seed:  67\n",
      "Corresponding P:  0.207\n",
      "Corresponding R:  0.188\n",
      "Corresponding F1:  0.197\n",
      "\n",
      "\n",
      "\n",
      "Best Test Epoch:  27\n",
      "Corresponding P:  0.226\n",
      "Corresponding R:  0.197\n",
      "Corresponding F1:  0.211\n",
      "\n",
      "\n",
      "\n",
      "Test size: 322\n",
      "Re-checking the scores of entire Test data with the best saved model:\n",
      "Total sentences in the test set:  322\n",
      "GT Triple Count:  421  \tPRED Triple Count:  382  \tCORRECT Triple Count:  79\n",
      "Test P:  0.207\n",
      "Test R:  0.188\n",
      "Test F1:  0.197\n",
      "Now printing the scores for various subsets of Test Data with the best saved model:\n",
      "Total sentences with single triples:  243\n",
      "GT Triple Count:  243  \tPRED Triple Count:  273  \tCORRECT Triple Count:  56\n",
      "Test P:  0.205\n",
      "Test R:  0.23\n",
      "Test F1:  0.217\n",
      "Total sentences with multiple triples:  79\n",
      "GT Triple Count:  178  \tPRED Triple Count:  109  \tCORRECT Triple Count:  23\n",
      "Test P:  0.211\n",
      "Test R:  0.129\n",
      "Test F1:  0.16\n",
      "Total sentences triples with varying sentiments:  31\n",
      "GT Triple Count:  79  \tPRED Triple Count:  44  \tCORRECT Triple Count:  10\n",
      "Test P:  0.227\n",
      "Test R:  0.127\n",
      "Test F1:  0.163\n",
      "Total sentences with overlapping triples:  42\n",
      "GT Triple Count:  95  \tPRED Triple Count:  52  \tCORRECT Triple Count:  7\n",
      "Test P:  0.135\n",
      "Test R:  0.074\n",
      "Test F1:  0.095\n"
     ]
    }
   ],
   "source": [
    "!python3 PASTE_BERT.py --gpu_id 0 --src_folder mpqa/ --trg_folder mpqa/PASTE_BERT --bert_mode gen --gen_direct of --l2 y --use_pos_tags y --use_dep_emb y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a86d9d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e521875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/shivam/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/shivam/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/shivam/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "enc_hidden_size: 768\n",
      "dec_inp_size: 768\n",
      "dec_hidden_size: 768\n",
      "pointer_net_hidden_size: 300\n",
      "['PASTE_BERT.py', '--gpu_id', '0', '--src_folder', 'mpqa/', '--trg_folder', 'mpqa/PASTE_BERT', '--bert_mode', 'gen', '--gen_direct', 'of', '--l2', 'y', '--wd', '1e-5']\n",
      "100  10  0.5\n",
      "BERT\n",
      "loading data......\n",
      "No. of sentences:  996\n",
      "No. of lines in Target file:  996\n",
      "No. of lines in POS file:  996\n",
      "No. of lines in DEP file:  996\n",
      "No. of sentences:  323\n",
      "No. of lines in Target file:  323\n",
      "No. of lines in POS file:  323\n",
      "No. of lines in DEP file:  323\n",
      "No. of sentences:  322\n",
      "No. of lines in Target file:  322\n",
      "No. of lines in POS file:  322\n",
      "No. of lines in DEP file:  322\n",
      "Training data size:  994\n",
      "Development data size:  323\n",
      "Test data size:  322\n",
      "Building POS TAG Vocab..\n",
      "Building DEP TAG Vocab..\n",
      "Training started......\n",
      "Batch Count:   63\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_attentions\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/shivam/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Parameters size:  127959659\n",
      "weight factor:  1\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 1e-05\n",
      ")\n",
      "Epoch:  1\n",
      "  0%|                                                    | 0/63 [00:00<?, ?it/s]/home/shivam/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2251: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|| 63/63 [00:22<00:00,  2.80it/s]\n",
      "Training loss:  9.820661408560616\n",
      "Training time:  0:00:22.517059\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.45it/s]\n",
      "Prediction time:  0:00:06.082767\n",
      "325  \t  426  \t  50\n",
      "Dev P:  0.154\n",
      "Dev R:  0.117\n",
      "Dev F1:  0.133\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.725054\n",
      "322  \t  421  \t  37\n",
      "Test P:  0.115\n",
      "Test R:  0.088\n",
      "Test F1:  0.1\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  2\n",
      "100%|| 63/63 [00:22<00:00,  2.80it/s]\n",
      "Training loss:  7.042950872390989\n",
      "Training time:  0:00:22.524902\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.45it/s]\n",
      "Prediction time:  0:00:06.085663\n",
      "323  \t  426  \t  59\n",
      "Dev P:  0.183\n",
      "Dev R:  0.138\n",
      "Dev F1:  0.158\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.68it/s]\n",
      "Prediction time:  0:00:05.707169\n",
      "322  \t  421  \t  48\n",
      "Test P:  0.149\n",
      "Test R:  0.114\n",
      "Test F1:  0.129\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  3\n",
      "100%|| 63/63 [00:22<00:00,  2.82it/s]\n",
      "Training loss:  6.301974008953761\n",
      "Training time:  0:00:22.301376\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.123102\n",
      "323  \t  426  \t  60\n",
      "Dev P:  0.186\n",
      "Dev R:  0.141\n",
      "Dev F1:  0.16\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.719640\n",
      "324  \t  421  \t  47\n",
      "Test P:  0.145\n",
      "Test R:  0.112\n",
      "Test F1:  0.126\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  4\n",
      "100%|| 63/63 [00:22<00:00,  2.86it/s]\n",
      "Training loss:  5.624240712513999\n",
      "Training time:  0:00:22.004561\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.42it/s]\n",
      "Prediction time:  0:00:06.148871\n",
      "327  \t  426  \t  59\n",
      "Dev P:  0.18\n",
      "Dev R:  0.138\n",
      "Dev F1:  0.157\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.66it/s]\n",
      "Prediction time:  0:00:05.742984\n",
      "324  \t  421  \t  58\n",
      "Test P:  0.179\n",
      "Test R:  0.138\n",
      "Test F1:  0.156\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:22<00:00,  2.85it/s]\n",
      "Training loss:  4.964702855973017\n",
      "Training time:  0:00:22.068205\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.46it/s]\n",
      "Prediction time:  0:00:06.076604\n",
      "402  \t  426  \t  74\n",
      "Dev P:  0.184\n",
      "Dev R:  0.174\n",
      "Dev F1:  0.179\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.69it/s]\n",
      "Prediction time:  0:00:05.697246\n",
      "401  \t  421  \t  68\n",
      "Test P:  0.17\n",
      "Test R:  0.162\n",
      "Test F1:  0.165\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  6\n",
      "100%|| 63/63 [00:22<00:00,  2.83it/s]\n",
      "Training loss:  4.523283863824512\n",
      "Training time:  0:00:22.299095\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.42it/s]\n",
      "Prediction time:  0:00:06.144926\n",
      "370  \t  426  \t  76\n",
      "Dev P:  0.205\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.191\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.65it/s]\n",
      "Prediction time:  0:00:05.753040\n",
      "360  \t  421  \t  67\n",
      "Test P:  0.186\n",
      "Test R:  0.159\n",
      "Test F1:  0.172\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  7\n",
      "100%|| 63/63 [00:22<00:00,  2.81it/s]\n",
      "Training loss:  4.005924478409782\n",
      "Training time:  0:00:22.451229\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.129837\n",
      "344  \t  426  \t  65\n",
      "Dev P:  0.189\n",
      "Dev R:  0.153\n",
      "Dev F1:  0.169\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.66it/s]\n",
      "Prediction time:  0:00:05.740404\n",
      "342  \t  421  \t  56\n",
      "Test P:  0.164\n",
      "Test R:  0.133\n",
      "Test F1:  0.147\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  8\n",
      "100%|| 63/63 [00:22<00:00,  2.83it/s]\n",
      "Training loss:  3.3659961110069636\n",
      "Training time:  0:00:22.243608\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.130276\n",
      "337  \t  426  \t  65\n",
      "Dev P:  0.193\n",
      "Dev R:  0.153\n",
      "Dev F1:  0.17\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.65it/s]\n",
      "Prediction time:  0:00:05.747863\n",
      "334  \t  421  \t  56\n",
      "Test P:  0.168\n",
      "Test R:  0.133\n",
      "Test F1:  0.148\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  9\n",
      "100%|| 63/63 [00:22<00:00,  2.84it/s]\n",
      "Training loss:  2.9864688184526234\n",
      "Training time:  0:00:22.199736\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.45it/s]\n",
      "Prediction time:  0:00:06.086432\n",
      "333  \t  426  \t  63\n",
      "Dev P:  0.189\n",
      "Dev R:  0.148\n",
      "Dev F1:  0.166\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.718684\n",
      "329  \t  421  \t  57\n",
      "Test P:  0.173\n",
      "Test R:  0.135\n",
      "Test F1:  0.152\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  10\n",
      "100%|| 63/63 [00:22<00:00,  2.82it/s]\n",
      "Training loss:  2.6960840963181996\n",
      "Training time:  0:00:22.313708\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.121331\n",
      "381  \t  426  \t  81\n",
      "Dev P:  0.213\n",
      "Dev R:  0.19\n",
      "Dev F1:  0.201\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.721602\n",
      "379  \t  421  \t  67\n",
      "Test P:  0.177\n",
      "Test R:  0.159\n",
      "Test F1:  0.167\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  11\n",
      "100%|| 63/63 [00:22<00:00,  2.85it/s]\n",
      "Training loss:  2.3645813427274187\n",
      "Training time:  0:00:22.136299\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.42it/s]\n",
      "Prediction time:  0:00:06.137346\n",
      "396  \t  426  \t  79\n",
      "Dev P:  0.199\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.192\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.66it/s]\n",
      "Prediction time:  0:00:05.741896\n",
      "391  \t  421  \t  67\n",
      "Test P:  0.171\n",
      "Test R:  0.159\n",
      "Test F1:  0.165\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  12\n",
      "100%|| 63/63 [00:22<00:00,  2.84it/s]\n",
      "Training loss:  2.1314262435549782\n",
      "Training time:  0:00:22.196402\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.118967\n",
      "348  \t  426  \t  69\n",
      "Dev P:  0.198\n",
      "Dev R:  0.162\n",
      "Dev F1:  0.178\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.716418\n",
      "345  \t  421  \t  65\n",
      "Test P:  0.188\n",
      "Test R:  0.154\n",
      "Test F1:  0.17\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  13\n",
      "100%|| 63/63 [00:22<00:00,  2.79it/s]\n",
      "Training loss:  1.9589654396450709\n",
      "Training time:  0:00:22.550892\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.126223\n",
      "354  \t  426  \t  76\n",
      "Dev P:  0.215\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.195\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.725367\n",
      "353  \t  421  \t  68\n",
      "Test P:  0.193\n",
      "Test R:  0.162\n",
      "Test F1:  0.176\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  14\n",
      "100%|| 63/63 [00:22<00:00,  2.83it/s]\n",
      "Training loss:  1.7226289274200561\n",
      "Training time:  0:00:22.228459\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.44it/s]\n",
      "Prediction time:  0:00:06.106304\n",
      "347  \t  426  \t  72\n",
      "Dev P:  0.207\n",
      "Dev R:  0.169\n",
      "Dev F1:  0.186\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.68it/s]\n",
      "Prediction time:  0:00:05.709087\n",
      "338  \t  421  \t  63\n",
      "Test P:  0.186\n",
      "Test R:  0.15\n",
      "Test F1:  0.166\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  15\n",
      "100%|| 63/63 [00:22<00:00,  2.82it/s]\n",
      "Training loss:  1.5247068121319725\n",
      "Training time:  0:00:22.316340\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.121937\n",
      "355  \t  426  \t  72\n",
      "Dev P:  0.203\n",
      "Dev R:  0.169\n",
      "Dev F1:  0.184\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.66it/s]\n",
      "Prediction time:  0:00:05.742782\n",
      "349  \t  421  \t  65\n",
      "Test P:  0.186\n",
      "Test R:  0.154\n",
      "Test F1:  0.169\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  16\n",
      "100%|| 63/63 [00:22<00:00,  2.79it/s]\n",
      "Training loss:  1.484603618818616\n",
      "Training time:  0:00:22.563151\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.45it/s]\n",
      "Prediction time:  0:00:06.095804\n",
      "400  \t  426  \t  74\n",
      "Dev P:  0.185\n",
      "Dev R:  0.174\n",
      "Dev F1:  0.179\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.725626\n",
      "409  \t  421  \t  76\n",
      "Test P:  0.186\n",
      "Test R:  0.181\n",
      "Test F1:  0.183\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  17\n",
      "100%|| 63/63 [00:22<00:00,  2.84it/s]\n",
      "Training loss:  1.3487624686861794\n",
      "Training time:  0:00:22.193619\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.42it/s]\n",
      "Prediction time:  0:00:06.133744\n",
      "329  \t  426  \t  73\n",
      "Dev P:  0.222\n",
      "Dev R:  0.171\n",
      "Dev F1:  0.193\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.66it/s]\n",
      "Prediction time:  0:00:05.745957\n",
      "328  \t  421  \t  69\n",
      "Test P:  0.21\n",
      "Test R:  0.164\n",
      "Test F1:  0.184\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  18\n",
      "100%|| 63/63 [00:22<00:00,  2.82it/s]\n",
      "Training loss:  1.208514268909182\n",
      "Training time:  0:00:22.320130\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.44it/s]\n",
      "Prediction time:  0:00:06.106329\n",
      "354  \t  426  \t  74\n",
      "Dev P:  0.209\n",
      "Dev R:  0.174\n",
      "Dev F1:  0.19\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.726238\n",
      "349  \t  421  \t  67\n",
      "Test P:  0.192\n",
      "Test R:  0.159\n",
      "Test F1:  0.174\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  19\n",
      "100%|| 63/63 [00:22<00:00,  2.81it/s]\n",
      "Training loss:  1.1791794550797297\n",
      "Training time:  0:00:22.414974\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.45it/s]\n",
      "Prediction time:  0:00:06.081174\n",
      "336  \t  426  \t  75\n",
      "Dev P:  0.223\n",
      "Dev R:  0.176\n",
      "Dev F1:  0.197\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.721562\n",
      "344  \t  421  \t  65\n",
      "Test P:  0.189\n",
      "Test R:  0.154\n",
      "Test F1:  0.17\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:22<00:00,  2.83it/s]\n",
      "Training loss:  1.0566515586678944\n",
      "Training time:  0:00:22.281491\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.42it/s]\n",
      "Prediction time:  0:00:06.143221\n",
      "343  \t  426  \t  77\n",
      "Dev P:  0.224\n",
      "Dev R:  0.181\n",
      "Dev F1:  0.2\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.65it/s]\n",
      "Prediction time:  0:00:05.748285\n",
      "353  \t  421  \t  65\n",
      "Test P:  0.184\n",
      "Test R:  0.154\n",
      "Test F1:  0.168\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  21\n",
      "100%|| 63/63 [00:22<00:00,  2.86it/s]\n",
      "Training loss:  1.1258084731442588\n",
      "Training time:  0:00:22.034970\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.42it/s]\n",
      "Prediction time:  0:00:06.139358\n",
      "347  \t  426  \t  79\n",
      "Dev P:  0.228\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.204\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.65it/s]\n",
      "Prediction time:  0:00:05.748482\n",
      "345  \t  421  \t  63\n",
      "Test P:  0.183\n",
      "Test R:  0.15\n",
      "Test F1:  0.164\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  22\n",
      "100%|| 63/63 [00:22<00:00,  2.84it/s]\n",
      "Training loss:  1.0681081391752711\n",
      "Training time:  0:00:22.192603\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.117008\n",
      "350  \t  426  \t  77\n",
      "Dev P:  0.22\n",
      "Dev R:  0.181\n",
      "Dev F1:  0.198\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.65it/s]\n",
      "Prediction time:  0:00:05.758046\n",
      "354  \t  421  \t  59\n",
      "Test P:  0.167\n",
      "Test R:  0.14\n",
      "Test F1:  0.152\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  23\n",
      "100%|| 63/63 [00:22<00:00,  2.85it/s]\n",
      "Training loss:  0.9328156269731975\n",
      "Training time:  0:00:22.072434\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.129625\n",
      "358  \t  426  \t  78\n",
      "Dev P:  0.218\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.199\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.66it/s]\n",
      "Prediction time:  0:00:05.741361\n",
      "363  \t  421  \t  63\n",
      "Test P:  0.174\n",
      "Test R:  0.15\n",
      "Test F1:  0.161\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  24\n",
      "100%|| 63/63 [00:22<00:00,  2.82it/s]\n",
      "Training loss:  0.8976649826481229\n",
      "Training time:  0:00:22.375505\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.131659\n",
      "355  \t  426  \t  74\n",
      "Dev P:  0.208\n",
      "Dev R:  0.174\n",
      "Dev F1:  0.19\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.67it/s]\n",
      "Prediction time:  0:00:05.728351\n",
      "358  \t  421  \t  61\n",
      "Test P:  0.17\n",
      "Test R:  0.145\n",
      "Test F1:  0.157\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  25\n",
      "100%|| 63/63 [00:22<00:00,  2.83it/s]\n",
      "Training loss:  0.9400490427774096\n",
      "Training time:  0:00:22.226595\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.42it/s]\n",
      "Prediction time:  0:00:06.132067\n",
      "378  \t  426  \t  82\n",
      "Dev P:  0.217\n",
      "Dev R:  0.192\n",
      "Dev F1:  0.204\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.65it/s]\n",
      "Prediction time:  0:00:05.760536\n",
      "376  \t  421  \t  71\n",
      "Test P:  0.189\n",
      "Test R:  0.169\n",
      "Test F1:  0.178\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  26\n",
      "100%|| 63/63 [00:22<00:00,  2.78it/s]\n",
      "Training loss:  0.8195524128183486\n",
      "Training time:  0:00:22.627586\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.123912\n",
      "360  \t  426  \t  80\n",
      "Dev P:  0.222\n",
      "Dev R:  0.188\n",
      "Dev F1:  0.204\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.68it/s]\n",
      "Prediction time:  0:00:05.713096\n",
      "366  \t  421  \t  66\n",
      "Test P:  0.18\n",
      "Test R:  0.157\n",
      "Test F1:  0.168\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  27\n",
      "100%|| 63/63 [00:22<00:00,  2.78it/s]\n",
      "Training loss:  0.7772441302973127\n",
      "Training time:  0:00:22.640313\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.45it/s]\n",
      "Prediction time:  0:00:06.094968\n",
      "350  \t  426  \t  76\n",
      "Dev P:  0.217\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.196\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.68it/s]\n",
      "Prediction time:  0:00:05.700871\n",
      "359  \t  421  \t  68\n",
      "Test P:  0.189\n",
      "Test R:  0.162\n",
      "Test F1:  0.174\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  28\n",
      "100%|| 63/63 [00:22<00:00,  2.81it/s]\n",
      "Training loss:  0.8195510667467875\n",
      "Training time:  0:00:22.415165\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.44it/s]\n",
      "Prediction time:  0:00:06.103153\n",
      "342  \t  426  \t  76\n",
      "Dev P:  0.222\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.198\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.68it/s]\n",
      "Prediction time:  0:00:05.712019\n",
      "350  \t  421  \t  60\n",
      "Test P:  0.171\n",
      "Test R:  0.143\n",
      "Test F1:  0.156\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  29\n",
      "100%|| 63/63 [00:22<00:00,  2.85it/s]\n",
      "Training loss:  0.6975351806197848\n",
      "Training time:  0:00:22.139995\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.43it/s]\n",
      "Prediction time:  0:00:06.114356\n",
      "361  \t  426  \t  84\n",
      "Dev P:  0.233\n",
      "Dev R:  0.197\n",
      "Dev F1:  0.213\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.66it/s]\n",
      "Prediction time:  0:00:05.735333\n",
      "372  \t  421  \t  71\n",
      "Test P:  0.191\n",
      "Test R:  0.169\n",
      "Test F1:  0.179\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  30\n",
      "100%|| 63/63 [00:22<00:00,  2.80it/s]\n",
      "Training loss:  0.6681186755498251\n",
      "Training time:  0:00:22.485758\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.42it/s]\n",
      "Prediction time:  0:00:06.144802\n",
      "362  \t  426  \t  79\n",
      "Dev P:  0.218\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.201\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.65it/s]\n",
      "Prediction time:  0:00:05.748211\n",
      "376  \t  421  \t  64\n",
      "Test P:  0.17\n",
      "Test R:  0.152\n",
      "Test F1:  0.161\n",
      "\n",
      "\n",
      "\n",
      "*******\n",
      "Best Epoch:  29\n",
      "Best Epoch Seed:  71\n",
      "Corresponding P:  0.191\n",
      "Corresponding R:  0.169\n",
      "Corresponding F1:  0.179\n",
      "\n",
      "\n",
      "\n",
      "Best Test Epoch:  17\n",
      "Corresponding P:  0.21\n",
      "Corresponding R:  0.164\n",
      "Corresponding F1:  0.184\n",
      "\n",
      "\n",
      "\n",
      "Test size: 322\n",
      "Re-checking the scores of entire Test data with the best saved model:\n",
      "Total sentences in the test set:  322\n",
      "GT Triple Count:  421  \tPRED Triple Count:  372  \tCORRECT Triple Count:  71\n",
      "Test P:  0.191\n",
      "Test R:  0.169\n",
      "Test F1:  0.179\n",
      "Now printing the scores for various subsets of Test Data with the best saved model:\n",
      "Total sentences with single triples:  243\n",
      "GT Triple Count:  243  \tPRED Triple Count:  263  \tCORRECT Triple Count:  47\n",
      "Test P:  0.179\n",
      "Test R:  0.193\n",
      "Test F1:  0.186\n",
      "Total sentences with multiple triples:  79\n",
      "GT Triple Count:  178  \tPRED Triple Count:  109  \tCORRECT Triple Count:  24\n",
      "Test P:  0.22\n",
      "Test R:  0.135\n",
      "Test F1:  0.167\n",
      "Total sentences triples with varying sentiments:  31\n",
      "GT Triple Count:  79  \tPRED Triple Count:  43  \tCORRECT Triple Count:  8\n",
      "Test P:  0.186\n",
      "Test R:  0.101\n",
      "Test F1:  0.131\n",
      "Total sentences with overlapping triples:  42\n",
      "GT Triple Count:  95  \tPRED Triple Count:  53  \tCORRECT Triple Count:  9\n",
      "Test P:  0.17\n",
      "Test R:  0.095\n",
      "Test F1:  0.122\n"
     ]
    }
   ],
   "source": [
    "!python3 PASTE_BERT.py --gpu_id 0 --src_folder mpqa/ --trg_folder mpqa/PASTE_BERT --bert_mode gen --gen_direct of --l2 y --wd 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14fcbb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/shivam/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/shivam/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/shivam/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "enc_hidden_size: 818\n",
      "dec_inp_size: 818\n",
      "dec_hidden_size: 818\n",
      "pointer_net_hidden_size: 300\n",
      "['PASTE_BERT.py', '--gpu_id', '0', '--src_folder', 'mpqa/', '--trg_folder', 'mpqa/PASTE_BERT', '--bert_mode', 'gen', '--gen_direct', 'of', '--l2', 'y', '--wd', '1e-5', '--use_pos_tags', 'y']\n",
      "100  10  0.5\n",
      "BERT\n",
      "loading data......\n",
      "No. of sentences:  996\n",
      "No. of lines in Target file:  996\n",
      "No. of lines in POS file:  996\n",
      "No. of lines in DEP file:  996\n",
      "No. of sentences:  323\n",
      "No. of lines in Target file:  323\n",
      "No. of lines in POS file:  323\n",
      "No. of lines in DEP file:  323\n",
      "No. of sentences:  322\n",
      "No. of lines in Target file:  322\n",
      "No. of lines in POS file:  322\n",
      "No. of lines in DEP file:  322\n",
      "Training data size:  994\n",
      "Development data size:  323\n",
      "Test data size:  322\n",
      "Building POS TAG Vocab..\n",
      "Building DEP TAG Vocab..\n",
      "Training started......\n",
      "Batch Count:   63\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_attentions\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/shivam/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Parameters size:  129772009\n",
      "weight factor:  1\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 1e-05\n",
      ")\n",
      "Epoch:  1\n",
      "  0%|                                                    | 0/63 [00:00<?, ?it/s]/home/shivam/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2251: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  9.831539479513017\n",
      "Training time:  0:00:23.602483\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.256839\n",
      "327  \t  426  \t  53\n",
      "Dev P:  0.162\n",
      "Dev R:  0.124\n",
      "Dev F1:  0.141\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.61it/s]\n",
      "Prediction time:  0:00:05.820412\n",
      "323  \t  421  \t  39\n",
      "Test P:  0.121\n",
      "Test R:  0.093\n",
      "Test F1:  0.105\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  2\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  7.125585593874493\n",
      "Training time:  0:00:23.632135\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.261275\n",
      "323  \t  426  \t  62\n",
      "Dev P:  0.192\n",
      "Dev R:  0.146\n",
      "Dev F1:  0.166\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.842720\n",
      "322  \t  421  \t  50\n",
      "Test P:  0.155\n",
      "Test R:  0.119\n",
      "Test F1:  0.135\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  3\n",
      "100%|| 63/63 [00:23<00:00,  2.71it/s]\n",
      "Training loss:  6.344318624526736\n",
      "Training time:  0:00:23.250870\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.269319\n",
      "323  \t  426  \t  62\n",
      "Dev P:  0.192\n",
      "Dev R:  0.146\n",
      "Dev F1:  0.166\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.833014\n",
      "322  \t  421  \t  49\n",
      "Test P:  0.152\n",
      "Test R:  0.116\n",
      "Test F1:  0.132\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  4\n",
      "100%|| 63/63 [00:23<00:00,  2.72it/s]\n",
      "Training loss:  5.6919974069746715\n",
      "Training time:  0:00:23.164489\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.256500\n",
      "331  \t  426  \t  63\n",
      "Dev P:  0.19\n",
      "Dev R:  0.148\n",
      "Dev F1:  0.166\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.828303\n",
      "332  \t  421  \t  54\n",
      "Test P:  0.163\n",
      "Test R:  0.128\n",
      "Test F1:  0.143\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:23<00:00,  2.71it/s]\n",
      "Training loss:  5.2332673451257135\n",
      "Training time:  0:00:23.270714\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.262762\n",
      "363  \t  426  \t  78\n",
      "Dev P:  0.215\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.198\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.846083\n",
      "360  \t  421  \t  54\n",
      "Test P:  0.15\n",
      "Test R:  0.128\n",
      "Test F1:  0.138\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  6\n",
      "100%|| 63/63 [00:23<00:00,  2.69it/s]\n",
      "Training loss:  4.578803263013325\n",
      "Training time:  0:00:23.446643\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.258243\n",
      "395  \t  426  \t  82\n",
      "Dev P:  0.208\n",
      "Dev R:  0.192\n",
      "Dev F1:  0.2\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.848865\n",
      "388  \t  421  \t  65\n",
      "Test P:  0.168\n",
      "Test R:  0.154\n",
      "Test F1:  0.161\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  7\n",
      "100%|| 63/63 [00:23<00:00,  2.65it/s]\n",
      "Training loss:  4.232296383570111\n",
      "Training time:  0:00:23.756709\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.308018\n",
      "341  \t  426  \t  75\n",
      "Dev P:  0.22\n",
      "Dev R:  0.176\n",
      "Dev F1:  0.196\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.876943\n",
      "343  \t  421  \t  60\n",
      "Test P:  0.175\n",
      "Test R:  0.143\n",
      "Test F1:  0.157\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  8\n",
      "100%|| 63/63 [00:23<00:00,  2.69it/s]\n",
      "Training loss:  3.652197143388173\n",
      "Training time:  0:00:23.419551\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.37it/s]\n",
      "Prediction time:  0:00:06.235377\n",
      "355  \t  426  \t  87\n",
      "Dev P:  0.245\n",
      "Dev R:  0.204\n",
      "Dev F1:  0.223\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.834760\n",
      "352  \t  421  \t  66\n",
      "Test P:  0.187\n",
      "Test R:  0.157\n",
      "Test F1:  0.171\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  9\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  3.32992746905675\n",
      "Training time:  0:00:23.497903\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.274691\n",
      "334  \t  426  \t  81\n",
      "Dev P:  0.243\n",
      "Dev R:  0.19\n",
      "Dev F1:  0.213\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.846208\n",
      "339  \t  421  \t  60\n",
      "Test P:  0.177\n",
      "Test R:  0.143\n",
      "Test F1:  0.158\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  10\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  2.7678162427175614\n",
      "Training time:  0:00:23.581400\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.279921\n",
      "395  \t  426  \t  88\n",
      "Dev P:  0.223\n",
      "Dev R:  0.207\n",
      "Dev F1:  0.214\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.849815\n",
      "390  \t  421  \t  64\n",
      "Test P:  0.164\n",
      "Test R:  0.152\n",
      "Test F1:  0.158\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  11\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  2.550978290656256\n",
      "Training time:  0:00:23.481401\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.278006\n",
      "380  \t  426  \t  79\n",
      "Dev P:  0.208\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.196\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.859075\n",
      "380  \t  421  \t  70\n",
      "Test P:  0.184\n",
      "Test R:  0.166\n",
      "Test F1:  0.175\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  12\n",
      "100%|| 63/63 [00:23<00:00,  2.70it/s]\n",
      "Training loss:  2.366957015461392\n",
      "Training time:  0:00:23.301265\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.296662\n",
      "335  \t  426  \t  72\n",
      "Dev P:  0.215\n",
      "Dev R:  0.169\n",
      "Dev F1:  0.189\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.868246\n",
      "335  \t  421  \t  62\n",
      "Test P:  0.185\n",
      "Test R:  0.147\n",
      "Test F1:  0.164\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  13\n",
      "100%|| 63/63 [00:23<00:00,  2.63it/s]\n",
      "Training loss:  2.202803274941823\n",
      "Training time:  0:00:23.940746\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.309222\n",
      "355  \t  426  \t  80\n",
      "Dev P:  0.225\n",
      "Dev R:  0.188\n",
      "Dev F1:  0.205\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.869287\n",
      "365  \t  421  \t  65\n",
      "Test P:  0.178\n",
      "Test R:  0.154\n",
      "Test F1:  0.165\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  14\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  1.9547587737204537\n",
      "Training time:  0:00:23.560540\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.287556\n",
      "355  \t  426  \t  75\n",
      "Dev P:  0.211\n",
      "Dev R:  0.176\n",
      "Dev F1:  0.192\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.845586\n",
      "365  \t  421  \t  66\n",
      "Test P:  0.181\n",
      "Test R:  0.157\n",
      "Test F1:  0.168\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  15\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  1.829797975600712\n",
      "Training time:  0:00:23.596572\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.260181\n",
      "366  \t  426  \t  76\n",
      "Dev P:  0.208\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.192\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.826580\n",
      "366  \t  421  \t  63\n",
      "Test P:  0.172\n",
      "Test R:  0.15\n",
      "Test F1:  0.16\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  16\n",
      "100%|| 63/63 [00:23<00:00,  2.64it/s]\n",
      "Training loss:  1.6402256356345282\n",
      "Training time:  0:00:23.890690\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.267817\n",
      "378  \t  426  \t  82\n",
      "Dev P:  0.217\n",
      "Dev R:  0.192\n",
      "Dev F1:  0.204\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.840406\n",
      "385  \t  421  \t  61\n",
      "Test P:  0.158\n",
      "Test R:  0.145\n",
      "Test F1:  0.151\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  17\n",
      "100%|| 63/63 [00:23<00:00,  2.70it/s]\n",
      "Training loss:  1.501509822550274\n",
      "Training time:  0:00:23.305141\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.267413\n",
      "343  \t  426  \t  78\n",
      "Dev P:  0.227\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.203\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.848964\n",
      "344  \t  421  \t  65\n",
      "Test P:  0.189\n",
      "Test R:  0.154\n",
      "Test F1:  0.17\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  18\n",
      "100%|| 63/63 [00:23<00:00,  2.66it/s]\n",
      "Training loss:  1.4231535669357058\n",
      "Training time:  0:00:23.711044\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.280877\n",
      "367  \t  426  \t  86\n",
      "Dev P:  0.234\n",
      "Dev R:  0.202\n",
      "Dev F1:  0.217\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.850043\n",
      "368  \t  421  \t  63\n",
      "Test P:  0.171\n",
      "Test R:  0.15\n",
      "Test F1:  0.16\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  19\n",
      "100%|| 63/63 [00:23<00:00,  2.65it/s]\n",
      "Training loss:  1.3431675869321067\n",
      "Training time:  0:00:23.747559\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.299962\n",
      "350  \t  426  \t  79\n",
      "Dev P:  0.226\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.204\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.849626\n",
      "351  \t  421  \t  60\n",
      "Test P:  0.171\n",
      "Test R:  0.143\n",
      "Test F1:  0.155\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  1.2469784068682837\n",
      "Training time:  0:00:23.508272\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.277791\n",
      "330  \t  426  \t  75\n",
      "Dev P:  0.227\n",
      "Dev R:  0.176\n",
      "Dev F1:  0.198\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.870081\n",
      "337  \t  421  \t  64\n",
      "Test P:  0.19\n",
      "Test R:  0.152\n",
      "Test F1:  0.169\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  21\n",
      "100%|| 63/63 [00:23<00:00,  2.73it/s]\n",
      "Training loss:  1.1998551525766887\n",
      "Training time:  0:00:23.081019\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.266419\n",
      "379  \t  426  \t  77\n",
      "Dev P:  0.203\n",
      "Dev R:  0.181\n",
      "Dev F1:  0.191\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.836326\n",
      "370  \t  421  \t  73\n",
      "Test P:  0.197\n",
      "Test R:  0.173\n",
      "Test F1:  0.185\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  22\n",
      "100%|| 63/63 [00:23<00:00,  2.69it/s]\n",
      "Training loss:  1.1655490625472296\n",
      "Training time:  0:00:23.384884\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.271219\n",
      "345  \t  426  \t  71\n",
      "Dev P:  0.206\n",
      "Dev R:  0.167\n",
      "Dev F1:  0.184\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.850350\n",
      "344  \t  421  \t  66\n",
      "Test P:  0.192\n",
      "Test R:  0.157\n",
      "Test F1:  0.173\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  23\n",
      "100%|| 63/63 [00:23<00:00,  2.70it/s]\n",
      "Training loss:  1.0090527714244903\n",
      "Training time:  0:00:23.347334\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.296984\n",
      "381  \t  426  \t  86\n",
      "Dev P:  0.226\n",
      "Dev R:  0.202\n",
      "Dev F1:  0.213\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.856084\n",
      "394  \t  421  \t  65\n",
      "Test P:  0.165\n",
      "Test R:  0.154\n",
      "Test F1:  0.16\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  24\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  1.0385042041067094\n",
      "Training time:  0:00:23.594411\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.281584\n",
      "350  \t  426  \t  81\n",
      "Dev P:  0.231\n",
      "Dev R:  0.19\n",
      "Dev F1:  0.209\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.859773\n",
      "353  \t  421  \t  61\n",
      "Test P:  0.173\n",
      "Test R:  0.145\n",
      "Test F1:  0.158\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  25\n",
      "100%|| 63/63 [00:23<00:00,  2.69it/s]\n",
      "Training loss:  0.9973530017194294\n",
      "Training time:  0:00:23.398755\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.245922\n",
      "353  \t  426  \t  79\n",
      "Dev P:  0.224\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.203\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.835545\n",
      "355  \t  421  \t  72\n",
      "Test P:  0.203\n",
      "Test R:  0.171\n",
      "Test F1:  0.186\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  26\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  0.993091515132359\n",
      "Training time:  0:00:23.625065\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.250112\n",
      "356  \t  426  \t  76\n",
      "Dev P:  0.213\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.194\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.62it/s]\n",
      "Prediction time:  0:00:05.809021\n",
      "354  \t  421  \t  60\n",
      "Test P:  0.169\n",
      "Test R:  0.143\n",
      "Test F1:  0.155\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  27\n",
      "100%|| 63/63 [00:23<00:00,  2.64it/s]\n",
      "Training loss:  0.8888603425215161\n",
      "Training time:  0:00:23.831087\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.270259\n",
      "353  \t  426  \t  79\n",
      "Dev P:  0.224\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.203\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.838070\n",
      "365  \t  421  \t  68\n",
      "Test P:  0.186\n",
      "Test R:  0.162\n",
      "Test F1:  0.173\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  28\n",
      "100%|| 63/63 [00:23<00:00,  2.66it/s]\n",
      "Training loss:  0.7407730850908492\n",
      "Training time:  0:00:23.703170\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.280240\n",
      "344  \t  426  \t  73\n",
      "Dev P:  0.212\n",
      "Dev R:  0.171\n",
      "Dev F1:  0.19\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.860139\n",
      "352  \t  421  \t  68\n",
      "Test P:  0.193\n",
      "Test R:  0.162\n",
      "Test F1:  0.176\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  29\n",
      "100%|| 63/63 [00:23<00:00,  2.70it/s]\n",
      "Training loss:  0.728920096442813\n",
      "Training time:  0:00:23.351271\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.263953\n",
      "352  \t  426  \t  79\n",
      "Dev P:  0.224\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.203\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.61it/s]\n",
      "Prediction time:  0:00:05.821588\n",
      "358  \t  421  \t  70\n",
      "Test P:  0.196\n",
      "Test R:  0.166\n",
      "Test F1:  0.18\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  30\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  0.6936244671306913\n",
      "Training time:  0:00:23.517476\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.296167\n",
      "362  \t  426  \t  84\n",
      "Dev P:  0.232\n",
      "Dev R:  0.197\n",
      "Dev F1:  0.213\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.863321\n",
      "364  \t  421  \t  62\n",
      "Test P:  0.17\n",
      "Test R:  0.147\n",
      "Test F1:  0.158\n",
      "\n",
      "\n",
      "\n",
      "*******\n",
      "Best Epoch:  8\n",
      "Best Epoch Seed:  50\n",
      "Corresponding P:  0.187\n",
      "Corresponding R:  0.157\n",
      "Corresponding F1:  0.171\n",
      "\n",
      "\n",
      "\n",
      "Best Test Epoch:  25\n",
      "Corresponding P:  0.203\n",
      "Corresponding R:  0.171\n",
      "Corresponding F1:  0.186\n",
      "\n",
      "\n",
      "\n",
      "Test size: 322\n",
      "Re-checking the scores of entire Test data with the best saved model:\n",
      "Total sentences in the test set:  322\n",
      "GT Triple Count:  421  \tPRED Triple Count:  352  \tCORRECT Triple Count:  66\n",
      "Test P:  0.187\n",
      "Test R:  0.157\n",
      "Test F1:  0.171\n",
      "Now printing the scores for various subsets of Test Data with the best saved model:\n",
      "Total sentences with single triples:  243\n",
      "GT Triple Count:  243  \tPRED Triple Count:  256  \tCORRECT Triple Count:  49\n",
      "Test P:  0.191\n",
      "Test R:  0.202\n",
      "Test F1:  0.196\n",
      "Total sentences with multiple triples:  79\n",
      "GT Triple Count:  178  \tPRED Triple Count:  96  \tCORRECT Triple Count:  17\n",
      "Test P:  0.177\n",
      "Test R:  0.096\n",
      "Test F1:  0.124\n",
      "Total sentences triples with varying sentiments:  31\n",
      "GT Triple Count:  79  \tPRED Triple Count:  35  \tCORRECT Triple Count:  3\n",
      "Test P:  0.086\n",
      "Test R:  0.038\n",
      "Test F1:  0.053\n",
      "Total sentences with overlapping triples:  42\n",
      "GT Triple Count:  95  \tPRED Triple Count:  47  \tCORRECT Triple Count:  4\n",
      "Test P:  0.085\n",
      "Test R:  0.042\n",
      "Test F1:  0.056\n"
     ]
    }
   ],
   "source": [
    "!python3 PASTE_BERT.py --gpu_id 0 --src_folder mpqa/ --trg_folder mpqa/PASTE_BERT --bert_mode gen --gen_direct of --l2 y --wd 1e-5 --use_pos_tags y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "774536ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/shivam/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/shivam/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/shivam/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "enc_hidden_size: 818\n",
      "dec_inp_size: 818\n",
      "dec_hidden_size: 818\n",
      "pointer_net_hidden_size: 300\n",
      "['PASTE_BERT.py', '--gpu_id', '0', '--src_folder', 'mpqa/', '--trg_folder', 'mpqa/PASTE_BERT', '--bert_mode', 'gen', '--gen_direct', 'of', '--l2', 'y', '--wd', '1e-5', '--use_dep_emb', 'y']\n",
      "100  10  0.5\n",
      "BERT\n",
      "loading data......\n",
      "No. of sentences:  996\n",
      "No. of lines in Target file:  996\n",
      "No. of lines in POS file:  996\n",
      "No. of lines in DEP file:  996\n",
      "No. of sentences:  323\n",
      "No. of lines in Target file:  323\n",
      "No. of lines in POS file:  323\n",
      "No. of lines in DEP file:  323\n",
      "No. of sentences:  322\n",
      "No. of lines in Target file:  322\n",
      "No. of lines in POS file:  322\n",
      "No. of lines in DEP file:  322\n",
      "Training data size:  994\n",
      "Development data size:  323\n",
      "Test data size:  322\n",
      "Building POS TAG Vocab..\n",
      "Building DEP TAG Vocab..\n",
      "Training started......\n",
      "Batch Count:   63\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_attentions\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/shivam/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Parameters size:  129771609\n",
      "weight factor:  1\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 1e-05\n",
      ")\n",
      "Epoch:  1\n",
      "  0%|                                                    | 0/63 [00:00<?, ?it/s]/home/shivam/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2251: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|| 63/63 [00:23<00:00,  2.66it/s]\n",
      "Training loss:  9.758240336463565\n",
      "Training time:  0:00:23.717469\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.245456\n",
      "323  \t  426  \t  54\n",
      "Dev P:  0.167\n",
      "Dev R:  0.127\n",
      "Dev F1:  0.144\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.826760\n",
      "322  \t  421  \t  44\n",
      "Test P:  0.137\n",
      "Test R:  0.105\n",
      "Test F1:  0.118\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  2\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  7.025708887312147\n",
      "Training time:  0:00:23.610725\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.302310\n",
      "323  \t  426  \t  62\n",
      "Dev P:  0.192\n",
      "Dev R:  0.146\n",
      "Dev F1:  0.166\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.867802\n",
      "322  \t  421  \t  49\n",
      "Test P:  0.152\n",
      "Test R:  0.116\n",
      "Test F1:  0.132\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  3\n",
      "100%|| 63/63 [00:23<00:00,  2.69it/s]\n",
      "Training loss:  6.355550221034458\n",
      "Training time:  0:00:23.404786\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.259479\n",
      "323  \t  426  \t  60\n",
      "Dev P:  0.186\n",
      "Dev R:  0.141\n",
      "Dev F1:  0.16\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.829534\n",
      "323  \t  421  \t  51\n",
      "Test P:  0.158\n",
      "Test R:  0.121\n",
      "Test F1:  0.137\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  4\n",
      "100%|| 63/63 [00:23<00:00,  2.72it/s]\n",
      "Training loss:  5.6796236076052224\n",
      "Training time:  0:00:23.129170\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.251936\n",
      "329  \t  426  \t  70\n",
      "Dev P:  0.213\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.185\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.852702\n",
      "327  \t  421  \t  54\n",
      "Test P:  0.165\n",
      "Test R:  0.128\n",
      "Test F1:  0.144\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:23<00:00,  2.71it/s]\n",
      "Training loss:  5.122140464328584\n",
      "Training time:  0:00:23.238725\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.304812\n",
      "352  \t  426  \t  68\n",
      "Dev P:  0.193\n",
      "Dev R:  0.16\n",
      "Dev F1:  0.175\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.861354\n",
      "348  \t  421  \t  62\n",
      "Test P:  0.178\n",
      "Test R:  0.147\n",
      "Test F1:  0.161\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  6\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  4.510808914426773\n",
      "Training time:  0:00:23.616244\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.276856\n",
      "389  \t  426  \t  79\n",
      "Dev P:  0.203\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.194\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.868217\n",
      "385  \t  421  \t  63\n",
      "Test P:  0.164\n",
      "Test R:  0.15\n",
      "Test F1:  0.156\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  7\n",
      "100%|| 63/63 [00:23<00:00,  2.64it/s]\n",
      "Training loss:  4.1879744794633655\n",
      "Training time:  0:00:23.822791\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.31it/s]\n",
      "Prediction time:  0:00:06.346993\n",
      "343  \t  426  \t  79\n",
      "Dev P:  0.23\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.205\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:07<00:00,  2.69it/s]\n",
      "Prediction time:  0:00:07.793770\n",
      "339  \t  421  \t  62\n",
      "Test P:  0.183\n",
      "Test R:  0.147\n",
      "Test F1:  0.163\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  8\n",
      "100%|| 63/63 [00:27<00:00,  2.26it/s]\n",
      "Training loss:  3.604340125644018\n",
      "Training time:  0:00:27.859195\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.264606\n",
      "379  \t  426  \t  78\n",
      "Dev P:  0.206\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.194\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.843289\n",
      "371  \t  421  \t  64\n",
      "Test P:  0.173\n",
      "Test R:  0.152\n",
      "Test F1:  0.162\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  9\n",
      "100%|| 63/63 [00:23<00:00,  2.71it/s]\n",
      "Training loss:  3.234950029660785\n",
      "Training time:  0:00:23.255944\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.243759\n",
      "347  \t  426  \t  83\n",
      "Dev P:  0.239\n",
      "Dev R:  0.195\n",
      "Dev F1:  0.215\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.60it/s]\n",
      "Prediction time:  0:00:05.829649\n",
      "350  \t  421  \t  63\n",
      "Test P:  0.18\n",
      "Test R:  0.15\n",
      "Test F1:  0.163\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  10\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  2.8822493288252087\n",
      "Training time:  0:00:23.603612\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.284369\n",
      "352  \t  426  \t  76\n",
      "Dev P:  0.216\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.195\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.858421\n",
      "345  \t  421  \t  64\n",
      "Test P:  0.186\n",
      "Test R:  0.152\n",
      "Test F1:  0.167\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  11\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  2.4984343260053605\n",
      "Training time:  0:00:23.540539\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.36it/s]\n",
      "Prediction time:  0:00:06.259059\n",
      "357  \t  426  \t  79\n",
      "Dev P:  0.221\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.202\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.850689\n",
      "362  \t  421  \t  64\n",
      "Test P:  0.177\n",
      "Test R:  0.152\n",
      "Test F1:  0.163\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  12\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  2.230617029326303\n",
      "Training time:  0:00:23.526328\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.270948\n",
      "335  \t  426  \t  71\n",
      "Dev P:  0.212\n",
      "Dev R:  0.167\n",
      "Dev F1:  0.187\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.861525\n",
      "340  \t  421  \t  61\n",
      "Test P:  0.179\n",
      "Test R:  0.145\n",
      "Test F1:  0.16\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  13\n",
      "100%|| 63/63 [00:23<00:00,  2.64it/s]\n",
      "Training loss:  2.159587998238821\n",
      "Training time:  0:00:23.860418\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.300818\n",
      "344  \t  426  \t  72\n",
      "Dev P:  0.209\n",
      "Dev R:  0.169\n",
      "Dev F1:  0.187\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.881014\n",
      "348  \t  421  \t  64\n",
      "Test P:  0.184\n",
      "Test R:  0.152\n",
      "Test F1:  0.166\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  14\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  1.946135245618366\n",
      "Training time:  0:00:23.467526\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.299678\n",
      "336  \t  426  \t  71\n",
      "Dev P:  0.211\n",
      "Dev R:  0.167\n",
      "Dev F1:  0.186\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.868051\n",
      "333  \t  421  \t  64\n",
      "Test P:  0.192\n",
      "Test R:  0.152\n",
      "Test F1:  0.17\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  15\n",
      "100%|| 63/63 [00:23<00:00,  2.65it/s]\n",
      "Training loss:  1.7494504697739133\n",
      "Training time:  0:00:23.788260\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.310517\n",
      "360  \t  426  \t  81\n",
      "Dev P:  0.225\n",
      "Dev R:  0.19\n",
      "Dev F1:  0.206\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.884854\n",
      "362  \t  421  \t  69\n",
      "Test P:  0.191\n",
      "Test R:  0.164\n",
      "Test F1:  0.176\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  16\n",
      "100%|| 63/63 [00:24<00:00,  2.62it/s]\n",
      "Training loss:  1.615557366893405\n",
      "Training time:  0:00:24.021905\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.319237\n",
      "374  \t  426  \t  83\n",
      "Dev P:  0.222\n",
      "Dev R:  0.195\n",
      "Dev F1:  0.207\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.56it/s]\n",
      "Prediction time:  0:00:05.898438\n",
      "376  \t  421  \t  77\n",
      "Test P:  0.205\n",
      "Test R:  0.183\n",
      "Test F1:  0.193\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  17\n",
      "100%|| 63/63 [00:23<00:00,  2.70it/s]\n",
      "Training loss:  1.4657528466648526\n",
      "Training time:  0:00:23.350197\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.31it/s]\n",
      "Prediction time:  0:00:06.337294\n",
      "358  \t  426  \t  85\n",
      "Dev P:  0.237\n",
      "Dev R:  0.2\n",
      "Dev F1:  0.217\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.56it/s]\n",
      "Prediction time:  0:00:05.905496\n",
      "359  \t  421  \t  67\n",
      "Test P:  0.187\n",
      "Test R:  0.159\n",
      "Test F1:  0.172\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  18\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  1.3736851414044697\n",
      "Training time:  0:00:23.597688\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.300784\n",
      "363  \t  426  \t  82\n",
      "Dev P:  0.226\n",
      "Dev R:  0.192\n",
      "Dev F1:  0.208\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.882724\n",
      "373  \t  421  \t  71\n",
      "Test P:  0.19\n",
      "Test R:  0.169\n",
      "Test F1:  0.179\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  19\n",
      "100%|| 63/63 [00:23<00:00,  2.65it/s]\n",
      "Training loss:  1.2782898147900899\n",
      "Training time:  0:00:23.731391\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.35it/s]\n",
      "Prediction time:  0:00:06.273646\n",
      "352  \t  426  \t  87\n",
      "Dev P:  0.247\n",
      "Dev R:  0.204\n",
      "Dev F1:  0.224\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.851102\n",
      "362  \t  421  \t  65\n",
      "Test P:  0.18\n",
      "Test R:  0.154\n",
      "Test F1:  0.166\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  1.2010914196097662\n",
      "Training time:  0:00:23.516382\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.315546\n",
      "342  \t  426  \t  80\n",
      "Dev P:  0.234\n",
      "Dev R:  0.188\n",
      "Dev F1:  0.208\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.890819\n",
      "346  \t  421  \t  58\n",
      "Test P:  0.168\n",
      "Test R:  0.138\n",
      "Test F1:  0.151\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  21\n",
      "100%|| 63/63 [00:23<00:00,  2.69it/s]\n",
      "Training loss:  1.072557772908892\n",
      "Training time:  0:00:23.391939\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.280076\n",
      "374  \t  426  \t  77\n",
      "Dev P:  0.206\n",
      "Dev R:  0.181\n",
      "Dev F1:  0.192\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.59it/s]\n",
      "Prediction time:  0:00:05.851725\n",
      "380  \t  421  \t  68\n",
      "Test P:  0.179\n",
      "Test R:  0.162\n",
      "Test F1:  0.17\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  22\n",
      "100%|| 63/63 [00:23<00:00,  2.68it/s]\n",
      "Training loss:  1.081939083716226\n",
      "Training time:  0:00:23.500157\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.302142\n",
      "354  \t  426  \t  77\n",
      "Dev P:  0.218\n",
      "Dev R:  0.181\n",
      "Dev F1:  0.197\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.873245\n",
      "364  \t  421  \t  65\n",
      "Test P:  0.179\n",
      "Test R:  0.154\n",
      "Test F1:  0.166\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  23\n",
      "100%|| 63/63 [00:23<00:00,  2.71it/s]\n",
      "Training loss:  1.0831069823295352\n",
      "Training time:  0:00:23.239192\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.293061\n",
      "356  \t  426  \t  82\n",
      "Dev P:  0.23\n",
      "Dev R:  0.192\n",
      "Dev F1:  0.21\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.878957\n",
      "351  \t  421  \t  62\n",
      "Test P:  0.177\n",
      "Test R:  0.147\n",
      "Test F1:  0.161\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  24\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  0.989457298838903\n",
      "Training time:  0:00:23.596714\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.325685\n",
      "374  \t  426  \t  82\n",
      "Dev P:  0.219\n",
      "Dev R:  0.192\n",
      "Dev F1:  0.205\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.873933\n",
      "386  \t  421  \t  66\n",
      "Test P:  0.171\n",
      "Test R:  0.157\n",
      "Test F1:  0.164\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  25\n",
      "100%|| 63/63 [00:23<00:00,  2.69it/s]\n",
      "Training loss:  0.9798825444683196\n",
      "Training time:  0:00:23.437163\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.302596\n",
      "354  \t  426  \t  74\n",
      "Dev P:  0.209\n",
      "Dev R:  0.174\n",
      "Dev F1:  0.19\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.876495\n",
      "358  \t  421  \t  67\n",
      "Test P:  0.187\n",
      "Test R:  0.159\n",
      "Test F1:  0.172\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  26\n",
      "100%|| 63/63 [00:23<00:00,  2.65it/s]\n",
      "Training loss:  0.8137127035667026\n",
      "Training time:  0:00:23.813892\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.32it/s]\n",
      "Prediction time:  0:00:06.333761\n",
      "388  \t  426  \t  81\n",
      "Dev P:  0.209\n",
      "Dev R:  0.19\n",
      "Dev F1:  0.199\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.56it/s]\n",
      "Prediction time:  0:00:05.906208\n",
      "374  \t  421  \t  68\n",
      "Test P:  0.182\n",
      "Test R:  0.162\n",
      "Test F1:  0.171\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  27\n",
      "100%|| 63/63 [00:23<00:00,  2.64it/s]\n",
      "Training loss:  0.7971463269657559\n",
      "Training time:  0:00:23.893238\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.284605\n",
      "356  \t  426  \t  79\n",
      "Dev P:  0.222\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.202\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.859027\n",
      "357  \t  421  \t  61\n",
      "Test P:  0.171\n",
      "Test R:  0.145\n",
      "Test F1:  0.157\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  28\n",
      "100%|| 63/63 [00:23<00:00,  2.66it/s]\n",
      "Training loss:  0.8448471149045323\n",
      "Training time:  0:00:23.640290\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.313715\n",
      "373  \t  426  \t  85\n",
      "Dev P:  0.228\n",
      "Dev R:  0.2\n",
      "Dev F1:  0.213\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.873911\n",
      "364  \t  421  \t  70\n",
      "Test P:  0.192\n",
      "Test R:  0.166\n",
      "Test F1:  0.178\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  29\n",
      "100%|| 63/63 [00:23<00:00,  2.69it/s]\n",
      "Training loss:  0.8355294253144946\n",
      "Training time:  0:00:23.426074\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.34it/s]\n",
      "Prediction time:  0:00:06.286062\n",
      "347  \t  426  \t  82\n",
      "Dev P:  0.236\n",
      "Dev R:  0.192\n",
      "Dev F1:  0.212\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.57it/s]\n",
      "Prediction time:  0:00:05.877794\n",
      "347  \t  421  \t  64\n",
      "Test P:  0.184\n",
      "Test R:  0.152\n",
      "Test F1:  0.167\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  30\n",
      "100%|| 63/63 [00:23<00:00,  2.67it/s]\n",
      "Training loss:  0.855417493789915\n",
      "Training time:  0:00:23.585652\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.33it/s]\n",
      "Prediction time:  0:00:06.298961\n",
      "370  \t  426  \t  75\n",
      "Dev P:  0.203\n",
      "Dev R:  0.176\n",
      "Dev F1:  0.188\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.58it/s]\n",
      "Prediction time:  0:00:05.864568\n",
      "375  \t  421  \t  64\n",
      "Test P:  0.171\n",
      "Test R:  0.152\n",
      "Test F1:  0.161\n",
      "\n",
      "\n",
      "\n",
      "*******\n",
      "Best Epoch:  19\n",
      "Best Epoch Seed:  61\n",
      "Corresponding P:  0.18\n",
      "Corresponding R:  0.154\n",
      "Corresponding F1:  0.166\n",
      "\n",
      "\n",
      "\n",
      "Best Test Epoch:  16\n",
      "Corresponding P:  0.205\n",
      "Corresponding R:  0.183\n",
      "Corresponding F1:  0.193\n",
      "\n",
      "\n",
      "\n",
      "Test size: 322\n",
      "Re-checking the scores of entire Test data with the best saved model:\n",
      "Total sentences in the test set:  322\n",
      "GT Triple Count:  421  \tPRED Triple Count:  362  \tCORRECT Triple Count:  65\n",
      "Test P:  0.18\n",
      "Test R:  0.154\n",
      "Test F1:  0.166\n",
      "Now printing the scores for various subsets of Test Data with the best saved model:\n",
      "Total sentences with single triples:  243\n",
      "GT Triple Count:  243  \tPRED Triple Count:  257  \tCORRECT Triple Count:  45\n",
      "Test P:  0.175\n",
      "Test R:  0.185\n",
      "Test F1:  0.18\n",
      "Total sentences with multiple triples:  79\n",
      "GT Triple Count:  178  \tPRED Triple Count:  105  \tCORRECT Triple Count:  20\n",
      "Test P:  0.19\n",
      "Test R:  0.112\n",
      "Test F1:  0.141\n",
      "Total sentences triples with varying sentiments:  31\n",
      "GT Triple Count:  79  \tPRED Triple Count:  42  \tCORRECT Triple Count:  5\n",
      "Test P:  0.119\n",
      "Test R:  0.063\n",
      "Test F1:  0.083\n",
      "Total sentences with overlapping triples:  42\n",
      "GT Triple Count:  95  \tPRED Triple Count:  50  \tCORRECT Triple Count:  6\n",
      "Test P:  0.12\n",
      "Test R:  0.063\n",
      "Test F1:  0.083\n"
     ]
    }
   ],
   "source": [
    "!python3 PASTE_BERT.py --gpu_id 0 --src_folder mpqa/ --trg_folder mpqa/PASTE_BERT --bert_mode gen --gen_direct of --l2 y --wd 1e-5 --use_dep_emb y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdfb9004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/shivam/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/shivam/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/shivam/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "enc_hidden_size: 868\n",
      "dec_inp_size: 868\n",
      "dec_hidden_size: 868\n",
      "pointer_net_hidden_size: 300\n",
      "['PASTE_BERT.py', '--gpu_id', '0', '--src_folder', 'mpqa/', '--trg_folder', 'mpqa/PASTE_BERT', '--bert_mode', 'gen', '--gen_direct', 'of', '--l2', 'y', '--wd', '1e-5', '--use_pos_tags', 'y', '--use_dep_emb', 'y']\n",
      "100  10  0.5\n",
      "BERT\n",
      "loading data......\n",
      "No. of sentences:  996\n",
      "No. of lines in Target file:  996\n",
      "No. of lines in POS file:  996\n",
      "No. of lines in DEP file:  996\n",
      "No. of sentences:  323\n",
      "No. of lines in Target file:  323\n",
      "No. of lines in POS file:  323\n",
      "No. of lines in DEP file:  323\n",
      "No. of sentences:  322\n",
      "No. of lines in Target file:  322\n",
      "No. of lines in POS file:  322\n",
      "No. of lines in DEP file:  322\n",
      "Training data size:  994\n",
      "Development data size:  323\n",
      "Test data size:  322\n",
      "Building POS TAG Vocab..\n",
      "Building DEP TAG Vocab..\n",
      "Training started......\n",
      "Batch Count:   63\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/shivam/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_attentions\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/shivam/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Parameters size:  131663959\n",
      "weight factor:  1\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 1e-05\n",
      ")\n",
      "Epoch:  1\n",
      "  0%|                                                    | 0/63 [00:00<?, ?it/s]/home/shivam/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2251: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|| 63/63 [00:24<00:00,  2.59it/s]\n",
      "Training loss:  9.773456210181827\n",
      "Training time:  0:00:24.331162\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.28it/s]\n",
      "Prediction time:  0:00:06.402413\n",
      "323  \t  426  \t  55\n",
      "Dev P:  0.17\n",
      "Dev R:  0.129\n",
      "Dev F1:  0.147\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.53it/s]\n",
      "Prediction time:  0:00:05.946626\n",
      "322  \t  421  \t  40\n",
      "Test P:  0.124\n",
      "Test R:  0.095\n",
      "Test F1:  0.108\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  2\n",
      "100%|| 63/63 [00:24<00:00,  2.58it/s]\n",
      "Training loss:  7.0898248884412975\n",
      "Training time:  0:00:24.427676\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.447386\n",
      "323  \t  426  \t  59\n",
      "Dev P:  0.183\n",
      "Dev R:  0.138\n",
      "Dev F1:  0.158\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.49it/s]\n",
      "Prediction time:  0:00:06.020957\n",
      "322  \t  421  \t  47\n",
      "Test P:  0.146\n",
      "Test R:  0.112\n",
      "Test F1:  0.127\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  3\n",
      "100%|| 63/63 [00:24<00:00,  2.61it/s]\n",
      "Training loss:  6.400741675543407\n",
      "Training time:  0:00:24.174492\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.25it/s]\n",
      "Prediction time:  0:00:06.452642\n",
      "323  \t  426  \t  67\n",
      "Dev P:  0.207\n",
      "Dev R:  0.157\n",
      "Dev F1:  0.179\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.49it/s]\n",
      "Prediction time:  0:00:06.010017\n",
      "322  \t  421  \t  56\n",
      "Test P:  0.174\n",
      "Test R:  0.133\n",
      "Test F1:  0.151\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  4\n",
      "100%|| 63/63 [00:23<00:00,  2.64it/s]\n",
      "Training loss:  5.79859303292774\n",
      "Training time:  0:00:23.868719\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.436735\n",
      "326  \t  426  \t  73\n",
      "Dev P:  0.224\n",
      "Dev R:  0.171\n",
      "Dev F1:  0.194\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.51it/s]\n",
      "Prediction time:  0:00:05.991423\n",
      "324  \t  421  \t  58\n",
      "Test P:  0.179\n",
      "Test R:  0.138\n",
      "Test F1:  0.156\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:24<00:00,  2.62it/s]\n",
      "Training loss:  5.347461938858032\n",
      "Training time:  0:00:24.075383\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.28it/s]\n",
      "Prediction time:  0:00:06.411252\n",
      "353  \t  426  \t  70\n",
      "Dev P:  0.198\n",
      "Dev R:  0.164\n",
      "Dev F1:  0.18\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.51it/s]\n",
      "Prediction time:  0:00:05.977036\n",
      "362  \t  421  \t  63\n",
      "Test P:  0.174\n",
      "Test R:  0.15\n",
      "Test F1:  0.161\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  6\n",
      "100%|| 63/63 [00:24<00:00,  2.58it/s]\n",
      "Training loss:  4.719335677131774\n",
      "Training time:  0:00:24.450106\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.442212\n",
      "354  \t  426  \t  76\n",
      "Dev P:  0.215\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.195\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:06.003489\n",
      "354  \t  421  \t  66\n",
      "Test P:  0.186\n",
      "Test R:  0.157\n",
      "Test F1:  0.17\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  7\n",
      "100%|| 63/63 [00:24<00:00,  2.56it/s]\n",
      "Training loss:  4.386658770697458\n",
      "Training time:  0:00:24.607319\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.27it/s]\n",
      "Prediction time:  0:00:06.419479\n",
      "342  \t  426  \t  74\n",
      "Dev P:  0.216\n",
      "Dev R:  0.174\n",
      "Dev F1:  0.193\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.51it/s]\n",
      "Prediction time:  0:00:05.976110\n",
      "346  \t  421  \t  60\n",
      "Test P:  0.173\n",
      "Test R:  0.143\n",
      "Test F1:  0.156\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  8\n",
      "100%|| 63/63 [00:24<00:00,  2.60it/s]\n",
      "Training loss:  3.8449636376093306\n",
      "Training time:  0:00:24.262528\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.446242\n",
      "331  \t  426  \t  78\n",
      "Dev P:  0.236\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.206\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.49it/s]\n",
      "Prediction time:  0:00:06.009583\n",
      "336  \t  421  \t  56\n",
      "Test P:  0.167\n",
      "Test R:  0.133\n",
      "Test F1:  0.148\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  9\n",
      "100%|| 63/63 [00:24<00:00,  2.61it/s]\n",
      "Training loss:  3.420140586202107\n",
      "Training time:  0:00:24.166611\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.27it/s]\n",
      "Prediction time:  0:00:06.431160\n",
      "333  \t  426  \t  85\n",
      "Dev P:  0.255\n",
      "Dev R:  0.2\n",
      "Dev F1:  0.224\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:05.995746\n",
      "328  \t  421  \t  57\n",
      "Test P:  0.174\n",
      "Test R:  0.135\n",
      "Test F1:  0.152\n",
      "model saved......\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  10\n",
      "100%|| 63/63 [00:24<00:00,  2.59it/s]\n",
      "Training loss:  3.110343166760036\n",
      "Training time:  0:00:24.361913\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.28it/s]\n",
      "Prediction time:  0:00:06.408310\n",
      "367  \t  426  \t  80\n",
      "Dev P:  0.218\n",
      "Dev R:  0.188\n",
      "Dev F1:  0.202\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.52it/s]\n",
      "Prediction time:  0:00:05.972187\n",
      "367  \t  421  \t  64\n",
      "Test P:  0.174\n",
      "Test R:  0.152\n",
      "Test F1:  0.162\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  11\n",
      "100%|| 63/63 [00:24<00:00,  2.60it/s]\n",
      "Training loss:  2.821464588717809\n",
      "Training time:  0:00:24.225630\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.27it/s]\n",
      "Prediction time:  0:00:06.427324\n",
      "375  \t  426  \t  77\n",
      "Dev P:  0.205\n",
      "Dev R:  0.181\n",
      "Dev F1:  0.192\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:06.003082\n",
      "376  \t  421  \t  71\n",
      "Test P:  0.189\n",
      "Test R:  0.169\n",
      "Test F1:  0.178\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  12\n",
      "100%|| 63/63 [00:24<00:00,  2.61it/s]\n",
      "Training loss:  2.502449417871142\n",
      "Training time:  0:00:24.100738\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.447773\n",
      "335  \t  426  \t  81\n",
      "Dev P:  0.242\n",
      "Dev R:  0.19\n",
      "Dev F1:  0.213\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:06.007600\n",
      "333  \t  421  \t  62\n",
      "Test P:  0.186\n",
      "Test R:  0.147\n",
      "Test F1:  0.164\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  13\n",
      "100%|| 63/63 [00:24<00:00,  2.57it/s]\n",
      "Training loss:  2.364548369059487\n",
      "Training time:  0:00:24.504636\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.445347\n",
      "337  \t  426  \t  78\n",
      "Dev P:  0.231\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.204\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.49it/s]\n",
      "Prediction time:  0:00:06.016333\n",
      "346  \t  421  \t  67\n",
      "Test P:  0.194\n",
      "Test R:  0.159\n",
      "Test F1:  0.175\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  14\n",
      "100%|| 63/63 [00:24<00:00,  2.60it/s]\n",
      "Training loss:  2.029854025159563\n",
      "Training time:  0:00:24.187018\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.27it/s]\n",
      "Prediction time:  0:00:06.427277\n",
      "340  \t  426  \t  81\n",
      "Dev P:  0.238\n",
      "Dev R:  0.19\n",
      "Dev F1:  0.211\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.51it/s]\n",
      "Prediction time:  0:00:05.985912\n",
      "341  \t  421  \t  67\n",
      "Test P:  0.196\n",
      "Test R:  0.159\n",
      "Test F1:  0.176\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  15\n",
      "100%|| 63/63 [00:24<00:00,  2.58it/s]\n",
      "Training loss:  1.8343173733779363\n",
      "Training time:  0:00:24.385315\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.27it/s]\n",
      "Prediction time:  0:00:06.426392\n",
      "350  \t  426  \t  72\n",
      "Dev P:  0.206\n",
      "Dev R:  0.169\n",
      "Dev F1:  0.186\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:05.996130\n",
      "359  \t  421  \t  75\n",
      "Test P:  0.209\n",
      "Test R:  0.178\n",
      "Test F1:  0.192\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  16\n",
      "100%|| 63/63 [00:24<00:00,  2.56it/s]\n",
      "Training loss:  1.732968166707054\n",
      "Training time:  0:00:24.649563\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.25it/s]\n",
      "Prediction time:  0:00:06.461741\n",
      "392  \t  426  \t  85\n",
      "Dev P:  0.217\n",
      "Dev R:  0.2\n",
      "Dev F1:  0.208\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.49it/s]\n",
      "Prediction time:  0:00:06.021172\n",
      "398  \t  421  \t  71\n",
      "Test P:  0.178\n",
      "Test R:  0.169\n",
      "Test F1:  0.173\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  17\n",
      "100%|| 63/63 [00:24<00:00,  2.59it/s]\n",
      "Training loss:  1.6702787384154305\n",
      "Training time:  0:00:24.318643\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.25it/s]\n",
      "Prediction time:  0:00:06.452312\n",
      "339  \t  426  \t  77\n",
      "Dev P:  0.227\n",
      "Dev R:  0.181\n",
      "Dev F1:  0.201\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.49it/s]\n",
      "Prediction time:  0:00:06.009583\n",
      "339  \t  421  \t  59\n",
      "Test P:  0.174\n",
      "Test R:  0.14\n",
      "Test F1:  0.155\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  18\n",
      "100%|| 63/63 [00:24<00:00,  2.57it/s]\n",
      "Training loss:  1.527496922583807\n",
      "Training time:  0:00:24.555504\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.450641\n",
      "346  \t  426  \t  76\n",
      "Dev P:  0.22\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.197\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.49it/s]\n",
      "Prediction time:  0:00:06.009077\n",
      "343  \t  421  \t  67\n",
      "Test P:  0.195\n",
      "Test R:  0.159\n",
      "Test F1:  0.175\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  19\n",
      "100%|| 63/63 [00:24<00:00,  2.58it/s]\n",
      "Training loss:  1.421923642120664\n",
      "Training time:  0:00:24.441245\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.29it/s]\n",
      "Prediction time:  0:00:06.387444\n",
      "350  \t  426  \t  78\n",
      "Dev P:  0.223\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.201\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.53it/s]\n",
      "Prediction time:  0:00:05.954929\n",
      "354  \t  421  \t  64\n",
      "Test P:  0.181\n",
      "Test R:  0.152\n",
      "Test F1:  0.165\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:24<00:00,  2.62it/s]\n",
      "Training loss:  1.3090122578636048\n",
      "Training time:  0:00:24.076247\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.24it/s]\n",
      "Prediction time:  0:00:06.473607\n",
      "368  \t  426  \t  78\n",
      "Dev P:  0.212\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.196\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.48it/s]\n",
      "Prediction time:  0:00:06.035019\n",
      "377  \t  421  \t  63\n",
      "Test P:  0.167\n",
      "Test R:  0.15\n",
      "Test F1:  0.158\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  21\n",
      "100%|| 63/63 [00:23<00:00,  2.64it/s]\n",
      "Training loss:  1.2229413702374412\n",
      "Training time:  0:00:23.866743\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.440974\n",
      "368  \t  426  \t  80\n",
      "Dev P:  0.217\n",
      "Dev R:  0.188\n",
      "Dev F1:  0.202\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:06.002375\n",
      "380  \t  421  \t  63\n",
      "Test P:  0.166\n",
      "Test R:  0.15\n",
      "Test F1:  0.157\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  22\n",
      "100%|| 63/63 [00:24<00:00,  2.60it/s]\n",
      "Training loss:  1.2241111322054787\n",
      "Training time:  0:00:24.226699\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.27it/s]\n",
      "Prediction time:  0:00:06.424646\n",
      "382  \t  426  \t  80\n",
      "Dev P:  0.209\n",
      "Dev R:  0.188\n",
      "Dev F1:  0.198\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.51it/s]\n",
      "Prediction time:  0:00:05.987375\n",
      "386  \t  421  \t  73\n",
      "Test P:  0.189\n",
      "Test R:  0.173\n",
      "Test F1:  0.181\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  23\n",
      "100%|| 63/63 [00:24<00:00,  2.61it/s]\n",
      "Training loss:  1.1511418885654874\n",
      "Training time:  0:00:24.127859\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.24it/s]\n",
      "Prediction time:  0:00:06.473302\n",
      "351  \t  426  \t  77\n",
      "Dev P:  0.219\n",
      "Dev R:  0.181\n",
      "Dev F1:  0.198\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.47it/s]\n",
      "Prediction time:  0:00:06.053095\n",
      "352  \t  421  \t  61\n",
      "Test P:  0.173\n",
      "Test R:  0.145\n",
      "Test F1:  0.158\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  24\n",
      "100%|| 63/63 [00:24<00:00,  2.57it/s]\n",
      "Training loss:  1.1027269316098047\n",
      "Training time:  0:00:24.479213\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.27it/s]\n",
      "Prediction time:  0:00:06.428308\n",
      "345  \t  426  \t  76\n",
      "Dev P:  0.22\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.197\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:05.998432\n",
      "340  \t  421  \t  66\n",
      "Test P:  0.194\n",
      "Test R:  0.157\n",
      "Test F1:  0.173\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  25\n",
      "100%|| 63/63 [00:24<00:00,  2.58it/s]\n",
      "Training loss:  1.0346810950173273\n",
      "Training time:  0:00:24.422845\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.24it/s]\n",
      "Prediction time:  0:00:06.477435\n",
      "361  \t  426  \t  78\n",
      "Dev P:  0.216\n",
      "Dev R:  0.183\n",
      "Dev F1:  0.198\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.48it/s]\n",
      "Prediction time:  0:00:06.029283\n",
      "367  \t  421  \t  65\n",
      "Test P:  0.177\n",
      "Test R:  0.154\n",
      "Test F1:  0.165\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  26\n",
      "100%|| 63/63 [00:24<00:00,  2.57it/s]\n",
      "Training loss:  0.9660832196001022\n",
      "Training time:  0:00:24.525825\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.448045\n",
      "347  \t  426  \t  69\n",
      "Dev P:  0.199\n",
      "Dev R:  0.162\n",
      "Dev F1:  0.179\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:06.003231\n",
      "344  \t  421  \t  66\n",
      "Test P:  0.192\n",
      "Test R:  0.157\n",
      "Test F1:  0.173\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  27\n",
      "100%|| 63/63 [00:24<00:00,  2.56it/s]\n",
      "Training loss:  0.8743411716487672\n",
      "Training time:  0:00:24.583326\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.440115\n",
      "352  \t  426  \t  76\n",
      "Dev P:  0.216\n",
      "Dev R:  0.178\n",
      "Dev F1:  0.195\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.51it/s]\n",
      "Prediction time:  0:00:05.989983\n",
      "354  \t  421  \t  60\n",
      "Test P:  0.169\n",
      "Test R:  0.143\n",
      "Test F1:  0.155\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  28\n",
      "100%|| 63/63 [00:24<00:00,  2.57it/s]\n",
      "Training loss:  0.7927162013356648\n",
      "Training time:  0:00:24.472339\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.444044\n",
      "348  \t  426  \t  82\n",
      "Dev P:  0.236\n",
      "Dev R:  0.192\n",
      "Dev F1:  0.212\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:05.993626\n",
      "343  \t  421  \t  67\n",
      "Test P:  0.195\n",
      "Test R:  0.159\n",
      "Test F1:  0.175\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  29\n",
      "100%|| 63/63 [00:24<00:00,  2.62it/s]\n",
      "Training loss:  0.8499110733705854\n",
      "Training time:  0:00:24.062742\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.26it/s]\n",
      "Prediction time:  0:00:06.436184\n",
      "351  \t  426  \t  86\n",
      "Dev P:  0.245\n",
      "Dev R:  0.202\n",
      "Dev F1:  0.221\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:05<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:05.998234\n",
      "359  \t  421  \t  66\n",
      "Test P:  0.184\n",
      "Test R:  0.157\n",
      "Test F1:  0.169\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  30\n",
      "100%|| 63/63 [00:24<00:00,  2.59it/s]\n",
      "Training loss:  0.7828442075895885\n",
      "Training time:  0:00:24.349610\n",
      "\n",
      "Dev Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.25it/s]\n",
      "Prediction time:  0:00:06.459662\n",
      "363  \t  426  \t  79\n",
      "Dev P:  0.218\n",
      "Dev R:  0.185\n",
      "Dev F1:  0.2\n",
      "\n",
      "Test Results\n",
      "\n",
      "100%|| 21/21 [00:06<00:00,  3.50it/s]\n",
      "Prediction time:  0:00:06.007871\n",
      "372  \t  421  \t  71\n",
      "Test P:  0.191\n",
      "Test R:  0.169\n",
      "Test F1:  0.179\n",
      "\n",
      "\n",
      "\n",
      "*******\n",
      "Best Epoch:  9\n",
      "Best Epoch Seed:  51\n",
      "Corresponding P:  0.174\n",
      "Corresponding R:  0.135\n",
      "Corresponding F1:  0.152\n",
      "\n",
      "\n",
      "\n",
      "Best Test Epoch:  15\n",
      "Corresponding P:  0.209\n",
      "Corresponding R:  0.178\n",
      "Corresponding F1:  0.192\n",
      "\n",
      "\n",
      "\n",
      "Test size: 322\n",
      "Re-checking the scores of entire Test data with the best saved model:\n",
      "Total sentences in the test set:  322\n",
      "GT Triple Count:  421  \tPRED Triple Count:  328  \tCORRECT Triple Count:  57\n",
      "Test P:  0.174\n",
      "Test R:  0.135\n",
      "Test F1:  0.152\n",
      "Now printing the scores for various subsets of Test Data with the best saved model:\n",
      "Total sentences with single triples:  243\n",
      "GT Triple Count:  243  \tPRED Triple Count:  245  \tCORRECT Triple Count:  42\n",
      "Test P:  0.171\n",
      "Test R:  0.173\n",
      "Test F1:  0.172\n",
      "Total sentences with multiple triples:  79\n",
      "GT Triple Count:  178  \tPRED Triple Count:  83  \tCORRECT Triple Count:  15\n",
      "Test P:  0.181\n",
      "Test R:  0.084\n",
      "Test F1:  0.115\n",
      "Total sentences triples with varying sentiments:  31\n",
      "GT Triple Count:  79  \tPRED Triple Count:  32  \tCORRECT Triple Count:  4\n",
      "Test P:  0.125\n",
      "Test R:  0.051\n",
      "Test F1:  0.072\n",
      "Total sentences with overlapping triples:  42\n",
      "GT Triple Count:  95  \tPRED Triple Count:  43  \tCORRECT Triple Count:  6\n",
      "Test P:  0.14\n",
      "Test R:  0.063\n",
      "Test F1:  0.087\n"
     ]
    }
   ],
   "source": [
    "!python3 PASTE_BERT.py --gpu_id 0 --src_folder mpqa/ --trg_folder mpqa/PASTE_BERT --bert_mode gen --gen_direct of --l2 y --wd 1e-5 --use_pos_tags y --use_dep_emb y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3aeaa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2040ace5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a26ea26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581bf593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831553fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
